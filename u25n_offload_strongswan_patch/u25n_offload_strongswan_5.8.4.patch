diff --git a/configure.ac b/configure.ac
index 7788121e1..b6287dc2a 100644
--- a/configure.ac
+++ b/configure.ac
@@ -225,6 +225,7 @@ ARG_ENABL_SET([xauth-pam],      [enable XAuth backend using PAM to verify passwo
 ARG_ENABL_SET([xauth-noauth],   [enable XAuth pseudo-backend that does not actually verify or even request any credentials.])
 # kernel interfaces / sockets
 ARG_DISBL_SET([kernel-netlink], [disable the netlink kernel interface.])
+ARG_ENABL_SET([ipsec-offload],  [enable ipsec offload plugin.])
 ARG_ENABL_SET([kernel-pfkey],   [enable the PF_KEY kernel interface.])
 ARG_ENABL_SET([kernel-pfroute], [enable the PF_ROUTE kernel interface.])
 ARG_ENABL_SET([kernel-iph],     [enable the Windows IP Helper based networking backend.])
@@ -1483,6 +1484,7 @@ ADD_PLUGIN([kernel-iph],           [c charon])
 ADD_PLUGIN([kernel-pfkey],         [c charon starter nm cmd])
 ADD_PLUGIN([kernel-pfroute],       [c charon starter nm cmd])
 ADD_PLUGIN([kernel-netlink],       [c charon starter nm cmd])
+ADD_PLUGIN([ipsec-offload],        [c charon])
 ADD_PLUGIN([resolve],              [c charon cmd])
 ADD_PLUGIN([save-keys],            [c])
 ADD_PLUGIN([socket-default],       [c charon nm cmd])
@@ -1657,6 +1659,7 @@ AM_CONDITIONAL(USE_DHCP, test x$dhcp = xtrue)
 AM_CONDITIONAL(USE_LOAD_TESTER, test x$load_tester = xtrue)
 AM_CONDITIONAL(USE_HA, test x$ha = xtrue)
 AM_CONDITIONAL(USE_KERNEL_NETLINK, test x$kernel_netlink = xtrue)
+AM_CONDITIONAL(USE_IPSEC_OFFLOAD, test x$ipsec_offload = xtrue)
 AM_CONDITIONAL(USE_KERNEL_PFKEY, test x$kernel_pfkey = xtrue)
 AM_CONDITIONAL(USE_KERNEL_PFROUTE, test x$kernel_pfroute = xtrue)
 AM_CONDITIONAL(USE_KERNEL_LIBIPSEC, test x$kernel_libipsec = xtrue)
@@ -2002,6 +2005,7 @@ AC_CONFIG_FILES([
 	src/libcharon/plugins/uci/Makefile
 	src/libcharon/plugins/ha/Makefile
 	src/libcharon/plugins/kernel_netlink/Makefile
+	src/libcharon/plugins/ipsec_offload/Makefile
 	src/libcharon/plugins/kernel_pfkey/Makefile
 	src/libcharon/plugins/kernel_pfroute/Makefile
 	src/libcharon/plugins/kernel_libipsec/Makefile
diff --git a/src/libcharon/Makefile.am b/src/libcharon/Makefile.am
index 15ac7a6d1..674e9185b 100644
--- a/src/libcharon/Makefile.am
+++ b/src/libcharon/Makefile.am
@@ -579,6 +579,13 @@ if MONOLITHIC
 endif
 endif
 
+if USE_IPSEC_OFFLOAD
+  SUBDIRS += plugins/ipsec_offload
+if MONOLITHIC
+  libcharon_la_LIBADD += plugins/ipsec_offload/libstrongswan-ipsec-offload.la
+endif
+endif
+
 if USE_KERNEL_LIBIPSEC
   SUBDIRS += plugins/kernel_libipsec
 if MONOLITHIC
diff --git a/src/libcharon/config/child_cfg.h b/src/libcharon/config/child_cfg.h
index b176d67bd..956de015b 100644
--- a/src/libcharon/config/child_cfg.h
+++ b/src/libcharon/config/child_cfg.h
@@ -15,6 +15,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 /**
  * @defgroup child_cfg child_cfg
@@ -334,17 +342,20 @@ enum child_cfg_option_t {
 	/** Install outbound FWD IPsec policies to bypass drop policies */
 	OPT_FWD_OUT_POLICIES = (1<<4),
 
+	/** Enable hardware offload, if supported by the IPsec backend */
+	OPT_HW_OFFLOAD = (1<<5),
+
 	/** Force 96-bit truncation for SHA-256 */
-	OPT_SHA256_96 = (1<<5),
+	OPT_SHA256_96 = (1<<6),
 
 	/** Set mark on inbound SAs */
-	OPT_MARK_IN_SA = (1<<6),
+	OPT_MARK_IN_SA = (1<<7),
 
 	/** Disable copying the DF bit to the outer IPv4 header in tunnel mode */
-	OPT_NO_COPY_DF = (1<<7),
+	OPT_NO_COPY_DF = (1<<8),
 
 	/** Disable copying the ECN header field in tunnel mode */
-	OPT_NO_COPY_ECN = (1<<8),
+	OPT_NO_COPY_ECN = (1<<9),
 };
 
 /**
diff --git a/src/libcharon/kernel/kernel_ipsec.h b/src/libcharon/kernel/kernel_ipsec.h
index 70ff2eb12..33ee55ec8 100644
--- a/src/libcharon/kernel/kernel_ipsec.h
+++ b/src/libcharon/kernel/kernel_ipsec.h
@@ -16,6 +16,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 /**
  * @defgroup kernel_ipsec kernel_ipsec
@@ -93,8 +101,10 @@ struct kernel_ipsec_add_sa_t {
 	uint16_t cpi;
 	/** TRUE to enable UDP encapsulation for NAT traversal */
 	bool encap;
+	/** TRUE to enable hardware offloading if available */
+	bool hw_offload;
 	/** no (disabled), yes (enabled), auto (enabled if supported) */
-	hw_offload_t hw_offload;
+	//hw_offload_t hw_offload;
 	/** Mark the SA should apply to packets after processing */
 	mark_t mark;
 	/** TRUE to use Extended Sequence Numbers */
diff --git a/src/libcharon/plugins/ipsec_offload/Makefile.am b/src/libcharon/plugins/ipsec_offload/Makefile.am
new file mode 100644
index 000000000..feb12af56
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/Makefile.am
@@ -0,0 +1,35 @@
+# Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+# Copyright 2021 Xilinx Inc.
+#
+# This program is free software; you can redistribute it and/or modify it
+# under the terms of the GNU General Public License version 2 as published
+# by the Free Software Foundation, incorporated herein by reference.
+#
+
+AM_CPPFLAGS = \
+	-I${linux_headers} \
+	-I$(top_srcdir)/src/libstrongswan \
+	-I$(top_srcdir)/src/libcharon \
+	-DROUTING_TABLE=${routing_table} \
+	-DROUTING_TABLE_PRIO=${routing_table_prio}
+
+AM_CFLAGS = \
+	$(PLUGIN_CFLAGS)
+
+if MONOLITHIC
+noinst_LTLIBRARIES = libstrongswan-ipsec-offload.la
+else
+plugin_LTLIBRARIES = libstrongswan-ipsec-offload.la
+endif
+
+libstrongswan_ipsec_offload_la_SOURCES = \
+	ipsec_offload_plugin.h ipsec_offload_plugin.c \
+	ipsec_offload_ipsec.h ipsec_offload_ipsec.c \
+	ipsec_offload_shared.h ipsec_offload_shared.c\
+	ipsec_offload_net.h ipsec_offload_net.c
+
+libstrongswan_ipsec_offload_la_LIBADD = $(DLLIB)
+
+libstrongswan_ipsec_offload_la_LDFLAGS = -module -avoid-version
+
+
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.c b/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.c
new file mode 100644
index 000000000..0853050aa
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.c
@@ -0,0 +1,4396 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#define _GNU_SOURCE
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <sys/ioctl.h>
+#include <stdint.h>
+#include <linux/ipsec.h>
+#include <linux/netlink.h>
+#include <linux/rtnetlink.h>
+#include <linux/xfrm.h>
+#include <linux/udp.h>
+#include <linux/ethtool.h>
+#include <linux/sockios.h>
+#include <net/if.h>
+#include <unistd.h>
+#include <time.h>
+#include <errno.h>
+#include <string.h>
+#include <fcntl.h>
+#include <dlfcn.h>
+
+#include "ipsec_offload_ipsec.h"
+#include "ipsec_offload_shared.h"
+
+#include <daemon.h>
+#include <utils/debug.h>
+#include <threading/mutex.h>
+#include <threading/condvar.h>
+#include <collections/array.h>
+#include <collections/hashtable.h>
+#include <collections/linked_list.h>
+
+#include <arpa/inet.h>
+
+/** Required for Linux 2.6.26 kernel and later */
+#ifndef XFRM_STATE_AF_UNSPEC
+#define XFRM_STATE_AF_UNSPEC 32
+#endif
+
+/** From linux/in.h */
+#ifndef IP_XFRM_POLICY
+#define IP_XFRM_POLICY 17
+#endif
+
+/** Missing on uclibc */
+#ifndef IPV6_XFRM_POLICY
+#define IPV6_XFRM_POLICY 34
+#endif /*IPV6_XFRM_POLICY*/
+
+/* from linux/udp.h */
+#ifndef UDP_ENCAP
+#define UDP_ENCAP 100
+#endif
+
+#ifndef UDP_ENCAP_ESPINUDP
+#define UDP_ENCAP_ESPINUDP 2
+#endif
+
+/* this is not defined on some platforms */
+#ifndef SOL_UDP
+#define SOL_UDP IPPROTO_UDP
+#endif
+
+/** Base priority for installed policies */
+#define PRIO_BASE 200000
+
+/**
+ * Map the limit for bytes and packets to XFRM_INF by default
+ */
+#define XFRM_LIMIT(x) ((x) == 0 ? XFRM_INF : (x))
+
+/**
+ * Create ORable bitfield of XFRM NL groups
+ */
+#define XFRMNLGRP(x) (1<<(XFRMNLGRP_##x-1))
+
+/**
+ * Returns a pointer to the first rtattr following the nlmsghdr *nlh and the
+ * 'usual' netlink data x like 'struct xfrm_usersa_info'
+ */
+#define XFRM_RTA(nlh, x) ((struct rtattr*)(NLMSG_DATA(nlh) + \
+			NLMSG_ALIGN(sizeof(x))))
+/**
+ * Returns the total size of attached rta data
+ * (after 'usual' netlink data x like 'struct xfrm_usersa_info')
+ */
+#define XFRM_PAYLOAD(nlh, x) NLMSG_PAYLOAD(nlh, sizeof(x))
+
+#define IPSEC_OFFLOAD_ADD_SA_ENC 0x89F4
+#define IPSEC_OFFLOAD_ADD_SA_DEC 0x89F5
+#define IPSEC_OFFLOAD_ADD_POLICY 0x89F6
+#define IPSEC_OFFLOAD_DEL_POLICY 0x89F7
+#define IPSEC_OFFLOAD_DEL_SA_DEC 0x89F8
+#define IPSEC_OFFLOAD_QUERY_SA 0x89F9
+#define ENC 1
+#define DEC 0
+
+static void print_key(void *addr, int size)
+{
+	uint8_t *data = addr;
+	int i;
+
+	for(i = 0; i < size; i+=8) {
+		DBG1(DBG_KNL,"%02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x\n", data[i], data[i+1], data[i+2], data[i+3], data[i+4], data[i+5], data[i+6], data[i+7]);
+	}
+}
+
+typedef struct ipsec_offload_add_sa_dec ipsec_offload_add_sa_dec;
+typedef struct ipsec_offload_add_policy_enc ipsec_offload_add_policy_enc;
+bool hw_check;
+
+struct ipsec_offload_add_sa_dec {
+	uint32_t ipsec_offload_sc;
+	uint32_t ipsec_offload_dc;
+	uint32_t ipsec_offload_spi;
+	uint32_t ipsec_offload_iiv;
+	uint8_t ipsec_offload_key [32];
+};
+typedef struct ipsec_offload_add_sa_enc ipsec_offload_add_sa_enc;
+struct ipsec_offload_add_sa_enc {
+	uint32_t ipsec_offload_sc;
+        uint32_t ipsec_offload_dc;
+        uint8_t ipsec_offload_protocol;
+	uint32_t ipsec_offload_spi;
+	uint32_t ipsec_offload_iiv;
+	uint64_t ipsec_offload_eiv;
+	uint8_t ipsec_offload_key [32];
+	uint8_t ipsec_offload_action_flag;
+};
+ipsec_offload_add_sa_enc sa_enc;
+
+typedef struct ipsec_offload_del_sa_dec ipsec_offload_del_sa_dec;
+
+struct ipsec_offload_del_sa_dec {
+	uint32_t ipsec_offload_sc;
+	uint32_t ipsec_offload_dc;
+	uint32_t ipsec_offload_spi;
+};
+
+typedef struct ipsec_offload_del_sa_enc ipsec_offload_del_sa_enc;
+
+struct ipsec_offload_del_sa_enc {
+	uint32_t ipsec_offload_sc;
+	uint32_t ipsec_offload_dc;
+	uint8_t ipsec_offload_protocol;
+	uint32_t ipsec_offload_spi;
+};
+
+
+
+typedef struct ipsec_offload_query_sa ipsec_offload_query_sa;
+
+struct ipsec_offload_query_sa {
+	uint32_t ipsec_offload_spi;
+	uint64_t ipsec_offload_packets;
+	uint64_t ipsec_offload_bytes;
+};
+
+struct Node {
+	uint32_t data;
+	struct Node* next;
+};
+struct Node *head = NULL;
+
+struct Node_ifname {
+	uint32_t spi;
+	char ifname[20];
+	struct Node_ifname* next_ifname;
+};
+struct Node_ifname *head_ifname = NULL;
+
+struct Node_add_sa_enc {
+	uint32_t src;
+	uint32_t dst;
+	uint32_t spi;
+	struct Node_add_sa_enc* next_add_sa_enc;
+};
+struct Node_add_sa_enc *head_add_sa_enc = NULL;
+
+
+int ipsec_offload_add_sa(int,  chunk_t *, uint32_t * , xfrm_address_t *, xfrm_address_t * , uint32_t *, const char *);
+struct ipsec_offload_query_sa ipsec_offload_query_sa_fun(uint32_t * );
+int ipsec_offload_del_sa(xfrm_address_t *, xfrm_address_t * , uint32_t *);
+void ipsec_offload_add_policy(policy_dir_t *, traffic_selector_t *, traffic_selector_t*, uint32_t *, policy_type_t *, uint8_t * );
+void ipsec_offload_get_sc_policy(uint32_t * ,  traffic_selector_t * );
+void ipsec_offload_get_dc_policy(uint32_t * ,  traffic_selector_t * );
+void ipsec_offload_get_sc(uint32_t * ,  xfrm_address_t * );
+void ipsec_offload_get_dc(uint32_t * , xfrm_address_t *);
+void ipsec_offload_get_spi(uint32_t * , uint32_t *);
+void ipsec_offload_get_iiv(uint32_t *,chunk_t *);
+void ipsec_offload_get_key(uint8_t *,chunk_t *);
+void ipsec_offload_get_eiv(uint64_t *);
+void ipsec_offload_get_action_flag(uint8_t *, policy_type_t *);
+void ipsec_offload_get_protocol(uint8_t *, uint8_t *);
+void printlist(struct Node * );
+void printlist_ifname(struct Node_ifname * );
+void printlist_add_sa_enc(struct Node_add_sa_enc * );
+void append(struct Node** , uint32_t);
+void append_ifname(struct Node_ifname** , uint32_t, const char *);
+void append_add_sa_enc(struct Node_add_sa_enc** , uint32_t, uint32_t , uint32_t);
+int find(struct Node** , uint32_t );
+char* find_ifname(struct Node_ifname** , uint32_t );
+uint32_t find_add_sa_enc(struct Node_add_sa_enc** , uint32_t, uint32_t );
+int delete(struct Node ** , uint32_t);
+int delete_ifname(struct Node_ifname ** , uint32_t);
+int delete_add_sa_enc(struct Node_add_sa_enc ** , uint32_t, uint32_t);
+
+typedef struct kernel_algorithm_t kernel_algorithm_t;
+
+/**
+ * Mapping of IKEv2 kernel identifier to linux crypto API names
+ */
+struct kernel_algorithm_t {
+	/**
+	 * Identifier specified in IKEv2
+	 */
+	int ikev2;
+
+	/**
+	 * Name of the algorithm in linux crypto API
+	 */
+	const char *name;
+};
+
+ENUM(xfrm_msg_names, XFRM_MSG_NEWSA, XFRM_MSG_MAPPING,
+		"XFRM_MSG_NEWSA",
+		"XFRM_MSG_DELSA",
+		"XFRM_MSG_GETSA",
+		"XFRM_MSG_NEWPOLICY",
+		"XFRM_MSG_DELPOLICY",
+		"XFRM_MSG_GETPOLICY",
+		"XFRM_MSG_ALLOCSPI",
+		"XFRM_MSG_ACQUIRE",
+		"XFRM_MSG_EXPIRE",
+		"XFRM_MSG_UPDPOLICY",
+		"XFRM_MSG_UPDSA",
+		"XFRM_MSG_POLEXPIRE",
+		"XFRM_MSG_FLUSHSA",
+		"XFRM_MSG_FLUSHPOLICY",
+		"XFRM_MSG_NEWAE",
+		"XFRM_MSG_GETAE",
+		"XFRM_MSG_REPORT",
+		"XFRM_MSG_MIGRATE",
+		"XFRM_MSG_NEWSADINFO",
+		"XFRM_MSG_GETSADINFO",
+		"XFRM_MSG_NEWSPDINFO",
+		"XFRM_MSG_GETSPDINFO",
+		"XFRM_MSG_MAPPING"
+		);
+
+		ENUM(xfrm_attr_type_names, XFRMA_UNSPEC, XFRMA_OFFLOAD_DEV,
+				"XFRMA_UNSPEC",
+				"XFRMA_ALG_AUTH",
+				"XFRMA_ALG_CRYPT",
+				"XFRMA_ALG_COMP",
+				"XFRMA_ENCAP",
+				"XFRMA_TMPL",
+				"XFRMA_SA",
+				"XFRMA_POLICY",
+				"XFRMA_SEC_CTX",
+				"XFRMA_LTIME_VAL",
+				"XFRMA_REPLAY_VAL",
+				"XFRMA_REPLAY_THRESH",
+				"XFRMA_ETIMER_THRESH",
+				"XFRMA_SRCADDR",
+				"XFRMA_COADDR",
+				"XFRMA_LASTUSED",
+				"XFRMA_POLICY_TYPE",
+				"XFRMA_MIGRATE",
+				"XFRMA_ALG_AEAD",
+				"XFRMA_KMADDRESS",
+				"XFRMA_ALG_AUTH_TRUNC",
+				"XFRMA_MARK",
+				"XFRMA_TFCPAD",
+				"XFRMA_REPLAY_ESN_VAL",
+				"XFRMA_SA_EXTRA_FLAGS",
+				"XFRMA_PROTO",
+				"XFRMA_ADDRESS_FILTER",
+				"XFRMA_PAD",
+				"XFRMA_OFFLOAD_DEV",
+				);
+
+/**
+ * Algorithms for encryption
+ */
+static kernel_algorithm_t encryption_algs[] = {
+	/*	{ENCR_DES_IV64,				"***"				}, */
+	{ENCR_DES,					"des"				},
+	{ENCR_3DES,					"des3_ede"			},
+	/*	{ENCR_RC5,					"***"				}, */
+	/*	{ENCR_IDEA,					"***"				}, */
+	{ENCR_CAST,					"cast5"				},
+	{ENCR_BLOWFISH,				"blowfish"			},
+	/*	{ENCR_3IDEA,				"***"				}, */
+	/*	{ENCR_DES_IV32,				"***"				}, */
+	{ENCR_NULL,					"cipher_null"		},
+	{ENCR_AES_CBC,				"aes"				},
+	{ENCR_AES_CTR,				"rfc3686(ctr(aes))"	},
+	{ENCR_AES_CCM_ICV8,			"rfc4309(ccm(aes))"	},
+	{ENCR_AES_CCM_ICV12,		"rfc4309(ccm(aes))"	},
+	{ENCR_AES_CCM_ICV16,		"rfc4309(ccm(aes))"	},
+	{ENCR_AES_GCM_ICV8,			"rfc4106(gcm(aes))"	},
+	{ENCR_AES_GCM_ICV12,		"rfc4106(gcm(aes))"	},
+	{ENCR_AES_GCM_ICV16,		"rfc4106(gcm(aes))"	},
+	{ENCR_NULL_AUTH_AES_GMAC,	"rfc4543(gcm(aes))"	},
+	{ENCR_CAMELLIA_CBC,			"cbc(camellia)"		},
+	/*	{ENCR_CAMELLIA_CTR,			"***"				}, */
+	/*	{ENCR_CAMELLIA_CCM_ICV8,	"***"				}, */
+	/*	{ENCR_CAMELLIA_CCM_ICV12,	"***"				}, */
+	/*	{ENCR_CAMELLIA_CCM_ICV16,	"***"				}, */
+	{ENCR_SERPENT_CBC,			"serpent"			},
+	{ENCR_TWOFISH_CBC,			"twofish"			},
+	{ENCR_CHACHA20_POLY1305,	"rfc7539esp(chacha20,poly1305)"},
+};
+
+/**
+ * Algorithms for integrity protection
+ */
+static kernel_algorithm_t integrity_algs[] = {
+	{AUTH_HMAC_MD5_96,			"md5"				},
+	{AUTH_HMAC_MD5_128,			"hmac(md5)"			},
+	{AUTH_HMAC_SHA1_96,			"sha1"				},
+	{AUTH_HMAC_SHA1_160,		"hmac(sha1)"		},
+	{AUTH_HMAC_SHA2_256_96,		"sha256"			},
+	{AUTH_HMAC_SHA2_256_128,	"hmac(sha256)"		},
+	{AUTH_HMAC_SHA2_384_192,	"hmac(sha384)"		},
+	{AUTH_HMAC_SHA2_512_256,	"hmac(sha512)"		},
+	/*	{AUTH_DES_MAC,				"***"				}, */
+	/*	{AUTH_KPDK_MD5,				"***"				}, */
+	{AUTH_AES_XCBC_96,			"xcbc(aes)"			},
+	{AUTH_AES_CMAC_96,			"cmac(aes)"			},
+};
+
+/**
+ * Algorithms for IPComp
+ */
+static kernel_algorithm_t compression_algs[] = {
+	/*	{IPCOMP_OUI,				"***"				}, */
+	{IPCOMP_DEFLATE,			"deflate"			},
+	{IPCOMP_LZS,				"lzs"				},
+	{IPCOMP_LZJH,				"lzjh"				},
+};
+
+/**
+ * IPsec offload
+ */
+enum nic_offload_state {
+	NIC_OFFLOAD_UNKNOWN,
+	NIC_OFFLOAD_UNSUPPORTED,
+	NIC_OFFLOAD_SUPPORTED
+};
+
+static struct {
+	unsigned int bit;
+	unsigned int total_blocks;
+	enum nic_offload_state state;
+} netlink_esp_hw_offload;
+
+/**
+ * Look up a kernel algorithm name and its key size
+ */
+static const char* lookup_algorithm(transform_type_t type, int ikev2)
+{
+	kernel_algorithm_t *list;
+	int i, count;
+	char *name;
+
+	switch (type)
+	{
+		case ENCRYPTION_ALGORITHM:
+			list = encryption_algs;
+			count = countof(encryption_algs);
+			break;
+		case INTEGRITY_ALGORITHM:
+			list = integrity_algs;
+			count = countof(integrity_algs);
+			break;
+		case COMPRESSION_ALGORITHM:
+			list = compression_algs;
+			count = countof(compression_algs);
+			break;
+		default:
+			return NULL;
+	}
+	for (i = 0; i < count; i++)
+	{
+		if (list[i].ikev2 == ikev2)
+		{
+			return list[i].name;
+		}
+	}
+	if (charon->kernel->lookup_algorithm(charon->kernel, ikev2, type, NULL,
+				&name))
+	{
+		return name;
+	}
+	return NULL;
+}
+
+typedef struct private_ipsec_offload_ipsec_t private_ipsec_offload_ipsec_t;
+
+/**
+ * Private variables and functions of kernel_netlink class.
+ */
+struct private_ipsec_offload_ipsec_t {
+	/**
+	 * Public part of the kernel_netlink_t object
+	 */
+	ipsec_offload_ipsec_t public;
+
+	/**
+	 * Mutex to lock access to installed policies
+	 */
+	mutex_t *mutex;
+
+	/**
+	 * Condvar to synchronize access to individual policies
+	 */
+	condvar_t *condvar;
+
+	/**
+	 * Hash table of installed policies (policy_entry_t)
+	 */
+	hashtable_t *policies;
+
+	/**
+	 * Hash table of IPsec SAs using policies (ipsec_sa_t)
+	 */
+	hashtable_t *sas;
+
+	/**
+	 * Netlink xfrm socket (IPsec)
+	 */
+	netlink_socket_t *socket_xfrm;
+
+	/**
+	 * Netlink xfrm socket to receive acquire and expire events
+	 */
+	int socket_xfrm_events;
+
+	/**
+	 * Whether to install routes along policies
+	 */
+	bool install_routes;
+
+	/**
+	 * Whether to set protocol and ports on selector installed with transport
+	 * mode IPsec SAs
+	 */
+	bool proto_port_transport;
+
+	/**
+	 * Whether to always use UPDATE to install policies
+	 */
+	bool policy_update;
+
+	/**
+	 * Installed port based IKE bypass policies, as bypass_t
+	 */
+	array_t *bypass;
+
+	/**
+	 * Custom priority calculation function
+	 */
+	uint32_t (*get_priority)(kernel_ipsec_policy_id_t *id,
+			kernel_ipsec_manage_policy_t *data);
+};
+
+typedef struct ipsec_sa_t ipsec_sa_t;
+
+/**
+ * IPsec SA assigned to a policy.
+ */
+struct ipsec_sa_t {
+	/** Source address of this SA */
+	host_t *src;
+
+	/** Destination address of this SA */
+	host_t *dst;
+
+	/** Optional mark */
+	mark_t mark;
+
+	/** Optional mark */
+	uint32_t if_id;
+
+	/** Description of this SA */
+	ipsec_sa_cfg_t cfg;
+
+	/** Reference count for this SA */
+	refcount_t refcount;
+};
+
+/**
+ * Hash function for ipsec_sa_t objects
+ */
+static u_int ipsec_sa_hash(ipsec_sa_t *sa)
+{
+	return chunk_hash_inc(sa->src->get_address(sa->src),
+			chunk_hash_inc(sa->dst->get_address(sa->dst),
+				chunk_hash_inc(chunk_from_thing(sa->mark),
+					chunk_hash_inc(chunk_from_thing(sa->if_id),
+						chunk_hash(chunk_from_thing(sa->cfg))))));
+}
+
+/**
+ * Equality function for ipsec_sa_t objects
+ */
+static bool ipsec_sa_equals(ipsec_sa_t *sa, ipsec_sa_t *other_sa)
+{
+	return sa->src->ip_equals(sa->src, other_sa->src) &&
+		sa->dst->ip_equals(sa->dst, other_sa->dst) &&
+		sa->mark.value == other_sa->mark.value &&
+		sa->mark.mask == other_sa->mark.mask &&
+		sa->if_id == other_sa->if_id &&
+		ipsec_sa_cfg_equals(&sa->cfg, &other_sa->cfg);
+}
+
+/**
+ * Allocate or reference an IPsec SA object
+ */
+static ipsec_sa_t *ipsec_sa_create(private_ipsec_offload_ipsec_t *this,
+		host_t *src, host_t *dst, mark_t mark,
+		uint32_t if_id, ipsec_sa_cfg_t *cfg)
+{
+	ipsec_sa_t *sa, *found;
+	INIT(sa,
+			.src = src,
+			.dst = dst,
+			.mark = mark,
+			.if_id = if_id,
+			.cfg = *cfg,
+	    );
+	found = this->sas->get(this->sas, sa);
+	if (!found)
+	{
+		sa->src = src->clone(src);
+		sa->dst = dst->clone(dst);
+		this->sas->put(this->sas, sa, sa);
+	}
+	else
+	{
+		free(sa);
+		sa = found;
+	}
+	ref_get(&sa->refcount);
+	return sa;
+}
+
+/**
+ * Release and destroy an IPsec SA object
+ */
+static void ipsec_sa_destroy(private_ipsec_offload_ipsec_t *this,
+		ipsec_sa_t *sa)
+{
+	if (ref_put(&sa->refcount))
+	{
+		this->sas->remove(this->sas, sa);
+		DESTROY_IF(sa->src);
+		DESTROY_IF(sa->dst);
+		free(sa);
+	}
+}
+
+typedef struct policy_sa_t policy_sa_t;
+typedef struct policy_sa_out_t policy_sa_out_t;
+
+/**
+ * Mapping between a policy and an IPsec SA.
+ */
+struct policy_sa_t {
+	/** Priority assigned to the policy when installed with this SA */
+	uint32_t priority;
+
+	/** Automatic priority assigned to the policy when installed with this SA */
+	uint32_t auto_priority;
+
+	/** Type of the policy */
+	policy_type_t type;
+
+	/** Assigned SA */
+	ipsec_sa_t *sa;
+};
+
+/**
+ * For outbound policies we also cache the traffic selectors in order to install
+ * the route.
+ */
+struct policy_sa_out_t {
+	/** Generic interface */
+	policy_sa_t generic;
+
+	/** Source traffic selector of this policy */
+	traffic_selector_t *src_ts;
+
+	/** Destination traffic selector of this policy */
+	traffic_selector_t *dst_ts;
+};
+
+/**
+ * Create a policy_sa(_in)_t object
+ */
+static policy_sa_t *policy_sa_create(private_ipsec_offload_ipsec_t *this,
+		policy_dir_t dir, policy_type_t type, host_t *src, host_t *dst,
+		traffic_selector_t *src_ts, traffic_selector_t *dst_ts, mark_t mark,
+		uint32_t if_id, ipsec_sa_cfg_t *cfg)
+{
+	policy_sa_t *policy;
+
+	if (dir == POLICY_OUT)
+	{
+		policy_sa_out_t *out;
+		INIT(out,
+				.src_ts = src_ts->clone(src_ts),
+				.dst_ts = dst_ts->clone(dst_ts),
+		    );
+		policy = &out->generic;
+	}
+	else
+	{
+		INIT(policy, .priority = 0);
+	}
+	policy->type = type;
+	policy->sa = ipsec_sa_create(this, src, dst, mark, if_id, cfg);
+	return policy;
+}
+
+/**
+ * Destroy a policy_sa(_in)_t object
+ */
+static void policy_sa_destroy(policy_sa_t *policy, policy_dir_t dir,
+		private_ipsec_offload_ipsec_t *this)
+{
+	if (dir == POLICY_OUT)
+	{
+		policy_sa_out_t *out = (policy_sa_out_t*)policy;
+		out->src_ts->destroy(out->src_ts);
+		out->dst_ts->destroy(out->dst_ts);
+	}
+	ipsec_sa_destroy(this, policy->sa);
+	free(policy);
+}
+
+CALLBACK(policy_sa_destroy_cb, void,
+		policy_sa_t *policy, va_list args)
+{
+	private_ipsec_offload_ipsec_t *this;
+	policy_dir_t dir;
+
+	VA_ARGS_VGET(args, dir, this);
+	policy_sa_destroy(policy, dir, this);
+}
+
+typedef struct policy_entry_t policy_entry_t;
+
+/**
+ * Installed kernel policy.
+ */
+struct policy_entry_t {
+
+	/** Direction of this policy: in, out, forward */
+	uint8_t direction;
+
+	/** Parameters of installed policy */
+	struct xfrm_selector sel;
+
+	/** Optional mark */
+	uint32_t mark;
+
+	/** Optional interface ID */
+	uint32_t if_id;
+
+	/** Associated route installed for this policy */
+	route_entry_t *route;
+
+	/** List of SAs this policy is used by, ordered by priority */
+	linked_list_t *used_by;
+
+	/** reqid for this policy */
+	uint32_t reqid;
+
+	/** Number of threads waiting to work on this policy */
+	int waiting;
+
+	/** TRUE if a thread is working on this policy */
+	bool working;
+};
+
+/**
+ * Destroy a policy_entry_t object
+ */
+static void policy_entry_destroy(private_ipsec_offload_ipsec_t *this,
+		policy_entry_t *policy)
+{
+	if (policy->route)
+	{
+		route_entry_destroy(policy->route);
+	}
+	if (policy->used_by)
+	{
+		policy->used_by->invoke_function(policy->used_by, policy_sa_destroy_cb,
+				policy->direction, this);
+		policy->used_by->destroy(policy->used_by);
+	}
+	free(policy);
+}
+
+/**
+ * Hash function for policy_entry_t objects
+ */
+static u_int policy_hash(policy_entry_t *key)
+{
+	chunk_t chunk = chunk_from_thing(key->sel);
+	return chunk_hash_inc(chunk, chunk_hash_inc(chunk_from_thing(key->mark),
+				chunk_hash(chunk_from_thing(key->if_id))));
+}
+
+/**
+ * Equality function for policy_entry_t objects
+ */
+static bool policy_equals(policy_entry_t *key, policy_entry_t *other_key)
+{
+	return memeq(&key->sel, &other_key->sel, sizeof(struct xfrm_selector)) &&
+		key->mark == other_key->mark &&
+		key->if_id == other_key->if_id &&
+		key->direction == other_key->direction;
+}
+
+/**
+ * Determine number of set bits in 16 bit port mask
+ */
+static inline uint32_t port_mask_bits(uint16_t port_mask)
+{
+	uint32_t bits;
+	uint16_t bit_mask = 0x8000;
+
+	port_mask = ntohs(port_mask);
+
+	for (bits = 0; bits < 16; bits++)
+	{
+		if (!(port_mask & bit_mask))
+		{
+			break;
+		}
+		bit_mask >>= 1;
+	}
+	return bits;
+}
+
+/**
+ * Calculate the priority of a policy
+ *
+ * bits 0-0:  separate trap and regular policies (0..1) 1 bit
+ * bits 1-1:  restriction to network interface (0..1)   1 bit
+ * bits 2-7:  src + dst port mask bits (2 * 0..16)      6 bits
+ * bits 8-8:  restriction to protocol (0..1)            1 bit
+ * bits 9-17: src + dst network mask bits (2 * 0..128)  9 bits
+ *                                                     18 bits
+ *
+ * smallest value: 000000000 0 000000 0 0:       0, lowest priority = 200'000
+ * largest value : 100000000 1 100000 1 1: 131'459, highst priority =  68'541
+ */
+static uint32_t get_priority(policy_entry_t *policy, policy_priority_t prio,
+		char *interface)
+{
+	uint32_t priority = PRIO_BASE, sport_mask_bits, dport_mask_bits;
+
+	switch (prio)
+	{
+		case POLICY_PRIORITY_FALLBACK:
+			priority += PRIO_BASE;
+			/* fall-through to next case */
+		case POLICY_PRIORITY_ROUTED:
+		case POLICY_PRIORITY_DEFAULT:
+			priority += PRIO_BASE;
+			/* fall-through to next case */
+		case POLICY_PRIORITY_PASS:
+			break;
+	}
+	sport_mask_bits = port_mask_bits(policy->sel.sport_mask);
+	dport_mask_bits = port_mask_bits(policy->sel.dport_mask);
+
+	/* calculate priority */
+	priority -= (policy->sel.prefixlen_s + policy->sel.prefixlen_d) * 512;
+	priority -=  policy->sel.proto ? 256 : 0;
+	priority -= (sport_mask_bits + dport_mask_bits) * 4;
+	priority -= (interface != NULL) * 2;
+	priority -= (prio != POLICY_PRIORITY_ROUTED);
+
+	return priority;
+}
+
+/**
+ * Convert the general ipsec mode to the one defined in xfrm.h
+ */
+static uint8_t mode2kernel(ipsec_mode_t mode)
+{
+	switch (mode)
+	{
+		case MODE_TRANSPORT:
+			return XFRM_MODE_TRANSPORT;
+		case MODE_TUNNEL:
+			return XFRM_MODE_TUNNEL;
+		case MODE_BEET:
+			return XFRM_MODE_BEET;
+		default:
+			return mode;
+	}
+}
+
+/**
+ * Convert a host_t to a struct xfrm_address
+ */
+static void host2xfrm(host_t *host, xfrm_address_t *xfrm)
+{
+	chunk_t chunk = host->get_address(host);
+	memcpy(xfrm, chunk.ptr, min(chunk.len, sizeof(xfrm_address_t)));
+}
+
+/**
+ * Convert a struct xfrm_address to a host_t
+ */
+static host_t* xfrm2host(int family, xfrm_address_t *xfrm, uint16_t port)
+{
+	chunk_t chunk;
+
+	switch (family)
+	{
+		case AF_INET:
+			chunk = chunk_create((u_char*)&xfrm->a4, sizeof(xfrm->a4));
+			break;
+		case AF_INET6:
+			chunk = chunk_create((u_char*)&xfrm->a6, sizeof(xfrm->a6));
+			break;
+		default:
+			return NULL;
+	}
+	return host_create_from_chunk(family, chunk, ntohs(port));
+}
+
+/**
+ * Convert a traffic selector address range to subnet and its mask.
+ */
+static void ts2subnet(traffic_selector_t* ts,
+		xfrm_address_t *net, uint8_t *mask)
+{
+	host_t *net_host;
+	chunk_t net_chunk;
+
+	ts->to_subnet(ts, &net_host, mask);
+	net_chunk = net_host->get_address(net_host);
+	memcpy(net, net_chunk.ptr, net_chunk.len);
+	net_host->destroy(net_host);
+}
+
+/**
+ * Convert a traffic selector port range to port/portmask
+ */
+static void ts2ports(traffic_selector_t* ts,
+		uint16_t *port, uint16_t *mask)
+{
+	uint16_t from, to, bitmask;
+	int bit;
+
+	from = ts->get_from_port(ts);
+	to = ts->get_to_port(ts);
+
+	/* Quick check for a single port */
+	if (from == to)
+	{
+		*port = htons(from);
+		*mask = ~0;
+	}
+	else
+	{
+		/* Compute the port mask for port ranges */
+		*mask = 0;
+
+		for (bit = 15; bit >= 0; bit--)
+		{
+			bitmask = 1 << bit;
+
+			if ((bitmask & from) != (bitmask & to))
+			{
+				*port = htons(from & *mask);
+				*mask = htons(*mask);
+				return;
+			}
+			*mask |= bitmask;
+		}
+	}
+	return;
+}
+
+/**
+ * Convert a pair of traffic_selectors to an xfrm_selector
+ */
+static struct xfrm_selector ts2selector(traffic_selector_t *src,
+		traffic_selector_t *dst,
+		char *interface)
+{
+	struct xfrm_selector sel;
+	uint16_t port;
+
+	memset(&sel, 0, sizeof(sel));
+	sel.family = (src->get_type(src) == TS_IPV4_ADDR_RANGE) ? AF_INET : AF_INET6;
+	/* src or dest proto may be "any" (0), use more restrictive one */
+	sel.proto = max(src->get_protocol(src), dst->get_protocol(dst));
+	ts2subnet(dst, &sel.daddr, &sel.prefixlen_d);
+	ts2subnet(src, &sel.saddr, &sel.prefixlen_s);
+	ts2ports(dst, &sel.dport, &sel.dport_mask);
+	ts2ports(src, &sel.sport, &sel.sport_mask);
+	if ((sel.proto == IPPROTO_ICMP || sel.proto == IPPROTO_ICMPV6) &&
+			(sel.dport || sel.sport))
+	{
+		/* the kernel expects the ICMP type and code in the source and
+		 * destination port fields, respectively. */
+		port = ntohs(max(sel.dport, sel.sport));
+		sel.sport = htons(traffic_selector_icmp_type(port));
+		sel.sport_mask = sel.sport ? ~0 : 0;
+		sel.dport = htons(traffic_selector_icmp_code(port));
+		sel.dport_mask = sel.dport ? ~0 : 0;
+	}
+	sel.ifindex = interface ? if_nametoindex(interface) : 0;
+	sel.user = 0;
+
+	return sel;
+}
+
+/**
+ * Convert an xfrm_selector to a src|dst traffic_selector
+ */
+static traffic_selector_t* selector2ts(struct xfrm_selector *sel, bool src)
+{
+	u_char *addr;
+	uint8_t prefixlen;
+	uint16_t port = 0;
+	host_t *host = NULL;
+
+	if (src)
+	{
+		addr = (u_char*)&sel->saddr;
+		prefixlen = sel->prefixlen_s;
+		if (sel->sport_mask)
+		{
+			port = ntohs(sel->sport);
+		}
+	}
+	else
+	{
+		addr = (u_char*)&sel->daddr;
+		prefixlen = sel->prefixlen_d;
+		if (sel->dport_mask)
+		{
+			port = ntohs(sel->dport);
+		}
+	}
+	if (sel->proto == IPPROTO_ICMP || sel->proto == IPPROTO_ICMPV6)
+	{	/* convert ICMP[v6] message type and code as supplied by the kernel in
+		 * source and destination ports (both in network order) */
+		port = (sel->sport >> 8) | (sel->dport & 0xff00);
+		port = ntohs(port);
+	}
+	/* The Linux 2.6 kernel does not set the selector's family field,
+	 * so as a kludge we additionally test the prefix length.
+	 */
+	if (sel->family == AF_INET || sel->prefixlen_s == 32)
+	{
+		host = host_create_from_chunk(AF_INET, chunk_create(addr, 4), 0);
+	}
+	else if (sel->family == AF_INET6 || sel->prefixlen_s == 128)
+	{
+		host = host_create_from_chunk(AF_INET6, chunk_create(addr, 16), 0);
+	}
+
+	if (host)
+	{
+		return traffic_selector_create_from_subnet(host, prefixlen,
+				sel->proto, port, port ?: 65535);
+	}
+	return NULL;
+}
+
+/**
+ * Process a XFRM_MSG_ACQUIRE from kernel
+ */
+static void process_acquire(private_ipsec_offload_ipsec_t *this,
+		struct nlmsghdr *hdr)
+{
+	struct xfrm_user_acquire *acquire;
+	struct rtattr *rta;
+	size_t rtasize;
+	traffic_selector_t *src_ts, *dst_ts;
+	uint32_t reqid = 0;
+	int proto = 0;
+
+	acquire = NLMSG_DATA(hdr);
+	rta = XFRM_RTA(hdr, struct xfrm_user_acquire);
+	rtasize = XFRM_PAYLOAD(hdr, struct xfrm_user_acquire);
+
+	DBG2(DBG_KNL, "received a XFRM_MSG_ACQUIRE");
+
+	while (RTA_OK(rta, rtasize))
+	{
+		DBG2(DBG_KNL, "  %N", xfrm_attr_type_names, rta->rta_type);
+
+		if (rta->rta_type == XFRMA_TMPL)
+		{
+			struct xfrm_user_tmpl* tmpl;
+			tmpl = (struct xfrm_user_tmpl*)RTA_DATA(rta);
+			reqid = tmpl->reqid;
+			proto = tmpl->id.proto;
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+	switch (proto)
+	{
+		case 0:
+		case IPPROTO_ESP:
+		case IPPROTO_AH:
+			break;
+		default:
+			/* acquire for AH/ESP only, not for IPCOMP */
+			return;
+	}
+	src_ts = selector2ts(&acquire->sel, TRUE);
+	dst_ts = selector2ts(&acquire->sel, FALSE);
+
+	charon->kernel->acquire(charon->kernel, reqid, src_ts, dst_ts);
+}
+
+/**
+ * Process a XFRM_MSG_EXPIRE from kernel
+ */
+static void process_expire(private_ipsec_offload_ipsec_t *this,
+		struct nlmsghdr *hdr)
+{
+	struct xfrm_user_expire *expire;
+	uint32_t spi;
+	uint8_t protocol;
+	host_t *dst;
+
+	expire = NLMSG_DATA(hdr);
+	protocol = expire->state.id.proto;
+	spi = expire->state.id.spi;
+
+	DBG2(DBG_KNL, "received a XFRM_MSG_EXPIRE");
+
+	if (protocol == IPPROTO_ESP || protocol == IPPROTO_AH)
+	{
+		dst = xfrm2host(expire->state.family, &expire->state.id.daddr, 0);
+		if (dst)
+		{
+			charon->kernel->expire(charon->kernel, protocol, spi, dst,
+					expire->hard != 0);
+			dst->destroy(dst);
+		}
+	}
+}
+
+/**
+ * Process a XFRM_MSG_MIGRATE from kernel
+ */
+static void process_migrate(private_ipsec_offload_ipsec_t *this,
+		struct nlmsghdr *hdr)
+{
+	struct xfrm_userpolicy_id *policy_id;
+	struct rtattr *rta;
+	size_t rtasize;
+	traffic_selector_t *src_ts, *dst_ts;
+	host_t *local = NULL, *remote = NULL;
+	host_t *old_src = NULL, *old_dst = NULL;
+	host_t *new_src = NULL, *new_dst = NULL;
+	uint32_t reqid = 0;
+	policy_dir_t dir;
+
+	policy_id = NLMSG_DATA(hdr);
+	rta     = XFRM_RTA(hdr, struct xfrm_userpolicy_id);
+	rtasize = XFRM_PAYLOAD(hdr, struct xfrm_userpolicy_id);
+
+	DBG2(DBG_KNL, "received a XFRM_MSG_MIGRATE");
+
+	src_ts = selector2ts(&policy_id->sel, TRUE);
+	dst_ts = selector2ts(&policy_id->sel, FALSE);
+	dir = (policy_dir_t)policy_id->dir;
+
+	DBG2(DBG_KNL, "  policy: %R === %R %N", src_ts, dst_ts, policy_dir_names);
+
+	while (RTA_OK(rta, rtasize))
+	{
+		DBG2(DBG_KNL, "  %N", xfrm_attr_type_names, rta->rta_type);
+		if (rta->rta_type == XFRMA_KMADDRESS)
+		{
+			struct xfrm_user_kmaddress *kmaddress;
+
+			kmaddress = (struct xfrm_user_kmaddress*)RTA_DATA(rta);
+			local  = xfrm2host(kmaddress->family, &kmaddress->local, 0);
+			remote = xfrm2host(kmaddress->family, &kmaddress->remote, 0);
+			DBG2(DBG_KNL, "  kmaddress: %H...%H", local, remote);
+		}
+		else if (rta->rta_type == XFRMA_MIGRATE)
+		{
+			struct xfrm_user_migrate *migrate;
+
+			migrate = (struct xfrm_user_migrate*)RTA_DATA(rta);
+			old_src = xfrm2host(migrate->old_family, &migrate->old_saddr, 0);
+			old_dst = xfrm2host(migrate->old_family, &migrate->old_daddr, 0);
+			new_src = xfrm2host(migrate->new_family, &migrate->new_saddr, 0);
+			new_dst = xfrm2host(migrate->new_family, &migrate->new_daddr, 0);
+			reqid = migrate->reqid;
+			DBG2(DBG_KNL, "  migrate %H...%H to %H...%H, reqid {%u}",
+					old_src, old_dst, new_src, new_dst, reqid);
+			DESTROY_IF(old_src);
+			DESTROY_IF(old_dst);
+			DESTROY_IF(new_src);
+			DESTROY_IF(new_dst);
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+
+	if (src_ts && dst_ts && local && remote)
+	{
+		charon->kernel->migrate(charon->kernel, reqid, src_ts, dst_ts, dir,
+				local, remote);
+	}
+	else
+	{
+		DESTROY_IF(src_ts);
+		DESTROY_IF(dst_ts);
+		DESTROY_IF(local);
+		DESTROY_IF(remote);
+	}
+}
+
+/**
+ * Process a XFRM_MSG_MAPPING from kernel
+ */
+static void process_mapping(private_ipsec_offload_ipsec_t *this,
+		struct nlmsghdr *hdr)
+{
+	struct xfrm_user_mapping *mapping;
+	uint32_t spi;
+
+	mapping = NLMSG_DATA(hdr);
+	spi = mapping->id.spi;
+
+	DBG2(DBG_KNL, "received a XFRM_MSG_MAPPING");
+
+	if (mapping->id.proto == IPPROTO_ESP)
+	{
+		host_t *dst, *new;
+
+		dst = xfrm2host(mapping->id.family, &mapping->id.daddr, 0);
+		if (dst)
+		{
+			new = xfrm2host(mapping->id.family, &mapping->new_saddr,
+					mapping->new_sport);
+			if (new)
+			{
+				charon->kernel->mapping(charon->kernel, IPPROTO_ESP, spi, dst,
+						new);
+				new->destroy(new);
+			}
+			dst->destroy(dst);
+		}
+	}
+}
+
+/**
+ * Receives events from kernel
+ */
+static bool receive_events(private_ipsec_offload_ipsec_t *this, int fd,
+		watcher_event_t event)
+{
+	char response[netlink_get_buflen()];
+	struct nlmsghdr *hdr = (struct nlmsghdr*)response;
+	struct sockaddr_nl addr;
+	socklen_t addr_len = sizeof(addr);
+	int len;
+
+	len = recvfrom(this->socket_xfrm_events, response, sizeof(response),
+			MSG_DONTWAIT, (struct sockaddr*)&addr, &addr_len);
+	if (len < 0)
+	{
+		switch (errno)
+		{
+			case EINTR:
+				/* interrupted, try again */
+				return TRUE;
+			case EAGAIN:
+				/* no data ready, select again */
+				return TRUE;
+			default:
+				DBG1(DBG_KNL, "unable to receive from XFRM event socket: %s "
+						"(%d)", strerror(errno), errno);
+				sleep(1);
+				return TRUE;
+		}
+	}
+
+	if (addr.nl_pid != 0)
+	{	/* not from kernel. not interested, try another one */
+		return TRUE;
+	}
+
+	while (NLMSG_OK(hdr, len))
+	{
+		switch (hdr->nlmsg_type)
+		{
+			case XFRM_MSG_ACQUIRE:
+				process_acquire(this, hdr);
+				break;
+			case XFRM_MSG_EXPIRE:
+				process_expire(this, hdr);
+				break;
+			case XFRM_MSG_MIGRATE:
+				process_migrate(this, hdr);
+				break;
+			case XFRM_MSG_MAPPING:
+				process_mapping(this, hdr);
+				break;
+			default:
+				DBG1(DBG_KNL, "received unknown event from XFRM event "
+						"socket: %d", hdr->nlmsg_type);
+				break;
+		}
+		hdr = NLMSG_NEXT(hdr, len);
+	}
+	return TRUE;
+}
+
+METHOD(kernel_ipsec_t, get_features, kernel_feature_t,
+		private_ipsec_offload_ipsec_t *this)
+{
+	return KERNEL_ESP_V3_TFC | KERNEL_POLICY_SPI;
+}
+
+/**
+ * Get an SPI for a specific protocol from the kernel.
+ */
+static status_t get_spi_internal(private_ipsec_offload_ipsec_t *this,
+		host_t *src, host_t *dst, uint8_t proto, uint32_t min, uint32_t max,
+		uint32_t *spi)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out;
+	struct xfrm_userspi_info *userspi;
+	uint32_t received_spi = 0;
+	size_t len;
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_ALLOCSPI;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userspi_info));
+
+	userspi = NLMSG_DATA(hdr);
+	host2xfrm(src, &userspi->info.saddr);
+	host2xfrm(dst, &userspi->info.id.daddr);
+	userspi->info.id.proto = proto;
+	userspi->info.mode = XFRM_MODE_TUNNEL;
+	userspi->info.family = src->get_family(src);
+	userspi->min = min;
+	userspi->max = max;
+
+	DBG2(DBG_KNL,"hello########## %s, %s , %d #############\n",__FILE__, __func__, __LINE__);
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWSA:
+					{
+						struct xfrm_usersa_info* usersa = NLMSG_DATA(hdr);
+						received_spi = usersa->id.spi;
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+						DBG1(DBG_KNL, "allocating SPI failed: %s (%d)",
+								strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+		free(out);
+	}
+
+	if (received_spi == 0)
+	{
+		return FAILED;
+	}
+
+	*spi = received_spi;
+	return SUCCESS;
+}
+
+METHOD(kernel_ipsec_t, get_spi, status_t,
+		private_ipsec_offload_ipsec_t *this, host_t *src, host_t *dst,
+		uint8_t protocol, uint32_t *spi)
+{
+	uint32_t spi_min, spi_max;
+
+	spi_min = lib->settings->get_int(lib->settings, "%s.spi_min",
+			KERNEL_SPI_MIN, lib->ns);
+	spi_max = lib->settings->get_int(lib->settings, "%s.spi_max",
+			KERNEL_SPI_MAX, lib->ns);
+
+	if (get_spi_internal(this, src, dst, protocol, min(spi_min, spi_max),
+				max(spi_min, spi_max), spi) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to get SPI");
+		return FAILED;
+	}
+
+	DBG2(DBG_KNL, "got SPI %.8x", ntohl(*spi));
+	return SUCCESS;
+}
+
+METHOD(kernel_ipsec_t, get_cpi, status_t,
+		private_ipsec_offload_ipsec_t *this, host_t *src, host_t *dst,
+		uint16_t *cpi)
+{
+	uint32_t received_spi = 0;
+
+	if (get_spi_internal(this, src, dst, IPPROTO_COMP,
+				0x100, 0xEFFF, &received_spi) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to get CPI");
+		return FAILED;
+	}
+
+	*cpi = htons((uint16_t)ntohl(received_spi));
+
+	DBG2(DBG_KNL, "got CPI %.4x", ntohs(*cpi));
+	return SUCCESS;
+}
+
+/**
+ * Format the mark for debug messages
+ */
+static void format_mark(char *buf, int buflen, mark_t mark)
+{
+	if (mark.value | mark.mask)
+	{
+		snprintf(buf, buflen, " (mark %u/0x%08x)", mark.value, mark.mask);
+	}
+}
+
+/**
+ * Add a XFRM mark to message if required
+ */
+static bool add_mark(struct nlmsghdr *hdr, int buflen, mark_t mark)
+{
+	if (mark.value | mark.mask)
+	{
+		struct xfrm_mark *xmrk;
+
+		xmrk = netlink_reserve(hdr, buflen, XFRMA_MARK, sizeof(*xmrk));
+		if (!xmrk)
+		{
+			return FALSE;
+		}
+		xmrk->v = mark.value;
+		xmrk->m = mark.mask;
+	}
+	return TRUE;
+}
+
+/**
+ * Add a uint32 attribute to message
+ */
+static bool add_uint32(struct nlmsghdr *hdr, int buflen,
+		enum xfrm_attr_type_t type, uint32_t value)
+{
+	uint32_t *xvalue;
+
+	xvalue = netlink_reserve(hdr, buflen, type, sizeof(*xvalue));
+	if (!xvalue)
+	{
+		return FALSE;
+	}
+	*xvalue = value;
+	return TRUE;
+}
+
+/* ETHTOOL_GSSET_INFO is available since 2.6.34 and ETH_SS_FEATURES (enum) and
+ * ETHTOOL_GFEATURES since 2.6.39, so check for the latter */
+#ifdef ETHTOOL_GFEATURES
+
+/**
+ * Global metadata used for IPsec HW offload
+ */
+static struct {
+	/** determined HW offload support */
+	bool supported;
+	/** bit in feature set */
+	u_int bit;
+	/** total number of device feature blocks */
+	u_int total_blocks;
+} netlink_hw_offload;
+
+/**
+ * Check if kernel supports HW offload and determine feature flag
+ */
+static void netlink_find_offload_feature(const char *ifname)
+{
+	struct ethtool_sset_info *sset_info;
+	struct ethtool_gstrings *cmd = NULL;
+	struct ifreq ifr;
+	uint32_t sset_len, i;
+	char *str;
+	int err, query_socket;
+
+	query_socket = socket(AF_NETLINK, SOCK_DGRAM, NETLINK_XFRM);
+	if (query_socket < 0)
+	{
+		return;
+	}
+
+	/* determine number of device features */
+	INIT_EXTRA(sset_info, sizeof(uint32_t),
+			.cmd = ETHTOOL_GSSET_INFO,
+			.sset_mask = 1ULL << ETH_SS_FEATURES,
+		  );
+	strncpy(ifr.ifr_name, ifname, IFNAMSIZ);
+	ifr.ifr_name[IFNAMSIZ-1] = '\0';
+	ifr.ifr_data = (void*)sset_info;
+
+	err = ioctl(query_socket, SIOCETHTOOL, &ifr);
+	if (err || sset_info->sset_mask != 1ULL << ETH_SS_FEATURES)
+	{
+		goto out;
+	}
+	sset_len = sset_info->data[0];
+
+	/* retrieve names of device features */
+	INIT_EXTRA(cmd, ETH_GSTRING_LEN * sset_len,
+			.cmd = ETHTOOL_GSTRINGS,
+			.string_set = ETH_SS_FEATURES,
+		  );
+	strncpy(ifr.ifr_name, ifname, IFNAMSIZ);
+	ifr.ifr_name[IFNAMSIZ-1] = '\0';
+	ifr.ifr_data = (void*)cmd;
+
+	err = ioctl(query_socket, SIOCETHTOOL, &ifr);
+	if (err)
+	{
+		goto out;
+	}
+
+	/* look for the ESP_HW feature bit */
+	str = (char*)cmd->data;
+	for (i = 0; i < cmd->len; i++)
+	{
+		if (strneq(str, "esp-hw-offload", ETH_GSTRING_LEN))
+		{
+			netlink_hw_offload.supported = TRUE;
+			netlink_hw_offload.bit = i;
+			netlink_hw_offload.total_blocks = (sset_len + 31) / 32;
+			break;
+		}
+		str += ETH_GSTRING_LEN;
+	}
+
+out:
+	free(sset_info);
+	free(cmd);
+	close(query_socket);
+}
+
+/**
+ * Check if interface supported HW offload
+ */
+static bool netlink_detect_offload(const char *ifname)
+{
+	struct ethtool_gfeatures *cmd;
+	uint32_t feature_bit;
+	struct ifreq ifr;
+	int query_socket;
+	int block;
+	bool ret = FALSE;
+
+	if (!netlink_hw_offload.supported)
+	{
+		DBG1(DBG_KNL, "HW offload is not supported by kernel");
+		return FALSE;
+	}
+
+	query_socket = socket(AF_NETLINK, SOCK_DGRAM, NETLINK_XFRM);
+	if (query_socket < 0)
+	{
+		return FALSE;
+	}
+
+	/* feature is supported by kernel, query device features */
+	INIT_EXTRA(cmd, sizeof(cmd->features[0]) * netlink_hw_offload.total_blocks,
+			.cmd = ETHTOOL_GFEATURES,
+			.size = netlink_hw_offload.total_blocks,
+		  );
+	strncpy(ifr.ifr_name, ifname, IFNAMSIZ);
+	ifr.ifr_name[IFNAMSIZ-1] = '\0';
+	ifr.ifr_data = (void*)cmd;
+
+	if (!ioctl(query_socket, SIOCETHTOOL, &ifr))
+	{
+		block = netlink_hw_offload.bit / 32;
+		feature_bit = 1U << (netlink_hw_offload.bit % 32);
+		if (cmd->features[block].active & feature_bit)
+		{
+			ret = TRUE;
+		}
+	}
+
+	if (!ret)
+	{
+		DBG1(DBG_KNL, "HW offload is not supported by device");
+	}
+	free(cmd);
+	close(query_socket);
+	return ret;
+}
+
+#else
+
+static void netlink_find_offload_feature(const char *ifname)
+{
+}
+
+static bool netlink_detect_offload(const char *ifname)
+{
+	return FALSE;
+}
+
+#endif
+
+/**
+ * There are 3 HW offload configuration values:
+ * 1. HW_OFFLOAD_NO   : Do not configure HW offload.
+ * 2. HW_OFFLOAD_YES  : Configure HW offload.
+ *                      Fail SA addition if offload is not supported.
+ * 3. HW_OFFLOAD_AUTO : Configure HW offload if supported by the kernel
+ *                      and device.
+ *                      Do not fail SA addition otherwise.
+ */
+static bool config_hw_offload(kernel_ipsec_sa_id_t *id,
+		kernel_ipsec_add_sa_t *data, struct nlmsghdr *hdr,
+		int buflen)
+{
+	host_t *local = data->inbound ? id->dst : id->src;
+	struct xfrm_user_offload *offload;
+	bool hw_offload_yes, ret = FALSE;
+	char *ifname;
+
+	/* do Ipsec configuration without offload */
+	if (data->hw_offload == HW_OFFLOAD_NO)
+	{
+		return TRUE;
+	}
+
+	hw_offload_yes = (data->hw_offload == HW_OFFLOAD_YES);
+
+	if (!charon->kernel->get_interface(charon->kernel, local, &ifname))
+	{
+		return !hw_offload_yes;
+	}
+
+	/* check if interface supports hw_offload */
+	if (!netlink_detect_offload(ifname))
+	{
+		ret = !hw_offload_yes;
+		goto out;
+	}
+
+	/* activate HW offload */
+	offload = netlink_reserve(hdr, buflen,
+			XFRMA_OFFLOAD_DEV, sizeof(*offload));
+	if (!offload)
+	{
+		ret = !hw_offload_yes;
+		goto out;
+	}
+	offload->ifindex = if_nametoindex(ifname);
+	if (local->get_family(local) == AF_INET6)
+	{
+		offload->flags |= XFRM_OFFLOAD_IPV6;
+	}
+	offload->flags |= data->inbound ? XFRM_OFFLOAD_INBOUND : 0;
+
+	ret = TRUE;
+
+out:
+	free(ifname);
+	return ret;
+}
+void ipsec_offload_add_policy(policy_dir_t *flow,traffic_selector_t* sc, traffic_selector_t* dc, uint32_t *reqid, policy_type_t *type, uint8_t *sel){	
+	int socket_descriptor = -1;
+	struct ifreq ifr;
+	socket_descriptor = socket(AF_INET, SOCK_DGRAM, 0);
+	if (socket_descriptor < 0)
+	{
+		DBG1(DBG_KNL, "######### socket_descriptor failed ##########\n");
+	}
+	memset(&ifr, 0, sizeof(struct ifreq));
+
+	if (*flow == ENC) {
+
+		/************FLILLING SPD*************/
+		ipsec_offload_get_sc_policy(&sa_enc.ipsec_offload_sc, sc);
+		ipsec_offload_get_dc_policy(&sa_enc.ipsec_offload_dc, dc);
+		ipsec_offload_get_protocol(&sa_enc.ipsec_offload_protocol, sel);
+		ipsec_offload_get_action_flag(&sa_enc.ipsec_offload_action_flag, type);
+		char * ifname = find_ifname(&head_ifname, sa_enc.ipsec_offload_spi);
+		if (ifname != 0) {
+
+			strcpy(ifr.ifr_name, ifname);
+
+			if ((sa_enc.ipsec_offload_protocol == 0x2f)&&(sa_enc.ipsec_offload_iiv != 0x00)){
+				uint32_t temp_spi = 0x00;
+				temp_spi = find_add_sa_enc(&head_add_sa_enc, sa_enc.ipsec_offload_sc, sa_enc.ipsec_offload_dc);
+				if(temp_spi == 0x00){
+					ifr.ifr_data = (char*) &sa_enc;
+					if (ioctl(socket_descriptor, IPSEC_OFFLOAD_ADD_SA_ENC, &ifr) != -1)
+					{
+						DBG2(DBG_KNL, "######### ioctl success-ADD SA ENC ##########\n");
+					}
+					else {
+						DBG2(DBG_KNL, "######### ioctl failed -ADD SA ENC ########## errno:%d   err:%s\n", 
+								errno, strerror(errno));
+					}
+					append_add_sa_enc(&head_add_sa_enc, sa_enc.ipsec_offload_sc, sa_enc.ipsec_offload_dc, 
+							sa_enc.ipsec_offload_spi);
+				} else{
+					temp_spi = ntohl(temp_spi);
+					uint32_t temp_sc = 0x00;
+					uint32_t temp_dt = 0x00;
+					temp_sc = ntohl(sa_enc.ipsec_offload_sc);
+					temp_dt = ntohl(sa_enc.ipsec_offload_dc);
+					ipsec_offload_del_sa((xfrm_address_t *)&temp_sc, (xfrm_address_t *) &temp_dt, &temp_spi);
+					ifr.ifr_data = (char*) &sa_enc;
+					if (ioctl(socket_descriptor, IPSEC_OFFLOAD_ADD_SA_ENC, &ifr) != -1)
+					{
+						DBG2(DBG_KNL, "######### ioctl success-ADD SA ENC ##########\n");
+					}
+					else {
+						DBG2(DBG_KNL, "######### ioctl failed -ADD SA ENC ########## errno:%d   err:%s\n", 
+							errno, strerror(errno));
+					}
+					append_add_sa_enc(&head_add_sa_enc, sa_enc.ipsec_offload_sc, sa_enc.ipsec_offload_dc, 
+							sa_enc.ipsec_offload_spi);
+				}
+			}
+		} 
+		close(socket_descriptor);
+
+			}
+	return ;
+}
+int ipsec_offload_add_sa(int flow, chunk_t *key, uint32_t* spi, xfrm_address_t *sc, xfrm_address_t *dc, uint32_t *reqid, const char *ifname)
+{
+
+	int socket_descriptor = -1;
+	struct ifreq ifr;
+	ipsec_offload_add_sa_dec offload_add_sa_dec;
+	socket_descriptor = socket(AF_INET, SOCK_DGRAM, 0);
+	if (socket_descriptor < 0)
+	{
+		DBG1(DBG_KNL, "######### socket_descriptor failed ##########\n");
+	}
+	memset(&ifr, 0, sizeof(struct ifreq));
+	strcpy(ifr.ifr_name, ifname);
+
+	if (flow == ENC) {
+
+
+		/***********FILLING SA-ENC***************/
+
+		ipsec_offload_get_key(sa_enc.ipsec_offload_key, key);
+		ipsec_offload_get_iiv(&sa_enc.ipsec_offload_iiv, key);
+		ipsec_offload_get_spi(&sa_enc.ipsec_offload_spi , spi);
+		ipsec_offload_get_eiv(&sa_enc.ipsec_offload_eiv);
+		append_ifname(&head_ifname, sa_enc.ipsec_offload_spi, ifname);
+		close(socket_descriptor);
+
+	}
+	if (flow == DEC){
+		/*********************FILLING SA-DEC***************/
+		ipsec_offload_get_sc(&offload_add_sa_dec.ipsec_offload_sc, sc);
+		ipsec_offload_get_dc(&offload_add_sa_dec.ipsec_offload_dc, dc);	
+		ipsec_offload_get_spi(&offload_add_sa_dec.ipsec_offload_spi , spi);
+		ipsec_offload_get_key(offload_add_sa_dec.ipsec_offload_key, key);
+		ipsec_offload_get_iiv(&offload_add_sa_dec.ipsec_offload_iiv, key);
+		append(&head, offload_add_sa_dec.ipsec_offload_spi);
+		append_ifname(&head_ifname, offload_add_sa_dec.ipsec_offload_spi, ifname);
+		printlist_ifname(head_ifname);
+		uint32_t temp_spi = 0x00;
+		temp_spi = find_add_sa_enc(&head_add_sa_enc, offload_add_sa_dec.ipsec_offload_sc, offload_add_sa_dec.ipsec_offload_dc);
+		if(temp_spi == 0x00){
+			ifr.ifr_data = (char*) &offload_add_sa_dec;
+			if (ioctl(socket_descriptor, IPSEC_OFFLOAD_ADD_SA_DEC, &ifr) != -1)
+			{
+				DBG2(DBG_KNL, "######### ioctl success-ADD SA DEC ##########\n");
+			}
+			else {
+				DBG2(DBG_KNL, "######### ioctl failed -ADD SA-DEC ########## errno:%d   err:%s\n", errno, strerror(errno));
+			}
+			append_add_sa_enc(&head_add_sa_enc, offload_add_sa_dec.ipsec_offload_sc, offload_add_sa_dec.ipsec_offload_dc, 
+					offload_add_sa_dec.ipsec_offload_spi);
+			close(socket_descriptor);
+		}
+		else{
+			temp_spi = ntohl(temp_spi);
+			ipsec_offload_del_sa(sc, dc, &temp_spi);
+			ifr.ifr_data = (char*) &offload_add_sa_dec;
+			if (ioctl(socket_descriptor, IPSEC_OFFLOAD_ADD_SA_DEC, &ifr) != -1)
+			{
+				DBG2(DBG_KNL, "######### ioctl success-ADD SA DEC ##########\n");
+			}
+			else {
+				DBG2(DBG_KNL, "######### ioctl failed -ADD SA-DEC ########## errno:%d   err:%s\n", errno, strerror(errno));
+			}
+			append_add_sa_enc(&head_add_sa_enc, offload_add_sa_dec.ipsec_offload_sc, offload_add_sa_dec.ipsec_offload_dc, 
+					offload_add_sa_dec.ipsec_offload_spi);
+
+			close(socket_descriptor);
+		}
+
+	}
+
+	return 0;
+}
+
+int ipsec_offload_del_sa( xfrm_address_t *sc, xfrm_address_t *dc, uint32_t *spi)
+{
+
+
+	ipsec_offload_del_sa_dec offload_del_sa_dec;
+	ipsec_offload_del_sa_enc offload_del_sa_enc;
+	char * ifname = find_ifname(&head_ifname,ntohl( *spi));
+	if (ifname != 0) {
+		int socket_descriptor = -1;
+		struct ifreq ifr;
+		socket_descriptor = socket(AF_INET, SOCK_DGRAM, 0);
+		if (socket_descriptor < 0)
+		{
+			DBG1(DBG_KNL, "######### socket_descriptor failed ##########\n");
+		}
+		memset(&ifr, 0, sizeof(struct ifreq));
+		strcpy(ifr.ifr_name, ifname);
+
+
+		int ret_find = find(&head,ntohl( *spi));
+		if (ret_find == 1) {
+			ipsec_offload_get_sc(&offload_del_sa_dec.ipsec_offload_sc, sc);
+			ipsec_offload_get_dc(&offload_del_sa_dec.ipsec_offload_dc, dc);
+			ipsec_offload_get_spi(&offload_del_sa_dec.ipsec_offload_spi , spi);
+			ifr.ifr_data = (char*) &offload_del_sa_dec;
+			if (ioctl(socket_descriptor, IPSEC_OFFLOAD_DEL_SA_DEC, &ifr) != -1)
+			{
+				DBG2(DBG_KNL, "######### ioctl success-DEL SA DEC ##########\n");
+			}
+			else {
+				DBG2(DBG_KNL, "######### ioctl failed -DEL SA DEC ########## errno:%d   err:%s\n", errno, strerror(errno));
+			}
+			int ret_del = delete(&head,offload_del_sa_dec.ipsec_offload_spi);
+			if (ret_del == 1)
+				DBG2(DBG_KNL,"DELETE SUCESS IN LINKED LIST of decryption\n");
+			printlist(head);
+			int ret_del_ifname = delete_ifname(&head_ifname,ntohl(*spi));
+			if (ret_del_ifname)
+				DBG2(DBG_KNL,"DELETE SUCESS IN LINKED LIST in ifname\n");
+
+			printlist_ifname(head_ifname);
+			int ret_del_add_sa_enc = delete_add_sa_enc(&head_add_sa_enc, offload_del_sa_dec.ipsec_offload_sc, 
+					offload_del_sa_dec.ipsec_offload_dc);
+
+			DBG1(DBG_KNL,"ret_del_add_sa_enc = %d\n",ret_del_add_sa_enc);
+		}
+		else {
+
+
+			offload_del_sa_enc.ipsec_offload_protocol = 0x2f;
+			ipsec_offload_get_sc(&offload_del_sa_enc.ipsec_offload_sc, sc);
+			ipsec_offload_get_dc(&offload_del_sa_enc.ipsec_offload_dc, dc);
+			ipsec_offload_get_spi(&offload_del_sa_enc.ipsec_offload_spi , spi);
+
+			int ret_del_add_sa_enc = delete_add_sa_enc(&head_add_sa_enc, offload_del_sa_enc.ipsec_offload_sc, 
+					offload_del_sa_enc.ipsec_offload_dc);
+			ifr.ifr_data = (char*) &offload_del_sa_enc;
+			if (ioctl(socket_descriptor, IPSEC_OFFLOAD_DEL_POLICY, &ifr) != -1)
+			{
+				DBG2(DBG_KNL, "######### ioctl success-DEL SA enc ##########\n");
+			}
+			else {
+				DBG2(DBG_KNL, "######### ioctl failed -DEL SA enc ########## errno:%d   err:%s\n", errno, strerror(errno));
+			}
+
+			DBG1(DBG_KNL,"ret_del_add_sa_enc = %d\n",ret_del_add_sa_enc);
+
+			int ret_del_ifname = delete_ifname(&head_ifname,ntohl(*spi));
+			if (ret_del_ifname)
+				DBG2(DBG_KNL,"DELETE SUCESS IN LINKED LIST in ifname\n");
+
+		}
+		int ret_del_ifname = delete_ifname(&head_ifname,ntohl(*spi));
+		if (ret_del_ifname)
+			DBG2(DBG_KNL,"DELETE SUCESS IN LINKED LIST in ifname\n");
+
+
+	}
+
+	return 0;
+
+
+}
+struct ipsec_offload_query_sa ipsec_offload_query_sa_fun(uint32_t *spi ) {
+	struct ipsec_offload_query_sa query_sa;
+	query_sa.ipsec_offload_spi = (uint32_t) ntohl(*spi);
+	char * ifname = find_ifname(&head_ifname, query_sa.ipsec_offload_spi);
+	if (ifname != 0) {
+		int socket_descriptor = -1;
+		struct ifreq ifr;
+		socket_descriptor = socket(AF_INET, SOCK_DGRAM, 0);
+		if (socket_descriptor < 0)
+		{
+			DBG2(DBG_KNL, "######### socket_descriptor failed ##########\n");
+		}
+		memset(&ifr, 0, sizeof(struct ifreq));
+		strcpy(ifr.ifr_name, ifname);
+		ifr.ifr_data = (char *) &query_sa;
+		if (ioctl(socket_descriptor, IPSEC_OFFLOAD_QUERY_SA, &ifr) != -1)
+		{
+			DBG2(DBG_KNL, "######### ioctl success-Query sa ##########\n");
+
+		}
+		else {
+			DBG2(DBG_KNL, "######### ioctl failed -Query sa ########## errno:%d   err:%s\n", errno, strerror(errno));
+		}
+
+		close(socket_descriptor);
+	}
+	return query_sa;
+
+}
+
+void ipsec_offload_get_spi(uint32_t * ipsec_offload_spi , uint32_t * spi){
+
+	*ipsec_offload_spi = ntohl(*spi);
+	return; 
+}
+void ipsec_offload_get_sc_policy(uint32_t *ipsec_offload_sc ,  traffic_selector_t * sc )
+{
+	char srcip[32];
+	struct sockaddr_in sa;
+	uint32_t addr_src;
+	snprintf(srcip, sizeof(srcip), "%R", sc);
+	strtok(srcip, "/");
+	inet_pton(AF_INET, srcip, &(sa.sin_addr));
+	addr_src = ntohl(sa.sin_addr.s_addr);
+	*ipsec_offload_sc = addr_src;
+	return ;
+}
+void ipsec_offload_get_dc_policy(uint32_t *ipsec_offload_dc ,  traffic_selector_t * dc )
+{
+	char dstip[32];
+	struct sockaddr_in sa;
+	uint32_t addr_dst;
+	snprintf(dstip, sizeof(dstip), "%R", dc);
+	strtok(dstip, "/");
+	inet_pton(AF_INET, dstip, &(sa.sin_addr));
+	addr_dst = ntohl(sa.sin_addr.s_addr);
+	*ipsec_offload_dc = addr_dst;
+	return ;
+}
+void ipsec_offload_get_sc(uint32_t * ipsec_offload_sc , xfrm_address_t* sc)
+{
+	char srcip[32];
+	char *token_sc;
+	uint32_t source;
+	snprintf(srcip, sizeof(srcip), "%u/%08x", *(sc));
+	token_sc = strtok(srcip, "/");
+	token_sc = strtok(NULL,"/");
+	source = (uint32_t)strtol(token_sc, NULL, 16);;
+	*ipsec_offload_sc = ntohl(source);
+	return ;
+}
+
+void ipsec_offload_get_dc(uint32_t * ipsec_offload_dc, xfrm_address_t* dc)
+{
+	char dstip[32];
+	char *token_dc;
+	uint32_t destination;
+	snprintf(dstip, sizeof(dstip), "%u/%08x",*(dc));
+	token_dc = strtok(dstip, "/");
+	token_dc = strtok(NULL,"/");
+	destination = (uint32_t)strtol(token_dc, NULL, 16);;
+	*ipsec_offload_dc = ntohl(destination);
+	return ;
+}
+
+void ipsec_offload_get_eiv(uint64_t *eiv)
+{
+	unsigned char iv[8];
+	int k;
+	srand(time(NULL));
+	for (int i = 0; i <8; i++){
+		k = rand()%256;
+		iv[i] = (char)k;
+	}
+	char *pt;
+	pt = (char*)&iv;
+	*eiv = * (uint64_t *) pt;
+	return ;
+}
+
+void ipsec_offload_get_protocol(uint8_t *protocol, uint8_t *sel)
+{
+
+	*protocol = *(uint8_t*)sel;
+	return ;
+
+}
+void ipsec_offload_get_action_flag(uint8_t *flag, policy_type_t *type)
+{
+	*flag = 0x1;
+	return ;
+
+}
+
+void ipsec_offload_get_iiv(uint32_t *ipsec_offload_iiv, chunk_t *enc_iiv) {
+
+	uint32_t iiv_parse = * (uint32_t *) ((enc_iiv->ptr + 32));
+	*ipsec_offload_iiv = ntohl(iiv_parse);
+	return ;
+}
+void ipsec_offload_get_key(uint8_t *ipsec_offload_key, chunk_t *enc_key) {
+
+	for (int i = 0 ; i < 32 ; i++){
+		ipsec_offload_key[i] =  *(enc_key->ptr + i );
+	}
+	return ;
+}
+
+
+void printlist(struct Node * n)
+{
+	while(n!=NULL) {
+//		DBG1(DBG_KNL,"data in linked list=%x\n", n->data);
+		n = n->next;
+
+	}
+}
+void printlist_ifname(struct Node_ifname * n)
+{
+	while(n!=NULL) {
+//		DBG1(DBG_KNL,"spi=%x\n",n->spi);
+//		DBG1(DBG_KNL,"interface=%s\n",n->ifname);
+		n = n->next_ifname;
+
+	}
+}
+void printlist_add_sa_enc(struct Node_add_sa_enc * n)
+{
+	while(n!=NULL) {
+//		DBG1(DBG_KNL,"src=%x\n",n->src);
+//		DBG1(DBG_KNL,"dst=%x\n",n->dst);
+//		DBG1(DBG_KNL,"spi=%x\n",n->spi);
+		n = n->next_add_sa_enc;
+
+	}
+}
+
+void append(struct Node** head_ref, uint32_t new_data)
+{
+	struct Node* new_node = (struct Node*) malloc(sizeof(struct Node));
+
+	struct Node *last = *head_ref;
+	new_node->data  = new_data;
+
+	new_node->next = NULL;
+
+		if (*head_ref == NULL)
+	{
+		*head_ref = new_node;
+		return;
+	}
+
+	while (last->next != NULL)
+		last = last->next;
+
+	last->next = new_node;
+	return;
+}
+void append_ifname(struct Node_ifname** head_ref, uint32_t spi, const char *ifname)
+{
+	struct Node_ifname* new_node = (struct Node_ifname*) malloc(sizeof(struct Node_ifname));
+
+	struct Node_ifname *last = *head_ref;  
+	new_node->spi  = spi;
+	strcpy(new_node->ifname, ifname);
+
+	new_node->next_ifname = NULL;
+
+	if (*head_ref == NULL)
+	{
+		*head_ref = new_node;
+		return;
+	}
+
+	while (last->next_ifname != NULL)
+		last = last->next_ifname;
+
+	last->next_ifname = new_node;
+	return;
+}
+void append_add_sa_enc(struct Node_add_sa_enc** head_ref, uint32_t src, uint32_t dst, uint32_t spi)
+{
+	struct Node_add_sa_enc* new_node = (struct Node_add_sa_enc*) malloc(sizeof(struct Node_add_sa_enc));
+
+	struct Node_add_sa_enc *last = *head_ref;  
+	new_node->src  = src;
+	new_node->dst  = dst;
+	new_node->spi  = spi;
+	new_node->next_add_sa_enc = NULL;
+	if (*head_ref == NULL)
+	{
+		*head_ref = new_node;
+		return;
+	}
+
+	while (last->next_add_sa_enc != NULL)
+		last = last->next_add_sa_enc;
+
+	last->next_add_sa_enc = new_node;
+	return;
+}
+
+int find(struct Node** head_ref, uint32_t data )
+{
+	struct Node *current = (struct Node*) malloc(sizeof(struct Node));
+	current=*head_ref;
+
+	if (*head_ref == NULL) {
+		return 0;
+	}
+	while(current->data != data) {
+		if(current->next==NULL) {
+			return 0;
+
+		}
+		current = current->next;
+	}
+
+	return 1;
+
+}
+
+char * find_ifname(struct Node_ifname** head_ref, uint32_t data )
+{
+	struct Node_ifname *current = (struct Node_ifname*) malloc(sizeof(struct Node_ifname));
+	current=*head_ref;
+
+	if (*head_ref == NULL) {
+		return 0;
+	}
+	while(current->spi != data) {
+		if(current->next_ifname==NULL) {
+			return 0;
+
+		}
+		current = current->next_ifname;
+	}
+	return (char *) current->ifname;
+
+}
+uint32_t find_add_sa_enc(struct Node_add_sa_enc** head_ref, uint32_t src, uint32_t dst)
+{
+	struct Node_add_sa_enc *current = (struct Node_add_sa_enc*) malloc(sizeof(struct Node_add_sa_enc));
+	current=*head_ref;
+
+	if (*head_ref == NULL) {
+		return 0;
+	}
+	while(current->src!=src && current->dst!=dst)
+	{
+		if(current->next_add_sa_enc==NULL) {
+			return 0;
+
+		}
+		current = current->next_add_sa_enc;
+	}
+	return current->spi;
+}
+
+int delete(struct Node ** head_ref, uint32_t data)
+{
+	struct Node *current = (struct Node*) malloc(sizeof(struct Node));
+	struct Node *previous = (struct Node*) malloc(sizeof(struct Node));
+	current=*head_ref;
+	previous = NULL;
+
+	if (*head_ref == NULL) {
+		return 0;
+	}
+	while(current->data != data) {
+
+		if(current->next == NULL) {
+			return 0;
+		} else {
+			previous = current;
+			current = current->next;
+		}
+	}
+	if(current == head) {
+		head = head->next;
+	} else {
+		previous->next = current->next;
+	}
+
+	return 1;
+
+}
+
+int delete_ifname(struct Node_ifname ** head_ref, uint32_t data)
+{
+	struct Node_ifname *current = (struct Node_ifname*) malloc(sizeof(struct Node_ifname));
+	struct Node_ifname *previous = (struct Node_ifname*) malloc(sizeof(struct Node_ifname));
+	current=*head_ref;
+	previous = NULL;
+
+	if (*head_ref == NULL) {
+		DBG1(DBG_KNL,"NO member in the list\n");
+		return 0;
+	}
+	while(current->spi != data) {
+
+		if(current->next_ifname == NULL) {
+			return 0;
+		} else {
+			previous = current;
+			current = current->next_ifname;
+		}
+	}
+
+	if(current == head_ifname) {
+		head_ifname = head_ifname->next_ifname;
+	} else {
+		previous->next_ifname = current->next_ifname;
+	}
+
+	return 1;
+
+}
+int delete_add_sa_enc(struct Node_add_sa_enc ** head_ref, uint32_t src, uint32_t dst)
+{
+	struct Node_add_sa_enc *current = (struct Node_add_sa_enc*) malloc(sizeof(struct Node_add_sa_enc));
+	struct Node_add_sa_enc *previous = (struct Node_add_sa_enc*) malloc(sizeof(struct Node_add_sa_enc));
+	current=*head_ref;
+	previous = NULL;
+
+	if (*head_ref == NULL) {
+		return 0;
+	}
+	while(current->src != src && current->dst != dst) {
+
+		if(current->next_add_sa_enc == NULL) {
+			return 0;
+		} else {
+			previous = current;
+			current = current->next_add_sa_enc;
+		}
+	}
+
+	if(current == head_add_sa_enc) {
+		head_add_sa_enc = head_add_sa_enc->next_add_sa_enc;
+	} else {
+		previous->next_add_sa_enc = current->next_add_sa_enc;
+	}
+
+	return 1;
+
+}
+METHOD(kernel_ipsec_t, add_sa, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_sa_id_t *id,
+		kernel_ipsec_add_sa_t *data)
+{
+	netlink_buf_t request;
+	const char *alg_name;
+	char markstr[32] = "";
+	struct nlmsghdr *hdr;
+	struct xfrm_usersa_info *sa;
+	uint16_t icv_size = 64, ipcomp = data->ipcomp;
+	ipsec_mode_t mode = data->mode, original_mode = data->mode;
+	traffic_selector_t *first_src_ts, *first_dst_ts;
+	status_t status = FAILED;
+
+	int flow = data->inbound ? 0 : 1;
+	host_t *local = data->inbound ? id->dst : id->src;
+
+
+	char *ifname;
+	if (charon->kernel->get_interface(charon->kernel, local,
+				&ifname))
+	//	ipsec_offload_add_policy_enc offload_add_policy_enc;
+	/* if IPComp is used, we install an additional IPComp SA. if the cpi is 0
+	 * we are in the recursive call below */
+	if (ipcomp != IPCOMP_NONE && data->cpi != 0)
+	{
+		lifetime_cfg_t lft = {{0,0,0},{0,0,0},{0,0,0}};
+		kernel_ipsec_sa_id_t ipcomp_id = {
+			.src = id->src,
+			.dst = id->dst,
+			.spi = htonl(ntohs(data->cpi)),
+			.proto = IPPROTO_COMP,
+			.mark = id->mark,
+			.if_id = id->if_id,
+		};
+		kernel_ipsec_add_sa_t ipcomp_sa = {
+			.reqid = data->reqid,
+			.mode = data->mode,
+			.src_ts = data->src_ts,
+			.dst_ts = data->dst_ts,
+			.lifetime = &lft,
+			.enc_alg = ENCR_UNDEFINED,
+			.int_alg = AUTH_UNDEFINED,
+			.tfc = data->tfc,
+			.ipcomp = data->ipcomp,
+			.initiator = data->initiator,
+			.inbound = data->inbound,
+			.update = data->update,
+		};
+		add_sa(this, &ipcomp_id, &ipcomp_sa);
+		ipcomp = IPCOMP_NONE;
+		/* use transport mode ESP SA, IPComp uses tunnel mode */
+		mode = MODE_TRANSPORT;
+	}
+
+	memset(&request, 0, sizeof(request));
+	format_mark(markstr, sizeof(markstr), id->mark);
+	hw_check = data->hw_offload;
+
+	DBG2(DBG_KNL, "adding SAD entry with SPI %.8x and reqid {%u}%s",
+			ntohl(id->spi), data->reqid, markstr);
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = data->update ? XFRM_MSG_UPDSA : XFRM_MSG_NEWSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_info));
+
+	sa = NLMSG_DATA(hdr);
+	host2xfrm(id->src, &sa->saddr);
+	host2xfrm(id->dst, &sa->id.daddr);
+	sa->id.spi = id->spi;
+	sa->id.proto = id->proto;
+	sa->family = id->src->get_family(id->src);
+	sa->mode = mode2kernel(mode);
+	if (!data->copy_df)
+	{
+		sa->flags |= XFRM_STATE_NOPMTUDISC;
+	}
+
+	if (!data->copy_ecn)
+	{
+		sa->flags |= XFRM_STATE_NOECN;
+	}
+
+	if (data->inbound)
+	{
+		switch (data->copy_dscp)
+		{
+			case DSCP_COPY_YES:
+			case DSCP_COPY_IN_ONLY:
+				sa->flags |= XFRM_STATE_DECAP_DSCP;
+				break;
+			default:
+				break;
+		}
+	}
+	else
+	{
+		switch (data->copy_dscp)
+		{
+			case DSCP_COPY_IN_ONLY:
+			case DSCP_COPY_NO:
+				{
+					/* currently the only extra flag */
+					if (!add_uint32(hdr, sizeof(request), XFRMA_SA_EXTRA_FLAGS,
+								XFRM_SA_XFLAG_DONT_ENCAP_DSCP))
+					{
+						goto failed;
+					}
+					break;
+				}
+			default:
+				break;
+		}
+	}
+
+	switch (mode)
+	{
+		case MODE_TUNNEL:
+			sa->flags |= XFRM_STATE_AF_UNSPEC;
+			break;
+		case MODE_BEET:
+		case MODE_TRANSPORT:
+			if (original_mode == MODE_TUNNEL)
+			{	/* don't install selectors for switched SAs.  because only one
+				 * selector can be installed other traffic would get dropped */
+				break;
+			}
+			if (data->src_ts->get_first(data->src_ts,
+						(void**)&first_src_ts) == SUCCESS &&
+					data->dst_ts->get_first(data->dst_ts,
+						(void**)&first_dst_ts) == SUCCESS)
+			{
+				sa->sel = ts2selector(first_src_ts, first_dst_ts,
+						data->interface);
+				if (!this->proto_port_transport)
+				{
+					/* don't install proto/port on SA. This would break
+					 * potential secondary SAs for the same address using a
+					 * different prot/port. */
+					sa->sel.proto = 0;
+					sa->sel.dport = sa->sel.dport_mask = 0;
+					sa->sel.sport = sa->sel.sport_mask = 0;
+				}
+			}
+			break;
+		default:
+			break;
+	}
+	if (id->proto == IPPROTO_AH && sa->family == AF_INET)
+	{	/* use alignment to 4 bytes for IPv4 instead of the incorrect 8 byte
+		 * alignment that's used by default but is only valid for IPv6 */
+		sa->flags |= XFRM_STATE_ALIGN4;
+	}
+
+	sa->reqid = data->reqid;
+	sa->lft.soft_byte_limit = XFRM_LIMIT(data->lifetime->bytes.rekey);
+	sa->lft.hard_byte_limit = XFRM_LIMIT(data->lifetime->bytes.life);
+	sa->lft.soft_packet_limit = XFRM_LIMIT(data->lifetime->packets.rekey);
+	sa->lft.hard_packet_limit = XFRM_LIMIT(data->lifetime->packets.life);
+	/* we use lifetimes since added, not since used */
+	sa->lft.soft_add_expires_seconds = data->lifetime->time.rekey;
+	sa->lft.hard_add_expires_seconds = data->lifetime->time.life;
+	sa->lft.soft_use_expires_seconds = 0;
+	sa->lft.hard_use_expires_seconds = 0;
+
+	switch (data->enc_alg)
+	{
+		case ENCR_UNDEFINED:
+			/* no encryption */
+			break;
+		case ENCR_AES_CCM_ICV16:
+		case ENCR_AES_GCM_ICV16:
+		case ENCR_NULL_AUTH_AES_GMAC:
+		case ENCR_CAMELLIA_CCM_ICV16:
+		case ENCR_CHACHA20_POLY1305:
+			icv_size += 32;
+			/* FALL */
+		case ENCR_AES_CCM_ICV12:
+		case ENCR_AES_GCM_ICV12:
+		case ENCR_CAMELLIA_CCM_ICV12:
+			icv_size += 32;
+			/* FALL */
+		case ENCR_AES_CCM_ICV8:
+		case ENCR_AES_GCM_ICV8:
+		case ENCR_CAMELLIA_CCM_ICV8:
+			{
+				struct xfrm_algo_aead *algo;
+
+				alg_name = lookup_algorithm(ENCRYPTION_ALGORITHM, data->enc_alg);
+				if (alg_name == NULL)
+				{
+					DBG1(DBG_KNL, "algorithm %N not supported by kernel!",
+							encryption_algorithm_names, data->enc_alg);
+					goto failed;
+				}
+				DBG2(DBG_KNL, "  using encryption algorithm %N with key size %d",
+						encryption_algorithm_names, data->enc_alg,
+						data->enc_key.len * 8);
+
+				algo = netlink_reserve(hdr, sizeof(request), XFRMA_ALG_AEAD,
+						sizeof(*algo) + data->enc_key.len);
+				if (!algo)
+				{
+					goto failed;
+				}
+				algo->alg_key_len = data->enc_key.len * 8;
+				algo->alg_icv_len = icv_size;
+				strncpy(algo->alg_name, alg_name, sizeof(algo->alg_name));
+				algo->alg_name[sizeof(algo->alg_name) - 1] = '\0';
+				memcpy(algo->alg_key, data->enc_key.ptr, data->enc_key.len);
+				break;
+			}
+		default:
+			{
+				struct xfrm_algo *algo;
+
+				alg_name = lookup_algorithm(ENCRYPTION_ALGORITHM, data->enc_alg);
+				if (alg_name == NULL)
+				{
+					DBG1(DBG_KNL, "algorithm %N not supported by kernel!",
+							encryption_algorithm_names, data->enc_alg);
+					goto failed;
+				}
+				DBG2(DBG_KNL, "  using encryption algorithm %N with key size %d",
+						encryption_algorithm_names, data->enc_alg,
+						data->enc_key.len * 8);
+
+				algo = netlink_reserve(hdr, sizeof(request), XFRMA_ALG_CRYPT,
+						sizeof(*algo) + data->enc_key.len);
+				if (!algo)
+				{
+					goto failed;
+				}
+				algo->alg_key_len = data->enc_key.len * 8;
+				strncpy(algo->alg_name, alg_name, sizeof(algo->alg_name));
+				algo->alg_name[sizeof(algo->alg_name) - 1] = '\0';
+				memcpy(algo->alg_key, data->enc_key.ptr, data->enc_key.len);
+			}
+	}
+
+	if (data->int_alg != AUTH_UNDEFINED)
+	{
+		u_int trunc_len = 0;
+
+		alg_name = lookup_algorithm(INTEGRITY_ALGORITHM, data->int_alg);
+		if (alg_name == NULL)
+		{
+			DBG1(DBG_KNL, "algorithm %N not supported by kernel!",
+					integrity_algorithm_names, data->int_alg);
+			goto failed;
+		}
+		DBG2(DBG_KNL, "  using integrity algorithm %N with key size %d",
+				integrity_algorithm_names, data->int_alg, data->int_key.len * 8);
+
+		switch (data->int_alg)
+		{
+			case AUTH_HMAC_MD5_128:
+			case AUTH_HMAC_SHA2_256_128:
+				trunc_len = 128;
+				break;
+			case AUTH_HMAC_SHA1_160:
+				trunc_len = 160;
+				break;
+			default:
+				break;
+		}
+
+		if (trunc_len)
+		{
+			struct xfrm_algo_auth* algo;
+
+			/* the kernel uses SHA256 with 96 bit truncation by default,
+			 * use specified truncation size supported by newer kernels.
+			 * also use this for untruncated MD5 and SHA1. */
+			algo = netlink_reserve(hdr, sizeof(request), XFRMA_ALG_AUTH_TRUNC,
+					sizeof(*algo) + data->int_key.len);
+			if (!algo)
+			{
+				goto failed;
+			}
+			algo->alg_key_len = data->int_key.len * 8;
+			algo->alg_trunc_len = trunc_len;
+			DBG1(DBG_KNL,"trunc_len = %d\n",trunc_len);
+			strncpy(algo->alg_name, alg_name, sizeof(algo->alg_name));
+			algo->alg_name[sizeof(algo->alg_name) - 1] = '\0';
+			memcpy(algo->alg_key, data->int_key.ptr, data->int_key.len);
+		}
+		else
+		{
+			struct xfrm_algo* algo;
+
+			algo = netlink_reserve(hdr, sizeof(request), XFRMA_ALG_AUTH,
+					sizeof(*algo) + data->int_key.len);
+			if (!algo)
+			{
+				goto failed;
+			}
+			algo->alg_key_len = data->int_key.len * 8;
+			strncpy(algo->alg_name, alg_name, sizeof(algo->alg_name));
+			algo->alg_name[sizeof(algo->alg_name) - 1] = '\0';
+			memcpy(algo->alg_key, data->int_key.ptr, data->int_key.len);
+		}
+	}
+	if (ipcomp != IPCOMP_NONE)
+	{
+		struct xfrm_algo* algo;
+
+		alg_name = lookup_algorithm(COMPRESSION_ALGORITHM, ipcomp);
+		if (alg_name == NULL)
+		{
+			DBG1(DBG_KNL, "algorithm %N not supported by kernel!",
+					ipcomp_transform_names, ipcomp);
+			goto failed;
+		}
+		DBG2(DBG_KNL, "  using compression algorithm %N",
+				ipcomp_transform_names, ipcomp);
+
+		algo = netlink_reserve(hdr, sizeof(request), XFRMA_ALG_COMP,
+				sizeof(*algo));
+		if (!algo)
+		{
+			goto failed;
+		}
+		algo->alg_key_len = 0;
+		strncpy(algo->alg_name, alg_name, sizeof(algo->alg_name));
+		algo->alg_name[sizeof(algo->alg_name) - 1] = '\0';
+	}
+
+	if (data->encap)
+	{
+		struct xfrm_encap_tmpl *tmpl;
+
+		tmpl = netlink_reserve(hdr, sizeof(request), XFRMA_ENCAP, sizeof(*tmpl));
+		if (!tmpl)
+		{
+			goto failed;
+		}
+		tmpl->encap_type = UDP_ENCAP_ESPINUDP;
+		tmpl->encap_sport = htons(id->src->get_port(id->src));
+		tmpl->encap_dport = htons(id->dst->get_port(id->dst));
+		memset(&tmpl->encap_oa, 0, sizeof (xfrm_address_t));
+		/* encap_oa could probably be derived from the
+		 * traffic selectors [rfc4306, p39]. In the netlink kernel
+		 * implementation pluto does the same as we do here but it uses
+		 * encap_oa in the pfkey implementation.
+		 * BUT as /usr/src/linux/net/key/af_key.c indicates the kernel ignores
+		 * it anyway
+		 *   -> does that mean that NAT-T encap doesn't work in transport mode?
+		 * No. The reason the kernel ignores NAT-OA is that it recomputes
+		 * (or, rather, just ignores) the checksum. If packets pass the IPsec
+		 * checks it marks them "checksum ok" so OA isn't needed. */
+	}
+
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		goto failed;
+	}
+
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		goto failed;
+	}
+
+	if (ipcomp == IPCOMP_NONE && (data->mark.value | data->mark.mask))
+	{
+		if (!add_uint32(hdr, sizeof(request), XFRMA_SET_MARK,
+					data->mark.value) ||
+				!add_uint32(hdr, sizeof(request), XFRMA_SET_MARK_MASK,
+					data->mark.mask))
+		{
+			goto failed;
+		}
+	}
+
+	if (data->tfc && id->proto == IPPROTO_ESP && mode == MODE_TUNNEL)
+	{	/* the kernel supports TFC padding only for tunnel mode ESP SAs */
+		if (!add_uint32(hdr, sizeof(request), XFRMA_TFCPAD, data->tfc))
+		{
+			goto failed;
+		}
+	}
+
+	if (id->proto != IPPROTO_COMP)
+	{
+		/* generally, we don't need a replay window for outbound SAs, however,
+		 * when using ESN the kernel rejects the attribute if it is 0 */
+		if (!data->inbound && data->replay_window)
+		{
+			data->replay_window = data->esn ? 1 : 0;
+		}
+		if (data->replay_window != 0 && (data->esn || data->replay_window > 32))
+		{
+			/* for ESN or larger replay windows we need the new
+			 * XFRMA_REPLAY_ESN_VAL attribute to configure a bitmap */
+			struct xfrm_replay_state_esn *replay;
+			uint32_t bmp_size;
+			bmp_size = round_up(data->replay_window, sizeof(uint32_t) * 8) / 8;
+			replay = netlink_reserve(hdr, sizeof(request), XFRMA_REPLAY_ESN_VAL,
+					sizeof(*replay) + bmp_size);
+			if (!replay)
+			{
+				goto failed;
+			}
+			/* bmp_len contains number uf __u32's */
+			replay->bmp_len = bmp_size / sizeof(uint32_t);
+			replay->replay_window = data->replay_window;
+			DBG2(DBG_KNL, "  using replay window of %u packets",
+					data->replay_window);
+
+			if (data->esn)
+			{
+				DBG2(DBG_KNL, "  using extended sequence numbers (ESN)");
+				sa->flags |= XFRM_STATE_ESN;
+			}
+		}
+		else
+		{
+			DBG2(DBG_KNL, "  using replay window of %u packets",
+					data->replay_window);
+			sa->replay_window = data->replay_window;
+		}
+
+#if 0
+		DBG2(DBG_KNL, "  HW offload: %N", hw_offload_names, data->hw_offload);
+		if (!config_hw_offload(id, data, hdr, sizeof(request)))
+		{
+			DBG1(DBG_KNL, "failed to configure HW offload");
+			goto failed;
+		}
+#endif		
+	}
+
+	status = this->socket_xfrm->send_ack(this->socket_xfrm, hdr);
+	if (status == NOT_FOUND && data->update)
+	{
+		DBG1(DBG_KNL, "allocated SPI not found anymore, try to add SAD entry");
+		hdr->nlmsg_type = XFRM_MSG_NEWSA;
+		status = this->socket_xfrm->send_ack(this->socket_xfrm, hdr);
+	}
+
+	if (status != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to add SAD entry with SPI %.8x%s (%N)", ntohl(id->spi),
+				markstr, status_names, status);
+		status = FAILED;
+		goto failed;
+	}
+
+	if(data->hw_offload){
+
+		int ret_fun_call = ipsec_offload_add_sa(flow, &data->enc_key,   &id->spi, &sa->saddr, &sa->id.daddr, &sa->reqid, ifname);
+		if(ret_fun_call == -1){
+			DBG2(DBG_KNL,"IOCTL_ADD_SA FAILED");
+		}
+
+	}
+	status = SUCCESS;
+
+failed:
+	memwipe(&request, sizeof(request));
+	return status;
+}
+
+/**
+ * Get the ESN replay state (i.e. sequence numbers) of an SA.
+ *
+ * Allocates into one the replay state structure we get from the kernel.
+ */
+static void get_replay_state(private_ipsec_offload_ipsec_t *this,
+		kernel_ipsec_sa_id_t *sa,
+		struct xfrm_replay_state_esn **replay_esn,
+		uint32_t *replay_esn_len,
+		struct xfrm_replay_state **replay,
+		struct xfrm_lifetime_cur **lifetime)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out = NULL;
+	struct xfrm_aevent_id *out_aevent = NULL, *aevent_id;
+	size_t len;
+	struct rtattr *rta;
+	size_t rtasize;
+
+	memset(&request, 0, sizeof(request));
+
+	DBG2(DBG_KNL, "querying replay state from SAD entry with SPI %.8x",
+			ntohl(sa->spi));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_GETAE;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_aevent_id));
+
+	aevent_id = NLMSG_DATA(hdr);
+	aevent_id->flags = XFRM_AE_RVAL;
+
+	host2xfrm(sa->dst, &aevent_id->sa_id.daddr);
+	aevent_id->sa_id.spi = sa->spi;
+	aevent_id->sa_id.proto = sa->proto;
+	aevent_id->sa_id.family = sa->dst->get_family(sa->dst);
+
+	if (!add_mark(hdr, sizeof(request), sa->mark))
+	{
+		return;
+	}
+	if (sa->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, sa->if_id))
+	{
+		return;
+	}
+
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWAE:
+					{
+						out_aevent = NLMSG_DATA(hdr);
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+						DBG1(DBG_KNL, "querying replay state from SAD entry "
+								"failed: %s (%d)", strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+	}
+
+	if (out_aevent)
+	{
+		rta = XFRM_RTA(out, struct xfrm_aevent_id);
+		rtasize = XFRM_PAYLOAD(out, struct xfrm_aevent_id);
+		while (RTA_OK(rta, rtasize))
+		{
+			if (rta->rta_type == XFRMA_LTIME_VAL &&
+					RTA_PAYLOAD(rta) == sizeof(**lifetime))
+			{
+				free(*lifetime);
+				*lifetime = malloc(RTA_PAYLOAD(rta));
+				memcpy(*lifetime, RTA_DATA(rta), RTA_PAYLOAD(rta));
+			}
+			if (rta->rta_type == XFRMA_REPLAY_VAL &&
+					RTA_PAYLOAD(rta) == sizeof(**replay))
+			{
+				free(*replay);
+				*replay = malloc(RTA_PAYLOAD(rta));
+				memcpy(*replay, RTA_DATA(rta), RTA_PAYLOAD(rta));
+			}
+			if (rta->rta_type == XFRMA_REPLAY_ESN_VAL &&
+					RTA_PAYLOAD(rta) >= sizeof(**replay_esn))
+			{
+				free(*replay_esn);
+				*replay_esn = malloc(RTA_PAYLOAD(rta));
+				*replay_esn_len = RTA_PAYLOAD(rta);
+				memcpy(*replay_esn, RTA_DATA(rta), RTA_PAYLOAD(rta));
+			}
+			rta = RTA_NEXT(rta, rtasize);
+		}
+	}
+	free(out);
+}
+
+METHOD(kernel_ipsec_t, query_sa, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_sa_id_t *id,
+		kernel_ipsec_query_sa_t *data, uint64_t *bytes, uint64_t *packets,
+		time_t *time)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *out = NULL, *hdr;
+	struct xfrm_usersa_id *sa_id;
+	struct xfrm_usersa_info *sa = NULL;
+	status_t status = FAILED;
+	size_t len;
+	char markstr[32] = "";
+	struct ipsec_offload_query_sa ipsec_offload_query_sa;
+		ipsec_offload_query_sa.ipsec_offload_packets = 0x00;
+		ipsec_offload_query_sa.ipsec_offload_bytes = 0x00;
+
+	memset(&request, 0, sizeof(request));
+	format_mark(markstr, sizeof(markstr), id->mark);
+
+	DBG2(DBG_KNL, "querying SAD entry with SPI %.8x%s", ntohl(id->spi),
+			markstr);
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_GETSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_id));
+
+	sa_id = NLMSG_DATA(hdr);
+	host2xfrm(id->dst, &sa_id->daddr);
+	sa_id->spi = id->spi;
+	sa_id->proto = id->proto;
+	sa_id->family = id->dst->get_family(id->dst);
+
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		return FAILED;
+	}
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		return FAILED;
+	}
+	if (hw_check) {
+
+
+
+		ipsec_offload_query_sa = ipsec_offload_query_sa_fun(&id->spi); 
+	}
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWSA:
+					{
+						sa = NLMSG_DATA(hdr);
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+
+						DBG1(DBG_KNL, "querying SAD entry with SPI %.8x%s failed: "
+								"%s (%d)", ntohl(id->spi), markstr,
+								strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+	}
+
+	if (sa == NULL)
+	{
+		DBG2(DBG_KNL, "unable to query SAD entry with SPI %.8x%s",
+				ntohl(id->spi), markstr);
+	}
+	else
+	{
+		if (bytes)
+		{
+			if (hw_check){
+				*bytes = ipsec_offload_query_sa.ipsec_offload_bytes;
+			}
+			else {
+				*bytes = sa->curlft.bytes;
+			}
+		}
+		if (packets)
+		{
+			if (hw_check){
+				*packets = ipsec_offload_query_sa.ipsec_offload_packets;
+			}
+			else {
+				*packets = sa->curlft.packets;
+			}
+		}
+		if (time)
+		{	/* curlft contains an "use" time, but that contains a timestamp
+			 * of the first use, not the last. Last use time must be queried
+			 * on the policy on Linux */
+			*time = 0;
+		}
+		status = SUCCESS;
+	}
+	memwipe(out, len);
+	free(out);
+	return status;
+}
+
+METHOD(kernel_ipsec_t, del_sa, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_sa_id_t *id,
+		kernel_ipsec_del_sa_t *data)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct xfrm_usersa_id *sa_id;
+	char markstr[32] = "";
+
+	/* if IPComp was used, we first delete the additional IPComp SA */
+	if (data->cpi)
+	{
+		kernel_ipsec_sa_id_t ipcomp_id = {
+			.src = id->src,
+			.dst = id->dst,
+			.spi = htonl(ntohs(data->cpi)),
+			.proto = IPPROTO_COMP,
+			.mark = id->mark,
+		};
+		kernel_ipsec_del_sa_t ipcomp = {};
+		del_sa(this, &ipcomp_id, &ipcomp);
+	}
+
+	memset(&request, 0, sizeof(request));
+	format_mark(markstr, sizeof(markstr), id->mark);
+
+	DBG2(DBG_KNL, "deleting SAD entry with SPI %.8x%s", ntohl(id->spi),
+			markstr);
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_DELSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_id));
+	uint32_t sample;
+	sa_id = NLMSG_DATA(hdr);
+	host2xfrm(id->dst, &sa_id->daddr);
+	host2xfrm(id->src, (xfrm_address_t*) &sample);
+	sa_id->spi = id->spi;
+	sa_id->proto = id->proto;
+	sa_id->family = id->dst->get_family(id->dst);
+	if(hw_check){
+		int ret_fun_call = ipsec_offload_del_sa((xfrm_address_t *) &sample, &sa_id->daddr,  &sa_id->spi);
+		if (ret_fun_call == -1){
+
+			DBG1(DBG_KNL,"IOCTL_FAILED_DELET_SA\n");
+
+		}
+	}
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		return FAILED;
+	}
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		return FAILED;
+	}
+
+	switch (this->socket_xfrm->send_ack(this->socket_xfrm, hdr))
+	{
+		case SUCCESS:
+			DBG2(DBG_KNL, "deleted SAD entry with SPI %.8x%s",
+					ntohl(id->spi), markstr);
+			return SUCCESS;
+		case NOT_FOUND:
+			return NOT_FOUND;
+		default:
+			DBG1(DBG_KNL, "unable to delete SAD entry with SPI %.8x%s",
+					ntohl(id->spi), markstr);
+			return FAILED;
+	}
+}
+
+METHOD(kernel_ipsec_t, update_sa, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_sa_id_t *id,
+		kernel_ipsec_update_sa_t *data)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out_hdr = NULL, *out = NULL;
+	struct xfrm_usersa_id *sa_id;
+	struct xfrm_usersa_info *sa;
+	size_t len;
+	struct rtattr *rta;
+	size_t rtasize;
+	struct xfrm_encap_tmpl* encap = NULL;
+	struct xfrm_replay_state *replay = NULL;
+	struct xfrm_replay_state_esn *replay_esn = NULL;
+	struct xfrm_lifetime_cur *lifetime = NULL;
+	uint32_t replay_esn_len = 0;
+	kernel_ipsec_del_sa_t del = { 0 };
+	status_t status = FAILED;
+	traffic_selector_t *ts;
+	char markstr[32] = "";
+
+	/* if IPComp is used, we first update the IPComp SA */
+	if (data->cpi)
+	{
+		kernel_ipsec_sa_id_t ipcomp_id = {
+			.src = id->src,
+			.dst = id->dst,
+			.spi = htonl(ntohs(data->cpi)),
+			.proto = IPPROTO_COMP,
+			.mark = id->mark,
+			.if_id = id->if_id,
+		};
+		kernel_ipsec_update_sa_t ipcomp = {
+			.new_src = data->new_src,
+			.new_dst = data->new_dst,
+		};
+		update_sa(this, &ipcomp_id, &ipcomp);
+	}
+
+	memset(&request, 0, sizeof(request));
+	format_mark(markstr, sizeof(markstr), id->mark);
+
+	DBG2(DBG_KNL, "querying SAD entry with SPI %.8x%s for update",
+			ntohl(id->spi), markstr);
+
+	/* query the existing SA first */
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_GETSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_id));
+
+	sa_id = NLMSG_DATA(hdr);
+	host2xfrm(id->dst, &sa_id->daddr);
+	sa_id->spi = id->spi;
+	sa_id->proto = id->proto;
+	sa_id->family = id->dst->get_family(id->dst);
+
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		return FAILED;
+	}
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		return FAILED;
+	}
+
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWSA:
+					{
+						out_hdr = hdr;
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+						DBG1(DBG_KNL, "querying SAD entry failed: %s (%d)",
+								strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+	}
+	if (!out_hdr)
+	{
+		DBG1(DBG_KNL, "unable to update SAD entry with SPI %.8x%s",
+				ntohl(id->spi), markstr);
+		goto failed;
+	}
+
+	get_replay_state(this, id, &replay_esn, &replay_esn_len, &replay,
+			&lifetime);
+
+	/* delete the old SA (without affecting the IPComp SA) */
+	if (del_sa(this, id, &del) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to delete old SAD entry with SPI %.8x%s",
+				ntohl(id->spi), markstr);
+		goto failed;
+	}
+
+	DBG2(DBG_KNL, "updating SAD entry with SPI %.8x%s from %#H..%#H to "
+			"%#H..%#H", ntohl(id->spi), markstr, id->src, id->dst, data->new_src,
+			data->new_dst);
+	/* copy over the SA from out to request */
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_NEWSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_info));
+	sa = NLMSG_DATA(hdr);
+	memcpy(sa, NLMSG_DATA(out_hdr), sizeof(struct xfrm_usersa_info));
+	sa->family = data->new_dst->get_family(data->new_dst);
+
+	if (!id->src->ip_equals(id->src, data->new_src))
+	{
+		host2xfrm(data->new_src, &sa->saddr);
+
+		ts = selector2ts(&sa->sel, TRUE);
+		if (ts && ts->is_host(ts, id->src))
+		{
+			ts->set_address(ts, data->new_src);
+			ts2subnet(ts, &sa->sel.saddr, &sa->sel.prefixlen_s);
+		}
+		DESTROY_IF(ts);
+	}
+	if (!id->dst->ip_equals(id->dst, data->new_dst))
+	{
+		host2xfrm(data->new_dst, &sa->id.daddr);
+
+		ts = selector2ts(&sa->sel, FALSE);
+		if (ts && ts->is_host(ts, id->dst))
+		{
+			ts->set_address(ts, data->new_dst);
+			ts2subnet(ts, &sa->sel.daddr, &sa->sel.prefixlen_d);
+		}
+		DESTROY_IF(ts);
+	}
+
+	rta = XFRM_RTA(out_hdr, struct xfrm_usersa_info);
+	rtasize = XFRM_PAYLOAD(out_hdr, struct xfrm_usersa_info);
+	while (RTA_OK(rta, rtasize))
+	{
+		/* copy all attributes, but not XFRMA_ENCAP if we are disabling it */
+		if (rta->rta_type != XFRMA_ENCAP || data->new_encap)
+		{
+			if (rta->rta_type == XFRMA_ENCAP)
+			{	/* update encap tmpl */
+				encap = RTA_DATA(rta);
+				encap->encap_sport = ntohs(data->new_src->get_port(data->new_src));
+				encap->encap_dport = ntohs(data->new_dst->get_port(data->new_dst));
+			}
+			if (rta->rta_type == XFRMA_OFFLOAD_DEV)
+			{	/* update offload device */
+				struct xfrm_user_offload *offload;
+				host_t *local;
+				char *ifname;
+
+				offload = RTA_DATA(rta);
+				local = offload->flags & XFRM_OFFLOAD_INBOUND ? data->new_dst
+					: data->new_src;
+
+				if (charon->kernel->get_interface(charon->kernel, local,
+							&ifname))
+				{
+					offload->ifindex = if_nametoindex(ifname);
+					if (local->get_family(local) == AF_INET6)
+					{
+						offload->flags |= XFRM_OFFLOAD_IPV6;
+					}
+					else
+					{
+						offload->flags &= ~XFRM_OFFLOAD_IPV6;
+					}
+					free(ifname);
+				}
+			}
+			netlink_add_attribute(hdr, rta->rta_type,
+					chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta)),
+					sizeof(request));
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+
+	if (encap == NULL && data->new_encap)
+	{	/* add tmpl if we are enabling it */
+		encap = netlink_reserve(hdr, sizeof(request), XFRMA_ENCAP,
+				sizeof(*encap));
+		if (!encap)
+		{
+			goto failed;
+		}
+		encap->encap_type = UDP_ENCAP_ESPINUDP;
+		encap->encap_sport = ntohs(data->new_src->get_port(data->new_src));
+		encap->encap_dport = ntohs(data->new_dst->get_port(data->new_dst));
+		memset(&encap->encap_oa, 0, sizeof (xfrm_address_t));
+	}
+
+	if (replay_esn)
+	{
+		struct xfrm_replay_state_esn *state;
+
+		state = netlink_reserve(hdr, sizeof(request), XFRMA_REPLAY_ESN_VAL,
+				replay_esn_len);
+		if (!state)
+		{
+			goto failed;
+		}
+		memcpy(state, replay_esn, replay_esn_len);
+	}
+	else if (replay)
+	{
+		struct xfrm_replay_state *state;
+
+		state = netlink_reserve(hdr, sizeof(request), XFRMA_REPLAY_VAL,
+				sizeof(*state));
+		if (!state)
+		{
+			goto failed;
+		}
+		memcpy(state, replay, sizeof(*state));
+	}
+	else
+	{
+		DBG1(DBG_KNL, "unable to copy replay state from old SAD entry with "
+				"SPI %.8x%s", ntohl(id->spi), markstr);
+	}
+	if (lifetime)
+	{
+		struct xfrm_lifetime_cur *state;
+
+		state = netlink_reserve(hdr, sizeof(request), XFRMA_LTIME_VAL,
+				sizeof(*state));
+		if (!state)
+		{
+			goto failed;
+		}
+		memcpy(state, lifetime, sizeof(*state));
+	}
+	else
+	{
+		DBG1(DBG_KNL, "unable to copy usage stats from old SAD entry with "
+				"SPI %.8x%s", ntohl(id->spi), markstr);
+	}
+
+	if (this->socket_xfrm->send_ack(this->socket_xfrm, hdr) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to update SAD entry with SPI %.8x%s",
+				ntohl(id->spi), markstr);
+		goto failed;
+	}
+	
+	status = SUCCESS;
+failed:
+	free(replay);
+	free(replay_esn);
+	free(lifetime);
+	memwipe(out, len);
+	memwipe(&request, sizeof(request));
+	free(out);
+
+	return status;
+}
+
+METHOD(kernel_ipsec_t, flush_sas, status_t,
+		private_ipsec_offload_ipsec_t *this)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct xfrm_usersa_flush *flush;
+	struct {
+		uint8_t proto;
+		char *name;
+	} protos[] = {
+		{ IPPROTO_AH, "AH" },
+		{ IPPROTO_ESP, "ESP" },
+		{ IPPROTO_COMP, "IPComp" },
+	};
+	int i;
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_FLUSHSA;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_usersa_flush));
+
+	flush = NLMSG_DATA(hdr);
+
+	for (i = 0; i < countof(protos); i++)
+	{
+		DBG2(DBG_KNL, "flushing all %s SAD entries", protos[i].name);
+
+		flush->proto = protos[i].proto;
+
+		if (this->socket_xfrm->send_ack(this->socket_xfrm, hdr) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "unable to flush %s SAD entries", protos[i].name);
+			return FAILED;
+		}
+	}
+	return SUCCESS;
+}
+
+/**
+ * Unlock the mutex and signal waiting threads
+ */
+static void policy_change_done(private_ipsec_offload_ipsec_t *this,
+		policy_entry_t *policy)
+{
+	policy->working = FALSE;
+	if (policy->waiting)
+	{	/* don't need to wake threads waiting for other policies */
+		this->condvar->broadcast(this->condvar);
+	}
+	this->mutex->unlock(this->mutex);
+}
+
+/**
+ * Install a route for the given policy if enabled and required
+ */
+static void install_route(private_ipsec_offload_ipsec_t *this,
+		policy_entry_t *policy, policy_sa_t *mapping, ipsec_sa_t *ipsec)
+{
+	policy_sa_out_t *out = (policy_sa_out_t*)mapping;
+	route_entry_t *route;
+	host_t *iface;
+
+	INIT(route,
+			.prefixlen = policy->sel.prefixlen_d,
+			.pass = mapping->type == POLICY_PASS,
+	    );
+
+	if (charon->kernel->get_address_by_ts(charon->kernel, out->src_ts,
+				&route->src_ip, NULL) != SUCCESS)
+	{
+		if (!route->pass)
+		{
+			free(route);
+			return;
+		}
+		/* allow blank source IP for passthrough policies */
+		route->src_ip = host_create_any(policy->sel.family);
+	}
+
+	if (!ipsec->dst->is_anyaddr(ipsec->dst))
+	{
+		route->gateway = charon->kernel->get_nexthop(charon->kernel,
+				ipsec->dst, -1, ipsec->src,
+				&route->if_name);
+	}
+	else
+	{	/* for shunt policies */
+		iface = xfrm2host(policy->sel.family, &policy->sel.daddr, 0);
+		route->gateway = charon->kernel->get_nexthop(charon->kernel,
+				iface, policy->sel.prefixlen_d,
+				route->src_ip, &route->if_name);
+		iface->destroy(iface);
+	}
+	route->dst_net = chunk_alloc(policy->sel.family == AF_INET ? 4 : 16);
+	memcpy(route->dst_net.ptr, &policy->sel.daddr, route->dst_net.len);
+
+	/* get the interface to install the route for, if we haven't one yet.
+	 * If we have a local address, use it. Otherwise (for shunt policies)
+	 * use the route's source address. */
+	if (!route->if_name)
+	{
+		iface = ipsec->src;
+		if (iface->is_anyaddr(iface))
+		{
+			iface = route->src_ip;
+		}
+		if (!charon->kernel->get_interface(charon->kernel, iface,
+					&route->if_name) &&
+				!route->pass)
+		{	/* don't require an interface for passthrough policies */
+			route_entry_destroy(route);
+			return;
+		}
+	}
+	if (policy->route)
+	{
+		route_entry_t *old = policy->route;
+		if (route_entry_equals(old, route))
+		{
+			route_entry_destroy(route);
+			return;
+		}
+		/* uninstall previously installed route */
+		if (charon->kernel->del_route(charon->kernel, old->dst_net,
+					old->prefixlen, old->gateway,
+					old->src_ip, old->if_name,
+					old->pass) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "error uninstalling route installed with policy "
+					"%R === %R %N", out->src_ts, out->dst_ts, policy_dir_names,
+					policy->direction);
+		}
+		route_entry_destroy(old);
+		policy->route = NULL;
+	}
+
+	DBG2(DBG_KNL, "installing route: %R via %H src %H dev %s", out->dst_ts,
+			route->gateway, route->src_ip, route->if_name);
+	switch (charon->kernel->add_route(charon->kernel, route->dst_net,
+				route->prefixlen, route->gateway,
+				route->src_ip, route->if_name,
+				route->pass))
+	{
+		default:
+			DBG1(DBG_KNL, "unable to install source route for %H",
+					route->src_ip);
+			/* FALL */
+		case ALREADY_DONE:
+			/* route exists, do not uninstall */
+			route_entry_destroy(route);
+			break;
+		case SUCCESS:
+			/* cache the installed route */
+			policy->route = route;
+			break;
+	}
+}
+
+/**
+ * Add or update a policy in the kernel.
+ *
+ * Note: The mutex has to be locked when entering this function
+ * and is unlocked here in any case.
+ */
+static status_t add_policy_internal(private_ipsec_offload_ipsec_t *this,
+		policy_entry_t *policy, policy_sa_t *mapping, bool update)
+{
+	netlink_buf_t request;
+	policy_entry_t clone;
+	ipsec_sa_t *ipsec = mapping->sa;
+	struct xfrm_userpolicy_info *policy_info;
+	struct nlmsghdr *hdr;
+	status_t status;
+	int i;
+
+	/* clone the policy so we are able to check it out again later */
+	memcpy(&clone, policy, sizeof(policy_entry_t));
+
+	memset(&request, 0, sizeof(request));
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = update ? XFRM_MSG_UPDPOLICY : XFRM_MSG_NEWPOLICY;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userpolicy_info));
+
+	policy_info = NLMSG_DATA(hdr);
+	policy_info->sel = policy->sel;
+	policy_info->dir = policy->direction;
+	/* calculate priority based on selector size, small size = high prio */
+	policy_info->priority = mapping->priority;
+	policy_info->action = mapping->type != POLICY_DROP ? XFRM_POLICY_ALLOW
+		: XFRM_POLICY_BLOCK;
+	policy_info->share = XFRM_SHARE_ANY;
+
+	/* policies don't expire */
+	policy_info->lft.soft_byte_limit = XFRM_INF;
+	policy_info->lft.soft_packet_limit = XFRM_INF;
+	policy_info->lft.hard_byte_limit = XFRM_INF;
+	policy_info->lft.hard_packet_limit = XFRM_INF;
+	policy_info->lft.soft_add_expires_seconds = 0;
+	policy_info->lft.hard_add_expires_seconds = 0;
+	policy_info->lft.soft_use_expires_seconds = 0;
+	policy_info->lft.hard_use_expires_seconds = 0;
+
+	if (mapping->type == POLICY_IPSEC && ipsec->cfg.reqid)
+	{
+		struct xfrm_user_tmpl *tmpl;
+		struct {
+			uint8_t proto;
+			uint32_t spi;
+			bool use;
+		} protos[] = {
+			{ IPPROTO_COMP, htonl(ntohs(ipsec->cfg.ipcomp.cpi)),
+				ipsec->cfg.ipcomp.transform != IPCOMP_NONE },
+			{ IPPROTO_ESP, ipsec->cfg.esp.spi, ipsec->cfg.esp.use },
+			{ IPPROTO_AH, ipsec->cfg.ah.spi, ipsec->cfg.ah.use },
+		};
+		ipsec_mode_t proto_mode = ipsec->cfg.mode;
+		int count = 0;
+
+		for (i = 0; i < countof(protos); i++)
+		{
+			if (protos[i].use)
+			{
+				count++;
+			}
+		}
+		tmpl = netlink_reserve(hdr, sizeof(request), XFRMA_TMPL,
+				count * sizeof(*tmpl));
+		if (!tmpl)
+		{
+			policy_change_done(this, policy);
+			return FAILED;
+		}
+
+		for (i = 0; i < countof(protos); i++)
+		{
+			if (!protos[i].use)
+			{
+				continue;
+			}
+			tmpl->reqid = ipsec->cfg.reqid;
+			tmpl->id.proto = protos[i].proto;
+			if (policy->direction == POLICY_OUT)
+			{
+				tmpl->id.spi = protos[i].spi;
+			}
+			tmpl->aalgos = tmpl->ealgos = tmpl->calgos = ~0;
+			tmpl->mode = mode2kernel(proto_mode);
+			tmpl->optional = protos[i].proto == IPPROTO_COMP &&
+				policy->direction != POLICY_OUT;
+			tmpl->family = ipsec->src->get_family(ipsec->src);
+
+			if (proto_mode == MODE_TUNNEL || proto_mode == MODE_BEET)
+			{	/* only for tunnel mode */
+				host2xfrm(ipsec->src, &tmpl->saddr);
+				host2xfrm(ipsec->dst, &tmpl->id.daddr);
+			}
+
+			tmpl++;
+
+			/* use transport mode for other SAs */
+			proto_mode = MODE_TRANSPORT;
+		}
+	}
+
+	if (!add_mark(hdr, sizeof(request), ipsec->mark))
+	{
+		policy_change_done(this, policy);
+		return FAILED;
+	}
+	if (ipsec->if_id &&
+			!add_uint32(hdr, sizeof(request), XFRMA_IF_ID, ipsec->if_id))
+	{
+		policy_change_done(this, policy);
+		return FAILED;
+	}
+	this->mutex->unlock(this->mutex);
+
+	status = this->socket_xfrm->send_ack(this->socket_xfrm, hdr);
+	if (status == ALREADY_DONE && !update)
+	{
+		DBG1(DBG_KNL, "policy already exists, try to update it");
+		hdr->nlmsg_type = XFRM_MSG_UPDPOLICY;
+		status = this->socket_xfrm->send_ack(this->socket_xfrm, hdr);
+	}
+
+	this->mutex->lock(this->mutex);
+	if (status != SUCCESS)
+	{
+		policy_change_done(this, policy);
+		return FAILED;
+	}
+	/* install a route, if:
+	 * - this is an outbound policy (to just get one for each child)
+	 * - routing is not disabled via strongswan.conf
+	 * - the selector is not for a specific protocol/port
+	 * - no XFRM interface ID is configured
+	 * - we are in tunnel/BEET mode or install a bypass policy
+	 */
+	if (policy->direction == POLICY_OUT && this->install_routes &&
+			!policy->sel.proto && !policy->sel.dport && !policy->sel.sport &&
+			!policy->if_id)
+	{
+		if (mapping->type == POLICY_PASS ||
+				(mapping->type == POLICY_IPSEC && ipsec->cfg.mode != MODE_TRANSPORT))
+		{
+			install_route(this, policy, mapping, ipsec);
+		}
+	}
+	policy_change_done(this, policy);
+	return SUCCESS;
+}
+
+METHOD(kernel_ipsec_t, add_policy, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_policy_id_t *id,
+		kernel_ipsec_manage_policy_t *data)
+{
+	policy_entry_t *policy, *current;
+	policy_sa_t *assigned_sa, *current_sa;
+	enumerator_t *enumerator;
+	bool found = FALSE, update = TRUE;
+	char markstr[32] = "";
+	uint32_t cur_priority = 0;
+	int use_count;
+	/* create a policy */
+	INIT(policy,
+			.sel = ts2selector(id->src_ts, id->dst_ts, id->interface),
+			.mark = id->mark.value & id->mark.mask,
+			.if_id = id->if_id,
+			.direction = id->dir,
+			.reqid = data->sa->reqid,
+	    );
+	format_mark(markstr, sizeof(markstr), id->mark);
+	/* find the policy, which matches EXACTLY */
+	this->mutex->lock(this->mutex);
+	current = this->policies->get(this->policies, policy);
+	if (current)
+	{
+		if (current->reqid && data->sa->reqid &&
+				current->reqid != data->sa->reqid)
+		{
+			DBG1(DBG_CFG, "unable to install policy %R === %R %N%s for reqid "
+					"%u, the same policy for reqid %u exists",
+					id->src_ts, id->dst_ts, policy_dir_names, id->dir, markstr,
+					data->sa->reqid, current->reqid);
+			policy_entry_destroy(this, policy);
+			this->mutex->unlock(this->mutex);
+			return INVALID_STATE;
+		}
+		/* use existing policy */
+		DBG2(DBG_KNL, "policy %R === %R %N%s already exists, increasing "
+				"refcount", id->src_ts, id->dst_ts, policy_dir_names, id->dir,
+				markstr);
+		policy_entry_destroy(this, policy);
+		policy = current;
+		found = TRUE;
+		policy->waiting++;
+		while (policy->working)
+		{
+			this->condvar->wait(this->condvar, this->mutex);
+		}
+		policy->waiting--;
+		policy->working = TRUE;
+	}
+	else
+	{	/* use the new one, if we have no such policy */
+		policy->used_by = linked_list_create();
+		this->policies->put(this->policies, policy, policy);
+	}
+
+	/* cache the assigned IPsec SA */
+	if (hw_check)
+		data->type = POLICY_PASS;
+	assigned_sa = policy_sa_create(this, id->dir, data->type, data->src,
+			data->dst, id->src_ts, id->dst_ts, id->mark,
+			id->if_id, data->sa);
+	assigned_sa->auto_priority = get_priority(policy, data->prio, id->interface);
+	assigned_sa->priority = this->get_priority ? this->get_priority(id, data)
+		: data->manual_prio;
+	assigned_sa->priority = assigned_sa->priority ?: assigned_sa->auto_priority;
+	if (hw_check)
+		assigned_sa->type = POLICY_PASS;
+
+	/* insert the SA according to its priority */
+	enumerator = policy->used_by->create_enumerator(policy->used_by);
+	while (enumerator->enumerate(enumerator, (void**)&current_sa))
+	{
+		if (current_sa->priority > assigned_sa->priority)
+		{
+			break;
+		}
+		if (current_sa->priority == assigned_sa->priority)
+		{
+			/* in case of equal manual prios order SAs by automatic priority */
+			if (current_sa->auto_priority > assigned_sa->auto_priority)
+			{
+				break;
+			}
+			/* prefer SAs with a reqid over those without */
+			if (current_sa->auto_priority == assigned_sa->auto_priority &&
+					(!current_sa->sa->cfg.reqid || assigned_sa->sa->cfg.reqid))
+			{
+				break;
+			}
+		}
+		if (update)
+		{
+			cur_priority = current_sa->priority;
+			update = FALSE;
+		}
+	}
+	policy->used_by->insert_before(policy->used_by, enumerator, assigned_sa);
+	enumerator->destroy(enumerator);
+
+	use_count = policy->used_by->get_count(policy->used_by);
+	if (!update)
+	{	/* we don't update the policy if the priority is lower than that of
+		 * the currently installed one */
+		policy_change_done(this, policy);
+		DBG2(DBG_KNL, "not updating policy %R === %R %N%s [priority %u, "
+				"refcount %d]", id->src_ts, id->dst_ts, policy_dir_names,
+				id->dir, markstr, cur_priority, use_count);
+		return SUCCESS;
+	}
+	policy->reqid = assigned_sa->sa->cfg.reqid;
+
+	ipsec_offload_add_policy(&id->dir,id->src_ts, id->dst_ts, &policy->reqid, &data->type, &policy->sel.proto);
+	if (this->policy_update)
+	{
+		found = TRUE;
+	}
+
+	DBG2(DBG_KNL, "%s policy %R === %R %N%s [priority %u, refcount %d]",
+			found ? "updating" : "adding", id->src_ts, id->dst_ts,
+			policy_dir_names, id->dir, markstr, assigned_sa->priority, use_count);
+
+	if (add_policy_internal(this, policy, assigned_sa, found) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to %s policy %R === %R %N%s",
+				found ? "update" : "add", id->src_ts, id->dst_ts,
+				policy_dir_names, id->dir, markstr);
+		return FAILED;
+	}
+	return SUCCESS;
+}
+
+METHOD(kernel_ipsec_t, query_policy, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_policy_id_t *id,
+		kernel_ipsec_query_policy_t *data, time_t *use_time)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *out = NULL, *hdr;
+	struct xfrm_userpolicy_id *policy_id;
+	struct xfrm_userpolicy_info *policy = NULL;
+	size_t len;
+	char markstr[32] = "";
+
+	memset(&request, 0, sizeof(request));
+	format_mark(markstr, sizeof(markstr), id->mark);
+
+	DBG2(DBG_KNL, "querying policy %R === %R %N%s", id->src_ts, id->dst_ts,
+			policy_dir_names, id->dir, markstr);
+	DBG2(DBG_KNL, "##############Inside query_policy\n");
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_GETPOLICY;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userpolicy_id));
+
+	policy_id = NLMSG_DATA(hdr);
+	policy_id->sel = ts2selector(id->src_ts, id->dst_ts, id->interface);
+	policy_id->dir = id->dir;
+
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		return FAILED;
+	}
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		return FAILED;
+	}
+
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWPOLICY:
+					{
+						policy = NLMSG_DATA(hdr);
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+						DBG1(DBG_KNL, "querying policy failed: %s (%d)",
+								strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+	}
+
+	if (policy == NULL)
+	{
+		DBG2(DBG_KNL, "unable to query policy %R === %R %N%s", id->src_ts,
+				id->dst_ts, policy_dir_names, id->dir, markstr);
+		free(out);
+		return FAILED;
+	}
+
+	if (policy->curlft.use_time)
+	{
+		/* we need the monotonic time, but the kernel returns system time. */
+		*use_time = time_monotonic(NULL) - (time(NULL) - policy->curlft.use_time);
+	}
+	else
+	{
+		*use_time = 0;
+	}
+
+	free(out);
+	return SUCCESS;
+}
+
+METHOD(kernel_ipsec_t, del_policy, status_t,
+		private_ipsec_offload_ipsec_t *this, kernel_ipsec_policy_id_t *id,
+		kernel_ipsec_manage_policy_t *data)
+{
+	policy_entry_t *current, policy;
+	enumerator_t *enumerator;
+	policy_sa_t *mapping;
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct xfrm_userpolicy_id *policy_id;
+	bool is_installed = TRUE;
+	uint32_t priority, auto_priority, cur_priority;
+	ipsec_sa_t assigned_sa = {
+		.src = data->src,
+		.dst = data->dst,
+		.mark = id->mark,
+		.if_id = id->if_id,
+		.cfg = *data->sa,
+	};
+	char markstr[32] = "";
+	int use_count;
+	status_t status = SUCCESS;
+
+	format_mark(markstr, sizeof(markstr), id->mark);
+
+	DBG2(DBG_KNL, "deleting policy %R === %R %N%s", id->src_ts, id->dst_ts,
+			policy_dir_names, id->dir, markstr);
+
+	/* create a policy */
+	memset(&policy, 0, sizeof(policy_entry_t));
+	policy.sel = ts2selector(id->src_ts, id->dst_ts, id->interface);
+	policy.mark = id->mark.value & id->mark.mask;
+	policy.if_id = id->if_id;
+	policy.direction = id->dir;
+	/* find the policy */
+	this->mutex->lock(this->mutex);
+	current = this->policies->get(this->policies, &policy);
+	if (!current)
+	{
+		DBG1(DBG_KNL, "deleting policy %R === %R %N%s failed, not found",
+				id->src_ts, id->dst_ts, policy_dir_names, id->dir, markstr);
+		this->mutex->unlock(this->mutex);
+		return NOT_FOUND;
+	}
+	current->waiting++;
+	while (current->working)
+	{
+		this->condvar->wait(this->condvar, this->mutex);
+	}
+	current->working = TRUE;
+	current->waiting--;
+
+	/* remove mapping to SA by reqid and priority */
+	auto_priority = get_priority(current, data->prio,id->interface);
+	priority = this->get_priority ? this->get_priority(id, data)
+		: data->manual_prio;
+	priority = priority ?: auto_priority;
+
+	enumerator = current->used_by->create_enumerator(current->used_by);
+	while (enumerator->enumerate(enumerator, (void**)&mapping))
+	{
+		if (priority == mapping->priority &&
+				auto_priority == mapping->auto_priority &&
+				data->type == mapping->type &&
+				ipsec_sa_equals(mapping->sa, &assigned_sa))
+		{
+			current->used_by->remove_at(current->used_by, enumerator);
+			policy_sa_destroy(mapping, id->dir, this);
+			break;
+		}
+		if (is_installed)
+		{
+			cur_priority = mapping->priority;
+			is_installed = FALSE;
+		}
+	}
+	enumerator->destroy(enumerator);
+
+	use_count = current->used_by->get_count(current->used_by);
+	if (use_count > 0)
+	{	/* policy is used by more SAs, keep in kernel */
+		DBG2(DBG_KNL, "policy still used by another CHILD_SA, not removed");
+		if (!is_installed)
+		{	/* no need to update as the policy was not installed for this SA */
+			policy_change_done(this, current);
+			DBG2(DBG_KNL, "not updating policy %R === %R %N%s [priority %u, "
+					"refcount %d]", id->src_ts, id->dst_ts, policy_dir_names,
+					id->dir, markstr, cur_priority, use_count);
+			return SUCCESS;
+		}
+		current->used_by->get_first(current->used_by, (void**)&mapping);
+		current->reqid = mapping->sa->cfg.reqid;
+
+		DBG2(DBG_KNL, "updating policy %R === %R %N%s [priority %u, "
+				"refcount %d]", id->src_ts, id->dst_ts, policy_dir_names, id->dir,
+				markstr, mapping->priority, use_count);
+
+		if (add_policy_internal(this, current, mapping, TRUE) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "unable to update policy %R === %R %N%s",
+					id->src_ts, id->dst_ts, policy_dir_names, id->dir, markstr);
+			return FAILED;
+		}
+		return SUCCESS;
+	}
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_DELPOLICY;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userpolicy_id));
+
+	policy_id = NLMSG_DATA(hdr);
+	policy_id->sel = current->sel;
+	policy_id->dir = id->dir;
+
+	if (!add_mark(hdr, sizeof(request), id->mark))
+	{
+		policy_change_done(this, current);
+		return FAILED;
+	}
+	if (id->if_id && !add_uint32(hdr, sizeof(request), XFRMA_IF_ID, id->if_id))
+	{
+		policy_change_done(this, current);
+		return FAILED;
+	}
+
+	if (current->route)
+	{
+		route_entry_t *route = current->route;
+		if (charon->kernel->del_route(charon->kernel, route->dst_net,
+					route->prefixlen, route->gateway,
+					route->src_ip, route->if_name,
+					route->pass) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "error uninstalling route installed with policy "
+					"%R === %R %N%s", id->src_ts, id->dst_ts, policy_dir_names,
+					id->dir, markstr);
+		}
+	}
+	this->mutex->unlock(this->mutex);
+
+	DBG2(DBG_KNL,"hello########## %s, %s , %d #############\n",__FILE__, __func__, __LINE__);
+	if (this->socket_xfrm->send_ack(this->socket_xfrm, hdr) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to delete policy %R === %R %N%s", id->src_ts,
+				id->dst_ts, policy_dir_names, id->dir, markstr);
+		status = FAILED;
+	}
+
+	this->mutex->lock(this->mutex);
+	if (!current->waiting)
+	{	/* only if no other thread still needs the policy */
+		this->policies->remove(this->policies, current);
+		policy_entry_destroy(this, current);
+		this->mutex->unlock(this->mutex);
+	}
+	else
+	{
+		policy_change_done(this, current);
+	}
+	return status;
+}
+
+METHOD(kernel_ipsec_t, flush_policies, status_t,
+		private_ipsec_offload_ipsec_t *this)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+
+	memset(&request, 0, sizeof(request));
+
+	DBG2(DBG_KNL, "flushing all policies from SPD");
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_FLUSHPOLICY;
+	hdr->nlmsg_len = NLMSG_LENGTH(0); /* no data associated */
+
+	/* by adding an rtattr of type  XFRMA_POLICY_TYPE we could restrict this
+	 * to main or sub policies (default is main) */
+
+	DBG2(DBG_KNL,"hello########## %s, %s , %d #############\n",__FILE__, __func__, __LINE__);
+	if (this->socket_xfrm->send_ack(this->socket_xfrm, hdr) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to flush SPD entries");
+		return FAILED;
+	}
+	return SUCCESS;
+}
+
+/**
+ * Bypass socket using a per-socket policy
+ */
+static bool add_socket_bypass(private_ipsec_offload_ipsec_t *this,
+		int fd, int family)
+{
+	struct xfrm_userpolicy_info policy;
+	u_int sol, ipsec_policy;
+
+	switch (family)
+	{
+		case AF_INET:
+			sol = SOL_IP;
+			ipsec_policy = IP_XFRM_POLICY;
+			break;
+		case AF_INET6:
+			sol = SOL_IPV6;
+			ipsec_policy = IPV6_XFRM_POLICY;
+			break;
+		default:
+			return FALSE;
+	}
+
+	memset(&policy, 0, sizeof(policy));
+	policy.action = XFRM_POLICY_ALLOW;
+	policy.sel.family = family;
+
+	policy.dir = XFRM_POLICY_OUT;
+	if (setsockopt(fd, sol, ipsec_policy, &policy, sizeof(policy)) < 0)
+	{
+		DBG1(DBG_KNL, "unable to set IPSEC_POLICY on socket: %s (%d)",
+				strerror(errno), errno);
+		return FALSE;
+	}
+	policy.dir = XFRM_POLICY_IN;
+	if (setsockopt(fd, sol, ipsec_policy, &policy, sizeof(policy)) < 0)
+	{
+		DBG1(DBG_KNL, "unable to set IPSEC_POLICY on socket: %s (%d)",
+				strerror(errno), errno);
+		return FALSE;
+	}
+	return TRUE;
+}
+
+/**
+ * Port based IKE bypass policy
+ */
+typedef struct {
+	/** address family */
+	int family;
+	/** layer 4 protocol */
+	int proto;
+	/** port number, network order */
+	uint16_t port;
+} bypass_t;
+
+/**
+ * Add or remove a bypass policy from/to kernel
+ */
+static bool manage_bypass(private_ipsec_offload_ipsec_t *this,
+		int type, policy_dir_t dir, bypass_t *bypass)
+{
+	netlink_buf_t request;
+	struct xfrm_selector *sel;
+	struct nlmsghdr *hdr;
+
+	memset(&request, 0, sizeof(request));
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = type;
+
+	if (type == XFRM_MSG_NEWPOLICY)
+	{
+		struct xfrm_userpolicy_info *policy;
+
+		hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userpolicy_info));
+
+		policy = NLMSG_DATA(hdr);
+		policy->dir = dir;
+		policy->priority = 32;
+		policy->action = XFRM_POLICY_ALLOW;
+		policy->share = XFRM_SHARE_ANY;
+
+		policy->lft.soft_byte_limit = XFRM_INF;
+		policy->lft.soft_packet_limit = XFRM_INF;
+		policy->lft.hard_byte_limit = XFRM_INF;
+		policy->lft.hard_packet_limit = XFRM_INF;
+
+		sel = &policy->sel;
+	}
+	else /* XFRM_MSG_DELPOLICY */
+	{
+		struct xfrm_userpolicy_id *policy;
+
+		hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct xfrm_userpolicy_id));
+
+		policy = NLMSG_DATA(hdr);
+		policy->dir = dir;
+
+		sel = &policy->sel;
+	}
+
+	sel->family = bypass->family;
+	sel->proto = bypass->proto;
+	if (dir == POLICY_IN)
+	{
+		sel->dport = bypass->port;
+		sel->dport_mask = 0xffff;
+	}
+	else
+	{
+		sel->sport = bypass->port;
+		sel->sport_mask = 0xffff;
+	}
+	return this->socket_xfrm->send_ack(this->socket_xfrm, hdr) == SUCCESS;
+}
+
+/**
+ * Bypass socket using a port-based bypass policy
+ */
+static bool add_port_bypass(private_ipsec_offload_ipsec_t *this,
+		int fd, int family)
+{
+	union {
+		struct sockaddr sa;
+		struct sockaddr_in in;
+		struct sockaddr_in6 in6;
+	} saddr;
+	socklen_t len;
+	bypass_t bypass = {
+		.family = family,
+	};
+
+	len = sizeof(saddr);
+	if (getsockname(fd, &saddr.sa, &len) != 0)
+	{
+		return FALSE;
+	}
+#ifdef SO_PROTOCOL /* since 2.6.32 */
+	len = sizeof(bypass.proto);
+	if (getsockopt(fd, SOL_SOCKET, SO_PROTOCOL, &bypass.proto, &len) != 0)
+#endif
+	{	/* assume UDP if SO_PROTOCOL not supported */
+		bypass.proto = IPPROTO_UDP;
+	}
+	switch (family)
+	{
+		case AF_INET:
+			bypass.port = saddr.in.sin_port;
+			break;
+		case AF_INET6:
+			bypass.port = saddr.in6.sin6_port;
+			break;
+		default:
+			return FALSE;
+	}
+
+	if (!manage_bypass(this, XFRM_MSG_NEWPOLICY, POLICY_IN, &bypass))
+	{
+		return FALSE;
+	}
+	if (!manage_bypass(this, XFRM_MSG_NEWPOLICY, POLICY_OUT, &bypass))
+	{
+		manage_bypass(this, XFRM_MSG_DELPOLICY, POLICY_IN, &bypass);
+		return FALSE;
+	}
+	array_insert(this->bypass, ARRAY_TAIL, &bypass);
+
+	return TRUE;
+}
+
+/**
+ * Remove installed port based bypass policy
+ */
+static void remove_port_bypass(bypass_t *bypass, int idx,
+		private_ipsec_offload_ipsec_t *this)
+{
+	manage_bypass(this, XFRM_MSG_DELPOLICY, POLICY_OUT, bypass);
+	manage_bypass(this, XFRM_MSG_DELPOLICY, POLICY_IN, bypass);
+}
+
+METHOD(kernel_ipsec_t, bypass_socket, bool,
+		private_ipsec_offload_ipsec_t *this, int fd, int family)
+{
+	if (lib->settings->get_bool(lib->settings,
+				"%s.plugins.kernel-netlink.port_bypass", FALSE, lib->ns))
+	{
+		return add_port_bypass(this, fd, family);
+	}
+	return add_socket_bypass(this, fd, family);
+}
+
+METHOD(kernel_ipsec_t, enable_udp_decap, bool,
+		private_ipsec_offload_ipsec_t *this, int fd, int family, uint16_t port)
+{
+	int type = UDP_ENCAP_ESPINUDP;
+
+	if (setsockopt(fd, SOL_UDP, UDP_ENCAP, &type, sizeof(type)) < 0)
+	{
+		DBG1(DBG_KNL, "unable to set UDP_ENCAP: %s", strerror(errno));
+		return FALSE;
+	}
+	return TRUE;
+}
+
+METHOD(kernel_ipsec_t, destroy, void,
+		private_ipsec_offload_ipsec_t *this)
+{
+	enumerator_t *enumerator;
+	policy_entry_t *policy;
+
+	array_destroy_function(this->bypass,
+			(array_callback_t)remove_port_bypass, this);
+	if (this->socket_xfrm_events > 0)
+	{
+		lib->watcher->remove(lib->watcher, this->socket_xfrm_events);
+		close(this->socket_xfrm_events);
+	}
+	DESTROY_IF(this->socket_xfrm);
+	enumerator = this->policies->create_enumerator(this->policies);
+	while (enumerator->enumerate(enumerator, &policy, &policy))
+	{
+		policy_entry_destroy(this, policy);
+	}
+	enumerator->destroy(enumerator);
+	this->policies->destroy(this->policies);
+	this->sas->destroy(this->sas);
+	this->condvar->destroy(this->condvar);
+	this->mutex->destroy(this->mutex);
+	free(this);
+}
+
+/**
+ * Get the currently configured SPD hashing thresholds for an address family
+ */
+static bool get_spd_hash_thresh(private_ipsec_offload_ipsec_t *this,
+		int type, uint8_t *lbits, uint8_t *rbits)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out;
+	struct xfrmu_spdhthresh *thresh;
+	struct rtattr *rta;
+	size_t len, rtasize;
+	bool success = FALSE;
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = XFRM_MSG_GETSPDINFO;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(uint32_t));
+
+	if (this->socket_xfrm->send(this->socket_xfrm, hdr, &out, &len) == SUCCESS)
+	{
+		hdr = out;
+		while (NLMSG_OK(hdr, len))
+		{
+			switch (hdr->nlmsg_type)
+			{
+				case XFRM_MSG_NEWSPDINFO:
+					{
+						rta = XFRM_RTA(hdr, uint32_t);
+						rtasize = XFRM_PAYLOAD(hdr, uint32_t);
+						while (RTA_OK(rta, rtasize))
+						{
+							if (rta->rta_type == type &&
+									RTA_PAYLOAD(rta) == sizeof(*thresh))
+							{
+								thresh = RTA_DATA(rta);
+								*lbits = thresh->lbits;
+								*rbits = thresh->rbits;
+								success = TRUE;
+								break;
+							}
+							rta = RTA_NEXT(rta, rtasize);
+						}
+						break;
+					}
+				case NLMSG_ERROR:
+					{
+						struct nlmsgerr *err = NLMSG_DATA(hdr);
+						DBG1(DBG_KNL, "getting SPD hash threshold failed: %s (%d)",
+								strerror(-err->error), -err->error);
+						break;
+					}
+				default:
+					hdr = NLMSG_NEXT(hdr, len);
+					continue;
+				case NLMSG_DONE:
+					break;
+			}
+			break;
+		}
+		free(out);
+	}
+	return success;
+}
+
+/**
+ * Configure SPD hashing threshold for an address family
+ */
+static void setup_spd_hash_thresh(private_ipsec_offload_ipsec_t *this,
+		char *key, int type, uint8_t def)
+{
+	struct xfrmu_spdhthresh *thresh;
+	struct nlmsghdr *hdr;
+	netlink_buf_t request;
+	uint8_t lbits, rbits;
+
+	if (!get_spd_hash_thresh(this, type, &lbits, &rbits))
+	{
+		return;
+	}
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = XFRM_MSG_NEWSPDINFO;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(uint32_t));
+
+	thresh = netlink_reserve(hdr, sizeof(request), type, sizeof(*thresh));
+	thresh->lbits = lib->settings->get_int(lib->settings,
+			"%s.plugins.kernel-netlink.spdh_thresh.%s.lbits",
+			def, lib->ns, key);
+	thresh->rbits = lib->settings->get_int(lib->settings,
+			"%s.plugins.kernel-netlink.spdh_thresh.%s.rbits",
+			def, lib->ns, key);
+	if (thresh->lbits != lbits || thresh->rbits != rbits)
+	{
+		if (this->socket_xfrm->send_ack(this->socket_xfrm, hdr) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "setting SPD hash threshold failed");
+		}
+	}
+}
+
+/*
+ * Described in header.
+ */
+ipsec_offload_ipsec_t *ipsec_offload_ipsec_create()
+{
+	private_ipsec_offload_ipsec_t *this;
+	bool register_for_events = TRUE;
+
+	INIT(this,
+			.public = {
+			.interface = {
+			.get_features = _get_features,
+			.get_spi = _get_spi,
+			.get_cpi = _get_cpi,
+			.add_sa  = _add_sa,
+			.update_sa = _update_sa,
+			.query_sa = _query_sa,
+			.del_sa = _del_sa,
+			.flush_sas = _flush_sas,
+			.add_policy = _add_policy,
+			.query_policy = _query_policy,
+			.del_policy = _del_policy,
+			.flush_policies = _flush_policies,
+			.bypass_socket = _bypass_socket,
+			.enable_udp_decap = _enable_udp_decap,
+			.destroy = _destroy,
+			},
+			},
+			.policies = hashtable_create((hashtable_hash_t)policy_hash,
+				(hashtable_equals_t)policy_equals, 32),
+			.sas = hashtable_create((hashtable_hash_t)ipsec_sa_hash,
+					(hashtable_equals_t)ipsec_sa_equals, 32),
+			.bypass = array_create(sizeof(bypass_t), 0),
+			.mutex = mutex_create(MUTEX_TYPE_DEFAULT),
+			.condvar = condvar_create(CONDVAR_TYPE_DEFAULT),
+			.get_priority = dlsym(RTLD_DEFAULT,
+					"kernel_netlink_get_priority_custom"),
+			.policy_update = lib->settings->get_bool(lib->settings,
+					"%s.plugins.kernel-netlink.policy_update", FALSE, lib->ns),
+			.install_routes = lib->settings->get_bool(lib->settings,
+					"%s.install_routes", TRUE, lib->ns),
+			.proto_port_transport = lib->settings->get_bool(lib->settings,
+					"%s.plugins.kernel-netlink.set_proto_port_transport_sa",
+					FALSE, lib->ns),
+			);
+
+	if (streq(lib->ns, "starter"))
+	{	/* starter has no threads, so we do not register for kernel events */
+		register_for_events = FALSE;
+	}
+
+	this->socket_xfrm = netlink_socket_create(NETLINK_XFRM, xfrm_msg_names,
+			lib->settings->get_bool(lib->settings,
+				"%s.plugins.kernel-netlink.parallel_xfrm", FALSE, lib->ns));
+	if (!this->socket_xfrm)
+	{
+		destroy(this);
+		return NULL;
+	}
+
+	setup_spd_hash_thresh(this, "ipv4", XFRMA_SPD_IPV4_HTHRESH, 32);
+	setup_spd_hash_thresh(this, "ipv6", XFRMA_SPD_IPV6_HTHRESH, 128);
+
+	if (register_for_events)
+	{
+		struct sockaddr_nl addr;
+
+		memset(&addr, 0, sizeof(addr));
+		addr.nl_family = AF_NETLINK;
+
+		/* create and bind XFRM socket for ACQUIRE, EXPIRE, MIGRATE & MAPPING */
+		this->socket_xfrm_events = socket(AF_NETLINK, SOCK_RAW, NETLINK_XFRM);
+		if (this->socket_xfrm_events <= 0)
+		{
+			DBG1(DBG_KNL, "unable to create XFRM event socket: %s (%d)",
+					strerror(errno), errno);
+			destroy(this);
+			return NULL;
+		}
+		addr.nl_groups = XFRMNLGRP(ACQUIRE) | XFRMNLGRP(EXPIRE) |
+			XFRMNLGRP(MIGRATE) | XFRMNLGRP(MAPPING);
+		if (bind(this->socket_xfrm_events, (struct sockaddr*)&addr, sizeof(addr)))
+		{
+			DBG1(DBG_KNL, "unable to bind XFRM event socket: %s (%d)",
+					strerror(errno), errno);
+			destroy(this);
+			return NULL;
+		}
+		lib->watcher->add(lib->watcher, this->socket_xfrm_events, WATCHER_READ,
+				(watcher_cb_t)receive_events, this);
+	}
+
+	netlink_find_offload_feature(lib->settings->get_str(lib->settings,
+				"%s.plugins.kernel-netlink.hw_offload_feature_interface",
+				"lo", lib->ns));
+
+	return &this->public;
+}
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.h b/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.h
new file mode 100644
index 000000000..406ef1c8b
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_ipsec.h
@@ -0,0 +1,34 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+#ifndef IPSEC_OFFLOAD_IPSEC_H_
+#define IPSEC_OFFLOAD_IPSEC_H_
+
+#include <kernel/kernel_ipsec.h>
+
+typedef struct ipsec_offload_ipsec_t ipsec_offload_ipsec_t;
+
+/**
+ * Implementation of the kernel ipsec interface using Netlink.
+ */
+struct ipsec_offload_ipsec_t {
+
+        /**
+         * Implements kernel_ipsec_t interface
+         */
+        kernel_ipsec_t interface;
+};
+
+/**
+ * Create a ipsec offload ipsec interface instance.
+ *
+ * @return                      ipsec_offload_ipsec_t instance
+ */
+ipsec_offload_ipsec_t *ipsec_offload_ipsec_create();
+
+#endif /** KERNEL_NETLINK_IPSEC_H_ @}*/
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.c b/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.c
new file mode 100644
index 000000000..51e955f65
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.c
@@ -0,0 +1,3218 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#include <sys/socket.h>
+#include <sys/utsname.h>
+#include <linux/netlink.h>
+#include <linux/rtnetlink.h>
+#include <linux/if_addrlabel.h>
+#include <unistd.h>
+#include <errno.h>
+#include <net/if.h>
+#ifdef HAVE_LINUX_FIB_RULES_H
+#include <linux/fib_rules.h>
+#endif
+
+#include "ipsec_offload_net.h"
+#include "ipsec_offload_shared.h"
+
+#include <daemon.h>
+#include <utils/debug.h>
+#include <threading/mutex.h>
+#include <threading/rwlock.h>
+#include <threading/rwlock_condvar.h>
+#include <threading/spinlock.h>
+#include <collections/hashtable.h>
+#include <collections/linked_list.h>
+#include <processing/jobs/callback_job.h>
+
+/** delay before firing roam events (ms) */
+#define ROAM_DELAY 100
+
+/** delay before reinstalling routes (ms) */
+#define ROUTE_DELAY 100
+
+/** maximum recursion when searching for addresses in get_route() */
+#define MAX_ROUTE_RECURSION 2
+
+#ifndef ROUTING_TABLE
+#define ROUTING_TABLE 0
+#endif
+
+#ifndef ROUTING_TABLE_PRIO
+#define ROUTING_TABLE_PRIO 0
+#endif
+
+/** multicast groups (for groups > 31 setsockopt has to be used) */
+#define nl_group(group) (1 << (group - 1))
+
+ENUM(rt_msg_names, RTM_NEWLINK, RTM_GETRULE,
+	"RTM_NEWLINK",
+	"RTM_DELLINK",
+	"RTM_GETLINK",
+	"RTM_SETLINK",
+	"RTM_NEWADDR",
+	"RTM_DELADDR",
+	"RTM_GETADDR",
+	"23",
+	"RTM_NEWROUTE",
+	"RTM_DELROUTE",
+	"RTM_GETROUTE",
+	"27",
+	"RTM_NEWNEIGH",
+	"RTM_DELNEIGH",
+	"RTM_GETNEIGH",
+	"31",
+	"RTM_NEWRULE",
+	"RTM_DELRULE",
+	"RTM_GETRULE",
+);
+
+typedef struct addr_entry_t addr_entry_t;
+
+/**
+ * IP address in an iface_entry_t
+ */
+struct addr_entry_t {
+
+	/** the ip address */
+	host_t *ip;
+
+	/** address flags */
+	u_char flags;
+
+	/** scope of the address */
+	u_char scope;
+
+	/** number of times this IP is used, if virtual (i.e. managed by us) */
+	u_int refcount;
+
+	/** TRUE once it is installed, if virtual */
+	bool installed;
+};
+
+/**
+ * destroy a addr_entry_t object
+ */
+static void addr_entry_destroy(addr_entry_t *this)
+{
+	this->ip->destroy(this->ip);
+	free(this);
+}
+
+typedef struct iface_entry_t iface_entry_t;
+
+/**
+ * A network interface on this system, containing addr_entry_t's
+ */
+struct iface_entry_t {
+
+	/** interface index */
+	int ifindex;
+
+	/** name of the interface */
+	char ifname[IFNAMSIZ];
+
+	/** interface flags, as in netdevice(7) SIOCGIFFLAGS */
+	u_int flags;
+
+	/** list of addresses as host_t */
+	linked_list_t *addrs;
+
+	/** TRUE if usable by config */
+	bool usable;
+};
+
+/**
+ * destroy an interface entry
+ */
+static void iface_entry_destroy(iface_entry_t *this)
+{
+	this->addrs->destroy_function(this->addrs, (void*)addr_entry_destroy);
+	free(this);
+}
+
+CALLBACK(iface_entry_by_index, bool,
+	iface_entry_t *this, va_list args)
+{
+	int ifindex;
+
+	VA_ARGS_VGET(args, ifindex);
+	return this->ifindex == ifindex;
+}
+
+CALLBACK(iface_entry_by_name, bool,
+	iface_entry_t *this, va_list args)
+{
+	char *ifname;
+
+	VA_ARGS_VGET(args, ifname);
+	return streq(this->ifname, ifname);
+}
+
+/**
+ * check if an interface is up
+ */
+static inline bool iface_entry_up(iface_entry_t *iface)
+{
+	return (iface->flags & IFF_UP) == IFF_UP;
+}
+
+/**
+ * check if an interface is up and usable
+ */
+static inline bool iface_entry_up_and_usable(iface_entry_t *iface)
+{
+	return iface->usable && iface_entry_up(iface);
+}
+
+typedef struct addr_map_entry_t addr_map_entry_t;
+
+/**
+ * Entry that maps an IP address to an interface entry
+ */
+struct addr_map_entry_t {
+	/** The IP address */
+	host_t *ip;
+
+	/** The address entry for this IP address */
+	addr_entry_t *addr;
+
+	/** The interface this address is installed on */
+	iface_entry_t *iface;
+};
+
+/**
+ * Hash a addr_map_entry_t object, all entries with the same IP address
+ * are stored in the same bucket
+ */
+static u_int addr_map_entry_hash(addr_map_entry_t *this)
+{
+	return chunk_hash(this->ip->get_address(this->ip));
+}
+
+/**
+ * Compare two addr_map_entry_t objects, two entries are equal if they are
+ * installed on the same interface
+ */
+static bool addr_map_entry_equals(addr_map_entry_t *a, addr_map_entry_t *b)
+{
+	return a->iface->ifindex == b->iface->ifindex &&
+		   a->ip->ip_equals(a->ip, b->ip);
+}
+
+/**
+ * Used with get_match this finds an address entry if it is installed on
+ * an up and usable interface
+ */
+static bool addr_map_entry_match_up_and_usable(addr_map_entry_t *a,
+											   addr_map_entry_t *b)
+{
+	return iface_entry_up_and_usable(b->iface) &&
+		   a->ip->ip_equals(a->ip, b->ip);
+}
+
+/**
+ * Used with get_match this finds an address entry if it is installed on
+ * any active local interface
+ */
+static bool addr_map_entry_match_up(addr_map_entry_t *a, addr_map_entry_t *b)
+{
+	return iface_entry_up(b->iface) && a->ip->ip_equals(a->ip, b->ip);
+}
+
+/**
+ * Used with get_match this finds an address entry if it is installed on
+ * any local interface
+ */
+static bool addr_map_entry_match(addr_map_entry_t *a, addr_map_entry_t *b)
+{
+	return a->ip->ip_equals(a->ip, b->ip);
+}
+
+typedef struct net_change_t net_change_t;
+
+/**
+ * Queued network changes
+ */
+struct net_change_t {
+	/** Name of the interface that got activated (or an IP appeared on) */
+	char *if_name;
+};
+
+/**
+ * Destroy a net_change_t object
+ */
+static void net_change_destroy(net_change_t *this)
+{
+	free(this->if_name);
+	free(this);
+}
+
+/**
+ * Hash a net_change_t object
+ */
+static u_int net_change_hash(net_change_t *this)
+{
+	return chunk_hash(chunk_create(this->if_name, strlen(this->if_name)));
+}
+
+/**
+ * Compare two net_change_t objects
+ */
+static bool net_change_equals(net_change_t *a, net_change_t *b)
+{
+	return streq(a->if_name, b->if_name);
+}
+
+typedef struct private_ipsec_offload_net_t private_ipsec_offload_net_t;
+
+/**
+ * Private variables and functions of ipsec_offload_net class.
+ */
+struct private_ipsec_offload_net_t {
+	/**
+	 * Public part of the kernel_netlink_net_t object.
+	 */
+	ipsec_offload_net_t public;
+
+	/**
+	 * lock to access various lists and maps
+	 */
+	rwlock_t *lock;
+
+	/**
+	 * condition variable to signal virtual IP add/removal
+	 */
+	rwlock_condvar_t *condvar;
+
+	/**
+	 * Cached list of interfaces and its addresses (iface_entry_t)
+	 */
+	linked_list_t *ifaces;
+
+	/**
+	 * Map for IP addresses to iface_entry_t objects (addr_map_entry_t)
+	 */
+	hashtable_t *addrs;
+
+	/**
+	 * Map for virtual IP addresses to iface_entry_t objects (addr_map_entry_t)
+	 */
+	hashtable_t *vips;
+
+	/**
+	 * netlink rt socket (routing)
+	 */
+	netlink_socket_t *socket;
+
+	/**
+	 * Netlink rt socket to receive address change events
+	 */
+	int socket_events;
+
+	/**
+	 * earliest time of the next roam event
+	 */
+	timeval_t next_roam;
+
+	/**
+	 * roam event due to address change
+	 */
+	bool roam_address;
+
+	/**
+	 * lock to check and update roam event time
+	 */
+	spinlock_t *roam_lock;
+
+	/**
+	 * routing table to install routes
+	 */
+	uint32_t routing_table;
+
+	/**
+	 * priority of used routing table
+	 */
+	uint32_t routing_table_prio;
+
+	/**
+	 * installed routes
+	 */
+	hashtable_t *routes;
+
+	/**
+	 * mutex for routes
+	 */
+	mutex_t *routes_lock;
+
+	/**
+	 * interface changes which may trigger route reinstallation
+	 */
+	hashtable_t *net_changes;
+
+	/**
+	 * mutex for route reinstallation triggers
+	 */
+	mutex_t *net_changes_lock;
+
+	/**
+	 * time of last route reinstallation
+	 */
+	timeval_t last_route_reinstall;
+
+	/**
+	 * whether to react to RTM_NEWROUTE or RTM_DELROUTE events
+	 */
+	bool process_route;
+
+	/**
+	 * whether to react to RTM_NEWRULE or RTM_DELRULE events
+	 */
+	bool process_rules;
+
+	/**
+	 * whether to trigger roam events
+	 */
+	bool roam_events;
+
+	/**
+	 * whether to install IPsec policy routes
+	 */
+	bool install_routes;
+
+	/**
+	 * whether to actually install virtual IPs
+	 */
+	bool install_virtual_ip;
+
+	/**
+	 * the name of the interface virtual IP addresses are installed on
+	 */
+	char *install_virtual_ip_on;
+
+	/**
+	 * whether preferred source addresses can be specified for IPv6 routes
+	 */
+	bool rta_prefsrc_for_ipv6;
+
+	/**
+	 * whether marks can be used in route lookups
+	 */
+	bool rta_mark;
+
+	/**
+	 * the mark excluded from the routing rule used for virtual IPs
+	 */
+	mark_t routing_mark;
+
+	/**
+	 * whether to prefer temporary IPv6 addresses over public ones
+	 */
+	bool prefer_temporary_addrs;
+
+	/**
+	 * list with routing tables to be excluded from route lookup
+	 */
+	linked_list_t *rt_exclude;
+
+	/**
+	 * MTU to set on installed routes
+	 */
+	uint32_t mtu;
+
+	/**
+	 * MSS to set on installed routes
+	 */
+	uint32_t mss;
+};
+
+/**
+ * Forward declaration
+ */
+static status_t manage_srcroute(private_ipsec_offload_net_t *this,
+								int nlmsg_type, int flags, chunk_t dst_net,
+								uint8_t prefixlen, host_t *gateway,
+								host_t *src_ip, char *if_name, bool pass);
+
+/**
+ * Clear the queued network changes.
+ */
+static void net_changes_clear(private_ipsec_offload_net_t *this)
+{
+	enumerator_t *enumerator;
+	net_change_t *change;
+
+	enumerator = this->net_changes->create_enumerator(this->net_changes);
+	while (enumerator->enumerate(enumerator, NULL, (void**)&change))
+	{
+		this->net_changes->remove_at(this->net_changes, enumerator);
+		net_change_destroy(change);
+	}
+	enumerator->destroy(enumerator);
+}
+
+/**
+ * Act upon queued network changes.
+ */
+static job_requeue_t reinstall_routes(private_ipsec_offload_net_t *this)
+{
+	enumerator_t *enumerator;
+	route_entry_t *route;
+
+	this->net_changes_lock->lock(this->net_changes_lock);
+	this->routes_lock->lock(this->routes_lock);
+
+	enumerator = this->routes->create_enumerator(this->routes);
+	while (enumerator->enumerate(enumerator, NULL, (void**)&route))
+	{
+		net_change_t *change, lookup = {
+			.if_name = route->if_name,
+		};
+		if (route->pass || !route->if_name)
+		{	/* no need to reinstall these, they don't reference interfaces */
+			continue;
+		}
+		/* check if a change for the outgoing interface is queued */
+		change = this->net_changes->get(this->net_changes, &lookup);
+		if (!change)
+		{	/* in case src_ip is not on the outgoing interface */
+			if (this->public.interface.get_interface(&this->public.interface,
+												route->src_ip, &lookup.if_name))
+			{
+				if (!streq(lookup.if_name, route->if_name))
+				{
+					change = this->net_changes->get(this->net_changes, &lookup);
+				}
+				free(lookup.if_name);
+			}
+		}
+		if (change)
+		{
+			manage_srcroute(this, RTM_NEWROUTE, NLM_F_CREATE | NLM_F_EXCL,
+							route->dst_net, route->prefixlen, route->gateway,
+							route->src_ip, route->if_name, route->pass);
+		}
+	}
+	enumerator->destroy(enumerator);
+	this->routes_lock->unlock(this->routes_lock);
+
+	net_changes_clear(this);
+	this->net_changes_lock->unlock(this->net_changes_lock);
+	return JOB_REQUEUE_NONE;
+}
+
+/**
+ * Queue route reinstallation caused by network changes for a given interface.
+ *
+ * The route reinstallation is delayed for a while and only done once for
+ * several calls during this delay, in order to avoid doing it too often.
+ * The interface name is freed.
+ */
+static void queue_route_reinstall(private_ipsec_offload_net_t *this,
+								  char *if_name)
+{
+	net_change_t *update, *found;
+	timeval_t now;
+	job_t *job;
+
+	INIT(update,
+		.if_name = if_name
+	);
+
+	this->net_changes_lock->lock(this->net_changes_lock);
+	found = this->net_changes->put(this->net_changes, update, update);
+	if (found)
+	{
+		net_change_destroy(found);
+	}
+	time_monotonic(&now);
+	if (timercmp(&now, &this->last_route_reinstall, >))
+	{
+		timeval_add_ms(&now, ROUTE_DELAY);
+		this->last_route_reinstall = now;
+
+		job = (job_t*)callback_job_create((callback_job_cb_t)reinstall_routes,
+										  this, NULL, NULL);
+		lib->scheduler->schedule_job_ms(lib->scheduler, job, ROUTE_DELAY);
+	}
+	this->net_changes_lock->unlock(this->net_changes_lock);
+}
+
+/**
+ * check if the given IP is known as virtual IP and currently installed
+ *
+ * this function will also return TRUE if the virtual IP entry disappeared.
+ * in that case the returned entry will be NULL.
+ *
+ * this->lock must be held when calling this function
+ */
+static bool is_vip_installed_or_gone(private_ipsec_offload_net_t *this,
+									 host_t *ip, addr_map_entry_t **entry)
+{
+	addr_map_entry_t lookup = {
+		.ip = ip,
+	};
+
+	*entry = this->vips->get_match(this->vips, &lookup,
+								  (void*)addr_map_entry_match);
+	if (*entry == NULL)
+	{	/* the virtual IP disappeared */
+		return TRUE;
+	}
+	return (*entry)->addr->installed;
+}
+
+/**
+ * check if the given IP is known as virtual IP
+ *
+ * this->lock must be held when calling this function
+ */
+static bool is_known_vip(private_ipsec_offload_net_t *this, host_t *ip)
+{
+	addr_map_entry_t lookup = {
+		.ip = ip,
+	};
+
+	return this->vips->get_match(this->vips, &lookup,
+								(void*)addr_map_entry_match) != NULL;
+}
+
+/**
+ * Add an address map entry
+ */
+static void addr_map_entry_add(hashtable_t *map, addr_entry_t *addr,
+							   iface_entry_t *iface)
+{
+	addr_map_entry_t *entry;
+
+	INIT(entry,
+		.ip = addr->ip,
+		.addr = addr,
+		.iface = iface,
+	);
+	entry = map->put(map, entry, entry);
+	free(entry);
+}
+
+/**
+ * Remove an address map entry
+ */
+static void addr_map_entry_remove(hashtable_t *map, addr_entry_t *addr,
+								  iface_entry_t *iface)
+{
+	addr_map_entry_t *entry, lookup = {
+		.ip = addr->ip,
+		.addr = addr,
+		.iface = iface,
+	};
+
+	entry = map->remove(map, &lookup);
+	free(entry);
+}
+
+/**
+ * Check if an address or net (addr with prefix net bits) is in
+ * subnet (net with net_len net bits)
+ */
+static bool addr_in_subnet(chunk_t addr, int prefix, chunk_t net, int net_len)
+{
+	static const u_char mask[] = { 0x00, 0x80, 0xc0, 0xe0, 0xf0, 0xf8, 0xfc, 0xfe };
+	int byte = 0;
+
+	if (net_len == 0)
+	{	/* any address matches a /0 network */
+		return TRUE;
+	}
+	if (addr.len != net.len || net_len > 8 * net.len || prefix < net_len)
+	{
+		return FALSE;
+	}
+	/* scan through all bytes in network order */
+	while (net_len > 0)
+	{
+		if (net_len < 8)
+		{
+			return (mask[net_len] & addr.ptr[byte]) == (mask[net_len] & net.ptr[byte]);
+		}
+		else
+		{
+			if (addr.ptr[byte] != net.ptr[byte])
+			{
+				return FALSE;
+			}
+			byte++;
+			net_len -= 8;
+		}
+	}
+	return TRUE;
+}
+
+/**
+ * Check if the given address is in subnet (net with net_len net bits)
+ */
+static bool host_in_subnet(host_t *host, chunk_t net, int net_len)
+{
+	chunk_t addr;
+
+	addr = host->get_address(host);
+	return addr_in_subnet(addr, addr.len * 8, net, net_len);
+}
+
+/**
+ * Determine the type or scope of the given unicast IP address.  This is not
+ * the same thing returned in rtm_scope/ifa_scope.
+ *
+ * We use return values as defined in RFC 6724 (referring to RFC 4291).
+ */
+static u_char get_scope(host_t *ip)
+{
+	chunk_t addr;
+
+	addr = ip->get_address(ip);
+	switch (addr.len)
+	{
+		case 4:
+			/* we use the mapping defined in RFC 6724, 3.2 */
+			if (addr.ptr[0] == 127)
+			{	/* link-local, same as the IPv6 loopback address */
+				return 2;
+			}
+			if (addr.ptr[0] == 169 && addr.ptr[1] == 254)
+			{	/* link-local */
+				return 2;
+			}
+			break;
+		case 16:
+			if (IN6_IS_ADDR_LOOPBACK((struct in6_addr*)addr.ptr))
+			{	/* link-local, according to RFC 4291, 2.5.3 */
+				return 2;
+			}
+			if (IN6_IS_ADDR_LINKLOCAL((struct in6_addr*)addr.ptr))
+			{
+				return 2;
+			}
+			if (IN6_IS_ADDR_SITELOCAL((struct in6_addr*)addr.ptr))
+			{	/* deprecated, according to RFC 4291, 2.5.7 */
+				return 5;
+			}
+			break;
+		default:
+			break;
+	}
+	/* global */
+	return 14;
+}
+
+/**
+ * Determine the label of the given unicast IP address.
+ *
+ * We currently only support the default table given in RFC 6724:
+ *
+ *  Prefix        Precedence Label
+ *  ::1/128               50     0
+ *  ::/0                  40     1
+ *  ::ffff:0:0/96         35     4
+ *  2002::/16             30     2
+ *  2001::/32              5     5
+ *  fc00::/7               3    13
+ *  ::/96                  1     3
+ *  fec0::/10              1    11
+ *  3ffe::/16              1    12
+ */
+static u_char get_label(host_t *ip)
+{
+	struct {
+		chunk_t net;
+		u_char prefix;
+		u_char label;
+	} priorities[] = {
+		/* priority table ordered by prefix */
+		/* ::1/128 */
+		{ chunk_from_chars(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01), 128, 0 },
+		/* ::ffff:0:0/96 */
+		{ chunk_from_chars(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00), 96, 4 },
+		/* ::/96 */
+		{ chunk_from_chars(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 96, 3 },
+		/* 2001::/32 */
+		{ chunk_from_chars(0x20, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 32, 5 },
+		/* 2002::/16 */
+		{ chunk_from_chars(0x20, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 16, 2 },
+		/* 3ffe::/16 */
+		{ chunk_from_chars(0x3f, 0xfe, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 16, 12 },
+		/* fec0::/10 */
+		{ chunk_from_chars(0xfe, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 10, 11 },
+		/* fc00::/7 */
+		{ chunk_from_chars(0xfc, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+						   0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00), 7, 13 },
+	};
+	int i;
+
+	for (i = 0; i < countof(priorities); i++)
+	{
+		if (host_in_subnet(ip, priorities[i].net, priorities[i].prefix))
+		{
+			return priorities[i].label;
+		}
+	}
+	/* ::/0 */
+	return 1;
+}
+
+/**
+ * Returns the length of the common prefix in bits up to the length of a's
+ * prefix, defined by RFC 6724 as the portion of the address not including the
+ * interface ID, which is 64-bit for most unicast addresses (see RFC 4291).
+ */
+static u_char common_prefix(host_t *a, host_t *b)
+{
+	chunk_t aa, ba;
+	u_char byte, bits = 0, match;
+
+	aa = a->get_address(a);
+	ba = b->get_address(b);
+	for (byte = 0; byte < 8; byte++)
+	{
+		if (aa.ptr[byte] != ba.ptr[byte])
+		{
+			match = aa.ptr[byte] ^ ba.ptr[byte];
+			for (bits = 8; match; match >>= 1)
+			{
+				bits--;
+			}
+			break;
+		}
+	}
+	return byte * 8 + bits;
+}
+
+/**
+ * Compare two IP addresses and return TRUE if the second address is the better
+ * choice of the two to reach the destination.
+ * For IPv6 we approximately follow RFC 6724.
+ */
+static bool is_address_better(private_ipsec_offload_net_t *this,
+							  addr_entry_t *a, addr_entry_t *b, host_t *d)
+{
+	u_char sa, sb, sd, la, lb, ld, pa, pb;
+
+	/* rule 2: prefer appropriate scope */
+	if (d)
+	{
+		sa = get_scope(a->ip);
+		sb = get_scope(b->ip);
+		sd = get_scope(d);
+		if (sa < sb)
+		{
+			return sa < sd;
+		}
+		else if (sb < sa)
+		{
+			return sb >= sd;
+		}
+	}
+	if (a->ip->get_family(a->ip) == AF_INET)
+	{	/* stop here for IPv4, default to addresses found earlier */
+		return FALSE;
+	}
+	/* rule 3: avoid deprecated addresses (RFC 4862) */
+	if ((a->flags & IFA_F_DEPRECATED) != (b->flags & IFA_F_DEPRECATED))
+	{
+		return a->flags & IFA_F_DEPRECATED;
+	}
+	/* rule 4 is not applicable as we don't know if an address is a home or
+	 * care-of addresses.
+	 * rule 5 does not apply as we only compare addresses from one interface
+	 */
+	/* rule 6: prefer matching label */
+	if (d)
+	{
+		la = get_label(a->ip);
+		lb = get_label(b->ip);
+		ld = get_label(d);
+		if (la == ld && lb != ld)
+		{
+			return FALSE;
+		}
+		else if (lb == ld && la != ld)
+		{
+			return TRUE;
+		}
+	}
+	/* rule 7: prefer temporary addresses (WE REVERSE THIS BY DEFAULT!) */
+	if ((a->flags & IFA_F_TEMPORARY) != (b->flags & IFA_F_TEMPORARY))
+	{
+		if (this->prefer_temporary_addrs)
+		{
+			return b->flags & IFA_F_TEMPORARY;
+		}
+		return a->flags & IFA_F_TEMPORARY;
+	}
+	/* rule 8: use longest matching prefix */
+	if (d)
+	{
+		pa = common_prefix(a->ip, d);
+		pb = common_prefix(b->ip, d);
+		if (pa != pb)
+		{
+			return pb > pa;
+		}
+	}
+	/* default to addresses found earlier */
+	return FALSE;
+}
+
+/**
+ * Get a non-virtual IP address on the given interfaces and optionally in a
+ * given subnet.
+ *
+ * If a candidate address is given, we first search for that address and if not
+ * found return the address as above.
+ * Returned host is a clone, has to be freed by caller.
+ *
+ * this->lock must be held when calling this function.
+ */
+static host_t *get_matching_address(private_ipsec_offload_net_t *this,
+									int *ifindex, int family, chunk_t net,
+									uint8_t mask, host_t *dest,
+									host_t *candidate)
+{
+	enumerator_t *ifaces, *addrs;
+	iface_entry_t *iface;
+	addr_entry_t *addr, *best = NULL;
+	bool candidate_matched = FALSE;
+
+	ifaces = this->ifaces->create_enumerator(this->ifaces);
+	while (ifaces->enumerate(ifaces, &iface))
+	{
+		if (iface->usable && (!ifindex || iface->ifindex == *ifindex))
+		{	/* only use matching interfaces not excluded by config */
+			addrs = iface->addrs->create_enumerator(iface->addrs);
+			while (addrs->enumerate(addrs, &addr))
+			{
+				if (addr->refcount ||
+					addr->ip->get_family(addr->ip) != family)
+				{	/* ignore virtual IP addresses and ensure family matches */
+					continue;
+				}
+				if (net.ptr && !host_in_subnet(addr->ip, net, mask))
+				{	/* optionally match a subnet */
+					continue;
+				}
+				if (candidate && candidate->ip_equals(candidate, addr->ip))
+				{	/* stop if we find the candidate */
+					best = addr;
+					candidate_matched = TRUE;
+					break;
+				}
+				else if (!best || is_address_better(this, best, addr, dest))
+				{
+					best = addr;
+				}
+			}
+			addrs->destroy(addrs);
+			if (ifindex || candidate_matched)
+			{
+				break;
+			}
+		}
+	}
+	ifaces->destroy(ifaces);
+	return best ? best->ip->clone(best->ip) : NULL;
+}
+
+/**
+ * Get a non-virtual IP address on the given interface.
+ *
+ * If a candidate address is given, we first search for that address and if not
+ * found return the address as above.
+ * Returned host is a clone, has to be freed by caller.
+ *
+ * this->lock must be held when calling this function.
+ */
+static host_t *get_interface_address(private_ipsec_offload_net_t *this,
+									 int ifindex, int family, host_t *dest,
+									 host_t *candidate)
+{
+	return get_matching_address(this, &ifindex, family, chunk_empty, 0, dest,
+								candidate);
+}
+
+/**
+ * Get a non-virtual IP address in the given subnet.
+ *
+ * If a candidate address is given, we first search for that address and if not
+ * found return the address as above.
+ * Returned host is a clone, has to be freed by caller.
+ *
+ * this->lock must be held when calling this function.
+ */
+static host_t *get_subnet_address(private_ipsec_offload_net_t *this,
+								  int family, chunk_t net, uint8_t mask,
+								  host_t *dest, host_t *candidate)
+{
+	return get_matching_address(this, NULL, family, net, mask, dest, candidate);
+}
+
+/**
+ * callback function that raises the delayed roam event
+ */
+static job_requeue_t roam_event(private_ipsec_offload_net_t *this)
+{
+	bool address;
+
+	this->roam_lock->lock(this->roam_lock);
+	address = this->roam_address;
+	this->roam_address = FALSE;
+	this->roam_lock->unlock(this->roam_lock);
+	charon->kernel->roam(charon->kernel, address);
+	return JOB_REQUEUE_NONE;
+}
+
+/**
+ * fire a roaming event. we delay it for a bit and fire only one event
+ * for multiple calls. otherwise we would create too many events.
+ */
+static void fire_roam_event(private_ipsec_offload_net_t *this, bool address)
+{
+	timeval_t now;
+	job_t *job;
+
+	if (!this->roam_events)
+	{
+		return;
+	}
+
+	time_monotonic(&now);
+	this->roam_lock->lock(this->roam_lock);
+	this->roam_address |= address;
+	if (!timercmp(&now, &this->next_roam, >))
+	{
+		this->roam_lock->unlock(this->roam_lock);
+		return;
+	}
+	timeval_add_ms(&now, ROAM_DELAY);
+	this->next_roam = now;
+	this->roam_lock->unlock(this->roam_lock);
+
+	job = (job_t*)callback_job_create((callback_job_cb_t)roam_event,
+									  this, NULL, NULL);
+	lib->scheduler->schedule_job_ms(lib->scheduler, job, ROAM_DELAY);
+}
+
+/**
+ * check if an interface with a given index is up and usable
+ *
+ * this->lock must be locked when calling this function
+ */
+static bool is_interface_up_and_usable(private_ipsec_offload_net_t *this,
+									   int index)
+{
+	iface_entry_t *iface;
+
+	if (this->ifaces->find_first(this->ifaces, iface_entry_by_index,
+								 (void**)&iface, index))
+	{
+		return iface_entry_up_and_usable(iface);
+	}
+	return FALSE;
+}
+
+/**
+ * unregister the current addr_entry_t from the hashtable it is stored in
+ *
+ * this->lock must be locked when calling this function
+ */
+CALLBACK(addr_entry_unregister, void,
+	addr_entry_t *addr, va_list args)
+{
+	private_ipsec_offload_net_t *this;
+	iface_entry_t *iface;
+
+	VA_ARGS_VGET(args, iface, this);
+	if (addr->refcount)
+	{
+		addr_map_entry_remove(this->vips, addr, iface);
+		this->condvar->broadcast(this->condvar);
+		return;
+	}
+	addr_map_entry_remove(this->addrs, addr, iface);
+}
+
+/**
+ * process RTM_NEWLINK/RTM_DELLINK from kernel
+ */
+static void process_link(private_ipsec_offload_net_t *this,
+						 struct nlmsghdr *hdr, bool event)
+{
+	struct ifinfomsg* msg = NLMSG_DATA(hdr);
+	struct rtattr *rta = IFLA_RTA(msg);
+	size_t rtasize = IFLA_PAYLOAD (hdr);
+	enumerator_t *enumerator;
+	iface_entry_t *current, *entry = NULL;
+	char *name = NULL;
+	bool update = FALSE, update_routes = FALSE;
+
+	while (RTA_OK(rta, rtasize))
+	{
+		switch (rta->rta_type)
+		{
+			case IFLA_IFNAME:
+				name = RTA_DATA(rta);
+				break;
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+	if (!name)
+	{
+		name = "(unknown)";
+	}
+
+	this->lock->write_lock(this->lock);
+	switch (hdr->nlmsg_type)
+	{
+		case RTM_NEWLINK:
+		{
+			if (!this->ifaces->find_first(this->ifaces, iface_entry_by_index,
+										 (void**)&entry, msg->ifi_index))
+			{
+				INIT(entry,
+					.ifindex = msg->ifi_index,
+					.addrs = linked_list_create(),
+				);
+				this->ifaces->insert_last(this->ifaces, entry);
+			}
+			strncpy(entry->ifname, name, IFNAMSIZ);
+			entry->ifname[IFNAMSIZ-1] = '\0';
+			entry->usable = charon->kernel->is_interface_usable(charon->kernel,
+																name);
+			if (event && entry->usable)
+			{
+				if (!(entry->flags & IFF_UP) && (msg->ifi_flags & IFF_UP))
+				{
+					update = update_routes = TRUE;
+					DBG1(DBG_KNL, "interface %s activated", name);
+				}
+				if ((entry->flags & IFF_UP) && !(msg->ifi_flags & IFF_UP))
+				{
+					update = TRUE;
+					DBG1(DBG_KNL, "interface %s deactivated", name);
+				}
+			}
+			entry->flags = msg->ifi_flags;
+			break;
+		}
+		case RTM_DELLINK:
+		{
+			enumerator = this->ifaces->create_enumerator(this->ifaces);
+			while (enumerator->enumerate(enumerator, &current))
+			{
+				if (current->ifindex == msg->ifi_index)
+				{
+					if (event && current->usable)
+					{
+						update = TRUE;
+						DBG1(DBG_KNL, "interface %s deleted", current->ifname);
+					}
+					/* TODO: move virtual IPs installed on this interface to
+					 * another interface? */
+					this->ifaces->remove_at(this->ifaces, enumerator);
+					current->addrs->invoke_function(current->addrs,
+										addr_entry_unregister, current, this);
+					iface_entry_destroy(current);
+					break;
+				}
+			}
+			enumerator->destroy(enumerator);
+			break;
+		}
+	}
+	this->lock->unlock(this->lock);
+
+	if (update_routes && event)
+	{
+		queue_route_reinstall(this, strdup(name));
+	}
+
+	if (update && event)
+	{
+		fire_roam_event(this, TRUE);
+	}
+}
+
+/**
+ * process RTM_NEWADDR/RTM_DELADDR from kernel
+ */
+static void process_addr(private_ipsec_offload_net_t *this,
+						 struct nlmsghdr *hdr, bool event)
+{
+	struct ifaddrmsg* msg = NLMSG_DATA(hdr);
+	struct rtattr *rta = IFA_RTA(msg);
+	size_t rtasize = IFA_PAYLOAD (hdr);
+	host_t *host = NULL;
+	iface_entry_t *iface;
+	chunk_t local = chunk_empty, address = chunk_empty;
+	char *route_ifname = NULL;
+	bool update = FALSE, found = FALSE, changed = FALSE;
+
+	while (RTA_OK(rta, rtasize))
+	{
+		switch (rta->rta_type)
+		{
+			case IFA_LOCAL:
+				local.ptr = RTA_DATA(rta);
+				local.len = RTA_PAYLOAD(rta);
+				break;
+			case IFA_ADDRESS:
+				address.ptr = RTA_DATA(rta);
+				address.len = RTA_PAYLOAD(rta);
+				break;
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+
+	/* For PPP interfaces, we need the IFA_LOCAL address,
+	 * IFA_ADDRESS is the peers address. But IFA_LOCAL is
+	 * not included in all cases (IPv6?), so fallback to IFA_ADDRESS. */
+	if (local.ptr)
+	{
+		host = host_create_from_chunk(msg->ifa_family, local, 0);
+	}
+	else if (address.ptr)
+	{
+		host = host_create_from_chunk(msg->ifa_family, address, 0);
+	}
+
+	if (host == NULL)
+	{	/* bad family? */
+		return;
+	}
+
+	this->lock->write_lock(this->lock);
+	if (this->ifaces->find_first(this->ifaces, iface_entry_by_index,
+								 (void**)&iface, msg->ifa_index))
+	{
+		addr_map_entry_t *entry, lookup = {
+			.ip = host,
+			.iface = iface,
+		};
+		addr_entry_t *addr;
+
+		entry = this->vips->get(this->vips, &lookup);
+		if (entry)
+		{
+			if (hdr->nlmsg_type == RTM_NEWADDR)
+			{	/* mark as installed and signal waiting threads */
+				entry->addr->installed = TRUE;
+			}
+			else
+			{	/* the address was already marked as uninstalled */
+				addr = entry->addr;
+				iface->addrs->remove(iface->addrs, addr, NULL);
+				addr_map_entry_remove(this->vips, addr, iface);
+				addr_entry_destroy(addr);
+			}
+			/* no roam events etc. for virtual IPs */
+			this->condvar->broadcast(this->condvar);
+			this->lock->unlock(this->lock);
+			host->destroy(host);
+			return;
+		}
+		entry = this->addrs->get(this->addrs, &lookup);
+		if (entry)
+		{
+			if (hdr->nlmsg_type == RTM_DELADDR)
+			{
+				found = TRUE;
+				addr = entry->addr;
+				iface->addrs->remove(iface->addrs, addr, NULL);
+				if (iface->usable)
+				{
+					changed = TRUE;
+					DBG1(DBG_KNL, "%H disappeared from %s", host,
+						 iface->ifname);
+				}
+				addr_map_entry_remove(this->addrs, addr, iface);
+				addr_entry_destroy(addr);
+			}
+		}
+		else
+		{
+			if (hdr->nlmsg_type == RTM_NEWADDR)
+			{
+				found = TRUE;
+				changed = TRUE;
+				route_ifname = strdup(iface->ifname);
+				INIT(addr,
+					.ip = host->clone(host),
+					.flags = msg->ifa_flags,
+					.scope = msg->ifa_scope,
+				);
+				iface->addrs->insert_last(iface->addrs, addr);
+				addr_map_entry_add(this->addrs, addr, iface);
+				if (event && iface->usable)
+				{
+					DBG1(DBG_KNL, "%H appeared on %s", host, iface->ifname);
+				}
+			}
+		}
+		if (found && (iface->flags & IFF_UP))
+		{
+			update = TRUE;
+		}
+		if (!iface->usable)
+		{	/* ignore events for interfaces excluded by config */
+			update = changed = FALSE;
+		}
+	}
+	this->lock->unlock(this->lock);
+
+	if (update && event && route_ifname)
+	{
+		queue_route_reinstall(this, route_ifname);
+	}
+	else
+	{
+		free(route_ifname);
+	}
+	host->destroy(host);
+
+	/* send an update to all IKE_SAs */
+	if (update && event && changed)
+	{
+		fire_roam_event(this, TRUE);
+	}
+}
+
+/**
+ * process RTM_NEWROUTE and RTM_DELROUTE from kernel
+ */
+static void process_route(private_ipsec_offload_net_t *this,
+						  struct nlmsghdr *hdr)
+{
+	struct rtmsg* msg = NLMSG_DATA(hdr);
+	struct rtattr *rta = RTM_RTA(msg);
+	size_t rtasize = RTM_PAYLOAD(hdr);
+	uint32_t rta_oif = 0;
+	host_t *host = NULL;
+
+	/* ignore routes added by us or in the local routing table (local addrs) */
+	if (msg->rtm_table && (msg->rtm_table == this->routing_table ||
+						   msg->rtm_table == RT_TABLE_LOCAL))
+	{
+		return;
+	}
+	else if (msg->rtm_flags & RTM_F_CLONED)
+	{	/* ignore cached routes, seem to be created a lot for IPv6 */
+		return;
+	}
+
+	while (RTA_OK(rta, rtasize))
+	{
+		switch (rta->rta_type)
+		{
+#ifdef HAVE_RTA_TABLE
+			case RTA_TABLE:
+				/* also check against extended table ID */
+				if (RTA_PAYLOAD(rta) == sizeof(uint32_t) &&
+					this->routing_table == *(uint32_t*)RTA_DATA(rta))
+				{
+					return;
+				}
+				break;
+#endif /* HAVE_RTA_TABLE */
+			case RTA_PREFSRC:
+				DESTROY_IF(host);
+				host = host_create_from_chunk(msg->rtm_family,
+							chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta)), 0);
+				break;
+			case RTA_OIF:
+				if (RTA_PAYLOAD(rta) == sizeof(rta_oif))
+				{
+					rta_oif = *(uint32_t*)RTA_DATA(rta);
+				}
+				break;
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+	this->lock->read_lock(this->lock);
+	if (rta_oif && !is_interface_up_and_usable(this, rta_oif))
+	{	/* ignore route changes for interfaces that are ignored or down */
+		this->lock->unlock(this->lock);
+		DESTROY_IF(host);
+		return;
+	}
+	if (!host && rta_oif)
+	{
+		host = get_interface_address(this, rta_oif, msg->rtm_family,
+									 NULL, NULL);
+	}
+	if (!host || is_known_vip(this, host))
+	{	/* ignore routes added for virtual IPs */
+		this->lock->unlock(this->lock);
+		DESTROY_IF(host);
+		return;
+	}
+	this->lock->unlock(this->lock);
+	fire_roam_event(this, FALSE);
+	host->destroy(host);
+}
+
+/**
+ * process RTM_NEW|DELRULE from kernel
+ */
+static void process_rule(private_ipsec_offload_net_t *this,
+						 struct nlmsghdr *hdr)
+{
+#ifdef HAVE_LINUX_FIB_RULES_H
+	struct rtmsg* msg = NLMSG_DATA(hdr);
+	struct rtattr *rta = RTM_RTA(msg);
+	size_t rtasize = RTM_PAYLOAD(hdr);
+
+	/* ignore rules added by us or in the local routing table (local addrs) */
+	if (msg->rtm_table && (msg->rtm_table == this->routing_table ||
+						   msg->rtm_table == RT_TABLE_LOCAL))
+	{
+		return;
+	}
+
+	while (RTA_OK(rta, rtasize))
+	{
+		switch (rta->rta_type)
+		{
+			case FRA_TABLE:
+				/* also check against extended table ID */
+				if (RTA_PAYLOAD(rta) == sizeof(uint32_t) &&
+					this->routing_table == *(uint32_t*)RTA_DATA(rta))
+				{
+					return;
+				}
+				break;
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+	fire_roam_event(this, FALSE);
+#endif
+}
+
+/**
+ * Receives events from kernel
+ */
+static bool receive_events(private_ipsec_offload_net_t *this, int fd,
+						   watcher_event_t event)
+{
+	char response[netlink_get_buflen()];
+	struct nlmsghdr *hdr = (struct nlmsghdr*)response;
+	struct sockaddr_nl addr;
+	socklen_t addr_len = sizeof(addr);
+	int len;
+
+	len = recvfrom(this->socket_events, response, sizeof(response),
+				   MSG_DONTWAIT, (struct sockaddr*)&addr, &addr_len);
+	if (len < 0)
+	{
+		switch (errno)
+		{
+			case EINTR:
+				/* interrupted, try again */
+				return TRUE;
+			case EAGAIN:
+				/* no data ready, select again */
+				return TRUE;
+			default:
+				DBG1(DBG_KNL, "unable to receive from RT event socket %s (%d)",
+					 strerror(errno), errno);
+				sleep(1);
+				return TRUE;
+		}
+	}
+
+	if (addr.nl_pid != 0)
+	{	/* not from kernel. not interested, try another one */
+		return TRUE;
+	}
+
+	while (NLMSG_OK(hdr, len))
+	{
+		/* looks good so far, dispatch netlink message */
+		switch (hdr->nlmsg_type)
+		{
+			case RTM_NEWADDR:
+			case RTM_DELADDR:
+				process_addr(this, hdr, TRUE);
+				break;
+			case RTM_NEWLINK:
+			case RTM_DELLINK:
+				process_link(this, hdr, TRUE);
+				break;
+			case RTM_NEWROUTE:
+			case RTM_DELROUTE:
+				if (this->process_route)
+				{
+					process_route(this, hdr);
+				}
+				break;
+			case RTM_NEWRULE:
+			case RTM_DELRULE:
+				if (this->process_rules)
+				{
+					process_rule(this, hdr);
+				}
+				break;
+			default:
+				break;
+		}
+		hdr = NLMSG_NEXT(hdr, len);
+	}
+	return TRUE;
+}
+
+/** enumerator over addresses */
+typedef struct {
+	private_ipsec_offload_net_t* this;
+	/** which addresses to enumerate */
+	kernel_address_type_t which;
+} address_enumerator_t;
+
+CALLBACK(address_enumerator_destroy, void,
+	address_enumerator_t *data)
+{
+	data->this->lock->unlock(data->this->lock);
+	free(data);
+}
+
+CALLBACK(filter_addresses, bool,
+	address_enumerator_t *data, enumerator_t *orig, va_list args)
+{
+	addr_entry_t *addr;
+	host_t **out;
+
+	VA_ARGS_VGET(args, out);
+
+	while (orig->enumerate(orig, &addr))
+	{
+		if (!(data->which & ADDR_TYPE_VIRTUAL) && addr->refcount)
+		{	/* skip virtual interfaces added by us */
+			continue;
+		}
+		if (!(data->which & ADDR_TYPE_REGULAR) && !addr->refcount)
+		{	/* address is regular, but not requested */
+			continue;
+		}
+		if (addr->flags & IFA_F_DEPRECATED ||
+			addr->scope >= RT_SCOPE_LINK)
+		{	/* skip deprecated addresses or those with an unusable scope */
+			continue;
+		}
+		if (addr->ip->get_family(addr->ip) == AF_INET6)
+		{	/* handle temporary IPv6 addresses according to config */
+			bool temporary = (addr->flags & IFA_F_TEMPORARY) == IFA_F_TEMPORARY;
+			if (data->this->prefer_temporary_addrs != temporary)
+			{
+				continue;
+			}
+		}
+		*out = addr->ip;
+		return TRUE;
+	}
+	return FALSE;
+}
+
+/**
+ * enumerator constructor for interfaces
+ */
+static enumerator_t *create_iface_enumerator(iface_entry_t *iface,
+											 address_enumerator_t *data)
+{
+	return enumerator_create_filter(
+						iface->addrs->create_enumerator(iface->addrs),
+						filter_addresses, data, NULL);
+}
+
+CALLBACK(filter_interfaces, bool,
+	address_enumerator_t *data, enumerator_t *orig, va_list args)
+{
+	iface_entry_t *iface, **out;
+
+	VA_ARGS_VGET(args, out);
+
+	while (orig->enumerate(orig, &iface))
+	{
+		if (!(data->which & ADDR_TYPE_IGNORED) && !iface->usable)
+		{	/* skip interfaces excluded by config */
+			continue;
+		}
+		if (!(data->which & ADDR_TYPE_LOOPBACK) && (iface->flags & IFF_LOOPBACK))
+		{	/* ignore loopback devices */
+			continue;
+		}
+		if (!(data->which & ADDR_TYPE_DOWN) && !(iface->flags & IFF_UP))
+		{	/* skip interfaces not up */
+			continue;
+		}
+		*out = iface;
+		return TRUE;
+	}
+	return FALSE;
+}
+
+METHOD(kernel_net_t, create_address_enumerator, enumerator_t*,
+	private_ipsec_offload_net_t *this, kernel_address_type_t which)
+{
+	address_enumerator_t *data;
+
+	INIT(data,
+		.this = this,
+		.which = which,
+	);
+
+	this->lock->read_lock(this->lock);
+	return enumerator_create_nested(
+				enumerator_create_filter(
+					this->ifaces->create_enumerator(this->ifaces),
+					filter_interfaces, data, NULL),
+				(void*)create_iface_enumerator, data,
+				address_enumerator_destroy);
+}
+
+METHOD(kernel_net_t, get_interface_name, bool,
+	private_ipsec_offload_net_t *this, host_t* ip, char **name)
+{
+	addr_map_entry_t *entry, lookup = {
+		.ip = ip,
+	};
+
+	if (ip->is_anyaddr(ip))
+	{
+		return FALSE;
+	}
+	this->lock->read_lock(this->lock);
+	/* first try to find it on an up and usable interface */
+	entry = this->addrs->get_match(this->addrs, &lookup,
+								  (void*)addr_map_entry_match_up_and_usable);
+	if (entry)
+	{
+		if (name)
+		{
+			*name = strdup(entry->iface->ifname);
+			DBG2(DBG_KNL, "%H is on interface %s", ip, *name);
+		}
+		this->lock->unlock(this->lock);
+		return TRUE;
+	}
+	/* in a second step, consider virtual IPs installed by us */
+	entry = this->vips->get_match(this->vips, &lookup,
+								  (void*)addr_map_entry_match_up_and_usable);
+	if (entry)
+	{
+		if (name)
+		{
+			*name = strdup(entry->iface->ifname);
+			DBG2(DBG_KNL, "virtual IP %H is on interface %s", ip, *name);
+		}
+		this->lock->unlock(this->lock);
+		return TRUE;
+	}
+	/* maybe it is installed on an ignored interface */
+	entry = this->addrs->get_match(this->addrs, &lookup,
+								  (void*)addr_map_entry_match_up);
+	if (!entry)
+	{
+		DBG2(DBG_KNL, "%H is not a local address or the interface is down", ip);
+	}
+	this->lock->unlock(this->lock);
+	return FALSE;
+}
+
+/**
+ * get the index of an interface by name
+ */
+static int get_interface_index(private_ipsec_offload_net_t *this, char* name)
+{
+	iface_entry_t *iface;
+	int ifindex = 0;
+
+	DBG2(DBG_KNL, "getting iface index for %s", name);
+
+	this->lock->read_lock(this->lock);
+	if (this->ifaces->find_first(this->ifaces, iface_entry_by_name,
+								(void**)&iface, name))
+	{
+		ifindex = iface->ifindex;
+	}
+	this->lock->unlock(this->lock);
+
+	if (ifindex == 0)
+	{
+		DBG1(DBG_KNL, "unable to get interface index for %s", name);
+	}
+	return ifindex;
+}
+
+/**
+ * get the name of an interface by index (allocated)
+ */
+static char *get_interface_name_by_index(private_ipsec_offload_net_t *this,
+										 int index)
+{
+	iface_entry_t *iface;
+	char *name = NULL;
+
+	DBG2(DBG_KNL, "getting iface name for index %d", index);
+
+	this->lock->read_lock(this->lock);
+	if (this->ifaces->find_first(this->ifaces, iface_entry_by_index,
+								(void**)&iface, index))
+	{
+		name = strdup(iface->ifname);
+	}
+	this->lock->unlock(this->lock);
+
+	if (!name)
+	{
+		DBG1(DBG_KNL, "unable to get interface name for %d", index);
+	}
+	return name;
+}
+
+/**
+ * Store information about a route retrieved via RTNETLINK
+ */
+typedef struct {
+	chunk_t gtw;
+	chunk_t pref_src;
+	chunk_t dst;
+	chunk_t src;
+	host_t *src_host;
+	uint8_t dst_len;
+	uint8_t src_len;
+	uint32_t table;
+	uint32_t oif;
+	uint32_t priority;
+} rt_entry_t;
+
+/**
+ * Free a route entry
+ */
+static void rt_entry_destroy(rt_entry_t *this)
+{
+	DESTROY_IF(this->src_host);
+	free(this);
+}
+
+/**
+ * Check if the route received with RTM_NEWROUTE is usable based on its type.
+ */
+static bool route_usable(struct nlmsghdr *hdr, bool allow_local)
+{
+	struct rtmsg *msg;
+
+	msg = NLMSG_DATA(hdr);
+	switch (msg->rtm_type)
+	{
+		case RTN_BLACKHOLE:
+		case RTN_UNREACHABLE:
+		case RTN_PROHIBIT:
+		case RTN_THROW:
+			return FALSE;
+		case RTN_LOCAL:
+			return allow_local;
+		default:
+			return TRUE;
+	}
+}
+
+/**
+ * Parse route received with RTM_NEWROUTE. The given rt_entry_t object will be
+ * reused if not NULL.
+ *
+ * Returned chunks point to internal data of the Netlink message.
+ */
+static rt_entry_t *parse_route(struct nlmsghdr *hdr, rt_entry_t *route)
+{
+	struct rtattr *rta;
+	struct rtmsg *msg;
+	size_t rtasize;
+
+	msg = NLMSG_DATA(hdr);
+	rta = RTM_RTA(msg);
+	rtasize = RTM_PAYLOAD(hdr);
+
+	if (route)
+	{
+		*route = (rt_entry_t){
+			.dst_len = msg->rtm_dst_len,
+			.src_len = msg->rtm_src_len,
+			.table = msg->rtm_table,
+		};
+	}
+	else
+	{
+		INIT(route,
+			.dst_len = msg->rtm_dst_len,
+			.src_len = msg->rtm_src_len,
+			.table = msg->rtm_table,
+		);
+	}
+
+	while (RTA_OK(rta, rtasize))
+	{
+		switch (rta->rta_type)
+		{
+			case RTA_PREFSRC:
+				route->pref_src = chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta));
+				break;
+			case RTA_GATEWAY:
+				route->gtw = chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta));
+				break;
+			case RTA_DST:
+				route->dst = chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta));
+				break;
+			case RTA_SRC:
+				route->src = chunk_create(RTA_DATA(rta), RTA_PAYLOAD(rta));
+				break;
+			case RTA_OIF:
+				if (RTA_PAYLOAD(rta) == sizeof(route->oif))
+				{
+					route->oif = *(uint32_t*)RTA_DATA(rta);
+				}
+				break;
+			case RTA_PRIORITY:
+				if (RTA_PAYLOAD(rta) == sizeof(route->priority))
+				{
+					route->priority = *(uint32_t*)RTA_DATA(rta);
+				}
+				break;
+#ifdef HAVE_RTA_TABLE
+			case RTA_TABLE:
+				if (RTA_PAYLOAD(rta) == sizeof(route->table))
+				{
+					route->table = *(uint32_t*)RTA_DATA(rta);
+				}
+				break;
+#endif /* HAVE_RTA_TABLE*/
+		}
+		rta = RTA_NEXT(rta, rtasize);
+	}
+	return route;
+}
+
+/**
+ * Get a route: If "nexthop", the nexthop is returned. source addr otherwise.
+ */
+static host_t *get_route(private_ipsec_offload_net_t *this, host_t *dest,
+						 int prefix, bool nexthop, host_t *candidate,
+						 char **iface, u_int recursion)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out, *current;
+	struct rtmsg *msg;
+	chunk_t chunk;
+	size_t len;
+	linked_list_t *routes;
+	rt_entry_t *route = NULL, *best = NULL;
+	enumerator_t *enumerator;
+	host_t *addr = NULL;
+	bool match_net;
+	int family;
+
+	if (recursion > MAX_ROUTE_RECURSION)
+	{
+		return NULL;
+	}
+	chunk = dest->get_address(dest);
+	len = chunk.len * 8;
+	prefix = prefix < 0 ? len : min(prefix, len);
+	match_net = prefix != len;
+
+	memset(&request, 0, sizeof(request));
+
+	family = dest->get_family(dest);
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = RTM_GETROUTE;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));
+
+	msg = NLMSG_DATA(hdr);
+	msg->rtm_family = family;
+	if (!match_net && this->rta_mark && this->routing_mark.value)
+	{
+		/* if our routing rule excludes packets with a certain mark we can
+		 * get the preferred route without having to dump all routes */
+		chunk = chunk_from_thing(this->routing_mark.value);
+		netlink_add_attribute(hdr, RTA_MARK, chunk, sizeof(request));
+	}
+	else if (family == AF_INET || this->rta_prefsrc_for_ipv6 ||
+			 this->routing_table || match_net)
+	{	/* kernels prior to 3.0 do not support RTA_PREFSRC for IPv6 routes.
+		 * as we want to ignore routes with virtual IPs we cannot use DUMP
+		 * if these routes are not installed in a separate table */
+		if (this->install_routes)
+		{
+			hdr->nlmsg_flags |= NLM_F_DUMP;
+		}
+	}
+	if (candidate)
+	{
+		chunk = candidate->get_address(candidate);
+		if (hdr->nlmsg_flags & NLM_F_DUMP)
+		{
+			netlink_add_attribute(hdr, RTA_PREFSRC, chunk, sizeof(request));
+		}
+		else
+		{
+			netlink_add_attribute(hdr, RTA_SRC, chunk, sizeof(request));
+		}
+	}
+	/* we use this below to match against the routes */
+	chunk = dest->get_address(dest);
+	if (!match_net)
+	{
+		netlink_add_attribute(hdr, RTA_DST, chunk, sizeof(request));
+	}
+
+	if (this->socket->send(this->socket, hdr, &out, &len) != SUCCESS)
+	{
+		DBG2(DBG_KNL, "getting %s to reach %H/%d failed",
+			 nexthop ? "nexthop" : "address", dest, prefix);
+		return NULL;
+	}
+	routes = linked_list_create();
+	this->lock->read_lock(this->lock);
+
+	for (current = out; NLMSG_OK(current, len);
+		 current = NLMSG_NEXT(current, len))
+	{
+		switch (current->nlmsg_type)
+		{
+			case NLMSG_DONE:
+				break;
+			case RTM_NEWROUTE:
+			{
+				rt_entry_t *other;
+				uintptr_t table;
+
+				if (!route_usable(current, TRUE))
+				{
+					continue;
+				}
+				route = parse_route(current, route);
+
+				table = (uintptr_t)route->table;
+				if (this->rt_exclude->find_first(this->rt_exclude, NULL,
+												 (void**)&table))
+				{	/* route is from an excluded routing table */
+					continue;
+				}
+				if (this->routing_table != 0 &&
+					route->table == this->routing_table)
+				{	/* route is from our own ipsec routing table */
+					continue;
+				}
+				if (route->oif && !is_interface_up_and_usable(this, route->oif))
+				{	/* interface is down */
+					continue;
+				}
+				if (!addr_in_subnet(chunk, prefix, route->dst, route->dst_len))
+				{	/* route destination does not contain dest */
+					continue;
+				}
+				if (route->pref_src.ptr)
+				{	/* verify source address, if any */
+					host_t *src = host_create_from_chunk(msg->rtm_family,
+														 route->pref_src, 0);
+					if (src && is_known_vip(this, src))
+					{	/* ignore routes installed by us */
+						src->destroy(src);
+						continue;
+					}
+					route->src_host = src;
+				}
+				/* insert route, sorted by network prefix and priority */
+				enumerator = routes->create_enumerator(routes);
+				while (enumerator->enumerate(enumerator, &other))
+				{
+					if (route->dst_len > other->dst_len)
+					{
+						break;
+					}
+					if (route->dst_len == other->dst_len &&
+						route->priority < other->priority)
+					{
+						break;
+					}
+				}
+				routes->insert_before(routes, enumerator, route);
+				enumerator->destroy(enumerator);
+				route = NULL;
+				continue;
+			}
+			default:
+				continue;
+		}
+		break;
+	}
+	if (route)
+	{
+		rt_entry_destroy(route);
+	}
+
+	/* now we have a list of routes matching dest, sorted by net prefix.
+	 * we will look for source addresses for these routes and select the one
+	 * with the preferred source address, if possible */
+	enumerator = routes->create_enumerator(routes);
+	while (enumerator->enumerate(enumerator, &route))
+	{
+		if (route->src_host)
+		{	/* got a source address with the route, if no preferred source
+			 * is given or it matches we are done, as this is the best route */
+			if (!candidate || candidate->ip_equals(candidate, route->src_host))
+			{
+				best = route;
+				break;
+			}
+			else if (route->oif)
+			{	/* no match yet, maybe it is assigned to the same interface */
+				host_t *src = get_interface_address(this, route->oif,
+											msg->rtm_family, dest, candidate);
+				if (src && src->ip_equals(src, candidate))
+				{
+					route->src_host->destroy(route->src_host);
+					route->src_host = src;
+					best = route;
+					break;
+				}
+				DESTROY_IF(src);
+			}
+			/* no luck yet with the source address. if this is the best (first)
+			 * route we store it as fallback in case we don't find a route with
+			 * the preferred source */
+			best = best ?: route;
+			continue;
+		}
+		if (route->src.ptr)
+		{	/* no src, but a source selector, try to find a matching address */
+			route->src_host = get_subnet_address(this, msg->rtm_family,
+											route->src, route->src_len, dest,
+											candidate);
+			if (route->src_host)
+			{	/* we handle this address the same as the one above */
+				if (!candidate ||
+					 candidate->ip_equals(candidate, route->src_host))
+				{
+					best = route;
+					break;
+				}
+				best = best ?: route;
+				continue;
+			}
+		}
+		if (route->oif)
+		{	/* no src, but an interface - get address from it */
+			route->src_host = get_interface_address(this, route->oif,
+											msg->rtm_family, dest, candidate);
+			if (route->src_host)
+			{	/* more of the same */
+				if (!candidate ||
+					 candidate->ip_equals(candidate, route->src_host))
+				{
+					best = route;
+					break;
+				}
+				best = best ?: route;
+				continue;
+			}
+		}
+		if (route->gtw.ptr)
+		{	/* no src, no iface, but a gateway - lookup src to reach gtw */
+			host_t *gtw;
+
+			gtw = host_create_from_chunk(msg->rtm_family, route->gtw, 0);
+			if (gtw && !gtw->ip_equals(gtw, dest))
+			{
+				route->src_host = get_route(this, gtw, -1, FALSE, candidate,
+											iface, recursion + 1);
+			}
+			DESTROY_IF(gtw);
+			if (route->src_host)
+			{	/* more of the same */
+				if (!candidate ||
+					 candidate->ip_equals(candidate, route->src_host))
+				{
+					best = route;
+					break;
+				}
+				best = best ?: route;
+			}
+		}
+	}
+	enumerator->destroy(enumerator);
+
+	if (nexthop)
+	{	/* nexthop lookup, return gateway and oif if any */
+		if (iface)
+		{
+			*iface = NULL;
+		}
+		if (best || routes->get_first(routes, (void**)&best) == SUCCESS)
+		{
+			addr = host_create_from_chunk(msg->rtm_family, best->gtw, 0);
+			if (iface && best->oif)
+			{
+				*iface = get_interface_name_by_index(this, best->oif);
+			}
+		}
+		if (!addr && !match_net)
+		{	/* fallback to destination address */
+			addr = dest->clone(dest);
+		}
+	}
+	else
+	{
+		if (best)
+		{
+			addr = best->src_host->clone(best->src_host);
+		}
+	}
+	this->lock->unlock(this->lock);
+	routes->destroy_function(routes, (void*)rt_entry_destroy);
+	free(out);
+
+	if (addr)
+	{
+		if (nexthop && iface && *iface)
+		{
+			DBG2(DBG_KNL, "using %H as nexthop and %s as dev to reach %H/%d",
+				 addr, *iface, dest, prefix);
+		}
+		else
+		{
+			DBG2(DBG_KNL, "using %H as %s to reach %H/%d", addr,
+				 nexthop ? "nexthop" : "address", dest, prefix);
+		}
+	}
+	else if (!recursion)
+	{
+		DBG2(DBG_KNL, "no %s found to reach %H/%d",
+			 nexthop ? "nexthop" : "address", dest, prefix);
+	}
+	return addr;
+}
+
+METHOD(kernel_net_t, get_source_addr, host_t*,
+	private_ipsec_offload_net_t *this, host_t *dest, host_t *src)
+{
+	return get_route(this, dest, -1, FALSE, src, NULL, 0);
+}
+
+METHOD(kernel_net_t, get_nexthop, host_t*,
+	private_ipsec_offload_net_t *this, host_t *dest, int prefix, host_t *src,
+	char **iface)
+{
+	return get_route(this, dest, prefix, TRUE, src, iface, 0);
+}
+
+/** enumerator over subnets */
+typedef struct {
+	enumerator_t public;
+	private_ipsec_offload_net_t *private;
+	/** message from the kernel */
+	struct nlmsghdr *msg;
+	/** current message from the kernel */
+	struct nlmsghdr *current;
+	/** remaining length */
+	size_t len;
+	/** last subnet enumerated */
+	host_t *net;
+	/** interface of current net */
+	char ifname[IFNAMSIZ];
+} subnet_enumerator_t;
+
+METHOD(enumerator_t, destroy_subnet_enumerator, void,
+	subnet_enumerator_t *this)
+{
+	DESTROY_IF(this->net);
+	free(this->msg);
+	free(this);
+}
+
+METHOD(enumerator_t, enumerate_subnets, bool,
+	subnet_enumerator_t *this, va_list args)
+{
+	host_t **net;
+	uint8_t *mask;
+	char **ifname;
+
+	VA_ARGS_VGET(args, net, mask, ifname);
+
+	if (!this->current)
+	{
+		this->current = this->msg;
+	}
+	else
+	{
+		this->current = NLMSG_NEXT(this->current, this->len);
+		DESTROY_IF(this->net);
+		this->net = NULL;
+	}
+
+	while (NLMSG_OK(this->current, this->len))
+	{
+		switch (this->current->nlmsg_type)
+		{
+			case NLMSG_DONE:
+				break;
+			case RTM_NEWROUTE:
+			{
+				rt_entry_t route;
+
+				if (!route_usable(this->current, FALSE))
+				{
+					break;
+				}
+				parse_route(this->current, &route);
+
+				if (route.table && (
+							route.table == RT_TABLE_LOCAL ||
+							route.table == this->private->routing_table))
+				{	/* ignore our own and the local routing tables */
+					break;
+				}
+				else if (route.gtw.ptr)
+				{	/* ignore routes via gateway/next hop */
+					break;
+				}
+
+				if (route.dst.ptr && route.oif &&
+					if_indextoname(route.oif, this->ifname))
+				{
+					this->net = host_create_from_chunk(AF_UNSPEC, route.dst, 0);
+					*net = this->net;
+					*mask = route.dst_len;
+					*ifname = this->ifname;
+					return TRUE;
+				}
+				break;
+			}
+			default:
+				break;
+		}
+		this->current = NLMSG_NEXT(this->current, this->len);
+	}
+	return FALSE;
+}
+
+METHOD(kernel_net_t, create_local_subnet_enumerator, enumerator_t*,
+	private_ipsec_offload_net_t *this)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr, *out;
+	struct rtmsg *msg;
+	size_t len;
+	subnet_enumerator_t *enumerator;
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST;
+	hdr->nlmsg_type = RTM_GETROUTE;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));
+	hdr->nlmsg_flags |= NLM_F_DUMP;
+
+	msg = NLMSG_DATA(hdr);
+	msg->rtm_scope = RT_SCOPE_LINK;
+
+	if (this->socket->send(this->socket, hdr, &out, &len) != SUCCESS)
+	{
+		DBG2(DBG_KNL, "enumerating local subnets failed");
+		return enumerator_create_empty();
+	}
+
+	INIT(enumerator,
+		.public = {
+			.enumerate = enumerator_enumerate_default,
+			.venumerate = _enumerate_subnets,
+			.destroy = _destroy_subnet_enumerator,
+		},
+		.private = this,
+		.msg = out,
+		.len = len,
+	);
+	return &enumerator->public;
+}
+
+/**
+ * Manages the creation and deletion of IPv6 address labels for virtual IPs.
+ * By setting the appropriate nlmsg_type the label is either added or removed.
+ */
+static status_t manage_addrlabel(private_ipsec_offload_net_t *this,
+								 int nlmsg_type, host_t *ip)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct ifaddrlblmsg *msg;
+	chunk_t chunk;
+	uint32_t label;
+
+	memset(&request, 0, sizeof(request));
+
+	chunk = ip->get_address(ip);
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	if (nlmsg_type == RTM_NEWADDRLABEL)
+	{
+		hdr->nlmsg_flags |= NLM_F_CREATE | NLM_F_EXCL;
+	}
+	hdr->nlmsg_type = nlmsg_type;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct ifaddrlblmsg));
+
+	msg = NLMSG_DATA(hdr);
+	msg->ifal_family = ip->get_family(ip);
+	msg->ifal_prefixlen = chunk.len * 8;
+
+	netlink_add_attribute(hdr, IFAL_ADDRESS, chunk, sizeof(request));
+	/* doesn't really matter as default labels are < 20 but this makes it kinda
+	 * recognizable */
+	label = 220;
+	netlink_add_attribute(hdr, IFAL_LABEL, chunk_from_thing(label),
+						  sizeof(request));
+
+	return this->socket->send_ack(this->socket, hdr);
+}
+
+/**
+ * Manages the creation and deletion of ip addresses on an interface.
+ * By setting the appropriate nlmsg_type, the ip will be set or unset.
+ */
+static status_t manage_ipaddr(private_ipsec_offload_net_t *this, int nlmsg_type,
+							  int flags, int if_index, host_t *ip, int prefix)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct ifaddrmsg *msg;
+	chunk_t chunk;
+
+	memset(&request, 0, sizeof(request));
+
+	chunk = ip->get_address(ip);
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK | flags;
+	hdr->nlmsg_type = nlmsg_type;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct ifaddrmsg));
+
+	msg = NLMSG_DATA(hdr);
+	msg->ifa_family = ip->get_family(ip);
+	msg->ifa_flags = 0;
+	msg->ifa_prefixlen = prefix < 0 ? chunk.len * 8 : prefix;
+	msg->ifa_scope = RT_SCOPE_UNIVERSE;
+	msg->ifa_index = if_index;
+
+	netlink_add_attribute(hdr, IFA_LOCAL, chunk, sizeof(request));
+
+	if (ip->get_family(ip) == AF_INET6)
+	{
+#ifdef IFA_F_NODAD
+		msg->ifa_flags |= IFA_F_NODAD;
+#endif
+		if (this->rta_prefsrc_for_ipv6)
+		{
+			/* if source routes are possible we set a label for this virtual IP
+			 * so it gets only used if forced by our route, and not by the
+			 * default IPv6 address selection */
+			int labelop = nlmsg_type == RTM_NEWADDR ? RTM_NEWADDRLABEL
+													: RTM_DELADDRLABEL;
+			if (manage_addrlabel(this, labelop, ip) != SUCCESS)
+			{
+				/* if we can't use address labels we let the virtual IP get
+				 * deprecated immediately (but mark it as valid forever), which
+				 * should also avoid that it gets used by the default address
+				 * selection */
+				struct ifa_cacheinfo cache = {
+					.ifa_valid = 0xFFFFFFFF,
+					.ifa_prefered = 0,
+				};
+				netlink_add_attribute(hdr, IFA_CACHEINFO,
+									  chunk_from_thing(cache), sizeof(request));
+			}
+		}
+	}
+	return this->socket->send_ack(this->socket, hdr);
+}
+
+METHOD(kernel_net_t, add_ip, status_t,
+	private_ipsec_offload_net_t *this, host_t *virtual_ip, int prefix,
+	char *iface_name)
+{
+	addr_map_entry_t *entry, lookup = {
+		.ip = virtual_ip,
+	};
+	iface_entry_t *iface = NULL;
+
+	if (!this->install_virtual_ip)
+	{	/* disabled by config */
+		return SUCCESS;
+	}
+
+	this->lock->write_lock(this->lock);
+	/* the virtual IP might actually be installed as regular IP, in which case
+	 * we don't track it as virtual IP */
+	entry = this->addrs->get_match(this->addrs, &lookup,
+								  (void*)addr_map_entry_match);
+	if (!entry)
+	{	/* otherwise it might already be installed as virtual IP */
+		entry = this->vips->get_match(this->vips, &lookup,
+									 (void*)addr_map_entry_match);
+		if (entry)
+		{	/* the vip we found can be in one of three states: 1) installed and
+			 * ready, 2) just added by another thread, but not yet confirmed to
+			 * be installed by the kernel, 3) just deleted, but not yet gone.
+			 * Then while we wait below, several things could happen (as we
+			 * release the lock).  For instance, the interface could disappear,
+			 * or the IP is finally deleted, and it reappears on a different
+			 * interface. All these cases are handled by the call below. */
+			while (!is_vip_installed_or_gone(this, virtual_ip, &entry))
+			{
+				this->condvar->wait(this->condvar, this->lock);
+			}
+			if (entry)
+			{
+				entry->addr->refcount++;
+			}
+		}
+	}
+	if (entry)
+	{
+		DBG2(DBG_KNL, "virtual IP %H is already installed on %s", virtual_ip,
+			 entry->iface->ifname);
+		this->lock->unlock(this->lock);
+		return SUCCESS;
+	}
+	/* try to find the target interface, either by config or via src ip */
+	if (!this->install_virtual_ip_on ||
+		!this->ifaces->find_first(this->ifaces, iface_entry_by_name,
+								 (void**)&iface, this->install_virtual_ip_on))
+	{
+		if (!this->ifaces->find_first(this->ifaces, iface_entry_by_name,
+									 (void**)&iface, iface_name))
+		{	/* if we don't find the requested interface we just use the first */
+			this->ifaces->get_first(this->ifaces, (void**)&iface);
+		}
+	}
+	if (iface)
+	{
+		addr_entry_t *addr;
+		char *ifname;
+		int ifi;
+
+		INIT(addr,
+			.ip = virtual_ip->clone(virtual_ip),
+			.refcount = 1,
+			.scope = RT_SCOPE_UNIVERSE,
+		);
+		iface->addrs->insert_last(iface->addrs, addr);
+		addr_map_entry_add(this->vips, addr, iface);
+		ifi = iface->ifindex;
+		this->lock->unlock(this->lock);
+		if (manage_ipaddr(this, RTM_NEWADDR, NLM_F_CREATE | NLM_F_EXCL,
+						  ifi, virtual_ip, prefix) == SUCCESS)
+		{
+			this->lock->write_lock(this->lock);
+			while (!is_vip_installed_or_gone(this, virtual_ip, &entry))
+			{	/* wait until address appears */
+				this->condvar->wait(this->condvar, this->lock);
+			}
+			if (entry)
+			{	/* we fail if the interface got deleted in the meantime */
+				ifname = strdup(entry->iface->ifname);
+				this->lock->unlock(this->lock);
+				DBG2(DBG_KNL, "virtual IP %H installed on %s",
+					 virtual_ip, ifname);
+				/* during IKEv1 reauthentication, children get moved from
+				 * old the new SA before the virtual IP is available. This
+				 * kills the route for our virtual IP, reinstall. */
+				queue_route_reinstall(this, ifname);
+				return SUCCESS;
+			}
+			this->lock->unlock(this->lock);
+		}
+		DBG1(DBG_KNL, "adding virtual IP %H failed", virtual_ip);
+		return FAILED;
+	}
+	this->lock->unlock(this->lock);
+	DBG1(DBG_KNL, "no interface available, unable to install virtual IP %H",
+		 virtual_ip);
+	return FAILED;
+}
+
+METHOD(kernel_net_t, del_ip, status_t,
+	private_ipsec_offload_net_t *this, host_t *virtual_ip, int prefix,
+	bool wait)
+{
+	addr_map_entry_t *entry, lookup = {
+		.ip = virtual_ip,
+	};
+
+	if (!this->install_virtual_ip)
+	{	/* disabled by config */
+		return SUCCESS;
+	}
+
+	DBG2(DBG_KNL, "deleting virtual IP %H", virtual_ip);
+
+	this->lock->write_lock(this->lock);
+	entry = this->vips->get_match(this->vips, &lookup,
+								 (void*)addr_map_entry_match);
+	if (!entry)
+	{	/* we didn't install this IP as virtual IP */
+		entry = this->addrs->get_match(this->addrs, &lookup,
+									  (void*)addr_map_entry_match);
+		if (entry)
+		{
+			DBG2(DBG_KNL, "not deleting existing IP %H on %s", virtual_ip,
+				 entry->iface->ifname);
+			this->lock->unlock(this->lock);
+			return SUCCESS;
+		}
+		DBG2(DBG_KNL, "virtual IP %H not cached, unable to delete", virtual_ip);
+		this->lock->unlock(this->lock);
+		return FAILED;
+	}
+	if (entry->addr->refcount == 1)
+	{
+		status_t status;
+		int ifi;
+
+		/* we set this flag so that threads calling add_ip will block and wait
+		 * until the entry is gone, also so we can wait below */
+		entry->addr->installed = FALSE;
+		ifi = entry->iface->ifindex;
+		this->lock->unlock(this->lock);
+		status = manage_ipaddr(this, RTM_DELADDR, 0, ifi, virtual_ip, prefix);
+		if (status == SUCCESS && wait)
+		{	/* wait until the address is really gone */
+			this->lock->write_lock(this->lock);
+			while (is_known_vip(this, virtual_ip))
+			{
+				this->condvar->wait(this->condvar, this->lock);
+			}
+			this->lock->unlock(this->lock);
+		}
+		return status;
+	}
+	else
+	{
+		entry->addr->refcount--;
+	}
+	DBG2(DBG_KNL, "virtual IP %H used by other SAs, not deleting",
+		 virtual_ip);
+	this->lock->unlock(this->lock);
+	return SUCCESS;
+}
+
+/**
+ * Manages source routes in the routing table.
+ * By setting the appropriate nlmsg_type, the route gets added or removed.
+ */
+static status_t manage_srcroute(private_ipsec_offload_net_t *this,
+								int nlmsg_type, int flags, chunk_t dst_net,
+								uint8_t prefixlen, host_t *gateway,
+								host_t *src_ip, char *if_name, bool pass)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct rtmsg *msg;
+	struct rtattr *rta;
+	int ifindex;
+	chunk_t chunk;
+
+	/* if route is 0.0.0.0/0, we can't install it, as it would
+	 * overwrite the default route. Instead, we add two routes:
+	 * 0.0.0.0/1 and 128.0.0.0/1 */
+	if (this->routing_table == 0 && prefixlen == 0)
+	{
+		chunk_t half_net;
+		uint8_t half_prefixlen;
+		status_t status;
+
+		half_net = chunk_alloca(dst_net.len);
+		memset(half_net.ptr, 0, half_net.len);
+		half_prefixlen = 1;
+		/* no throw routes in the main table */
+		status = manage_srcroute(this, nlmsg_type, flags, half_net,
+							half_prefixlen, gateway, src_ip, if_name, FALSE);
+		half_net.ptr[0] |= 0x80;
+		status |= manage_srcroute(this, nlmsg_type, flags, half_net,
+							half_prefixlen, gateway, src_ip, if_name, FALSE);
+		return status;
+	}
+
+	memset(&request, 0, sizeof(request));
+
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK | flags;
+	hdr->nlmsg_type = nlmsg_type;
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));
+
+	msg = NLMSG_DATA(hdr);
+	msg->rtm_family = (dst_net.len == 4) ? AF_INET : AF_INET6;
+	msg->rtm_dst_len = prefixlen;
+	msg->rtm_protocol = RTPROT_STATIC;
+	msg->rtm_type = pass ? RTN_THROW : RTN_UNICAST;
+	msg->rtm_scope = RT_SCOPE_UNIVERSE;
+
+	if (this->routing_table < 256)
+	{
+		msg->rtm_table = this->routing_table;
+	}
+	else
+	{
+#ifdef HAVE_RTA_TABLE
+		chunk = chunk_from_thing(this->routing_table);
+		netlink_add_attribute(hdr, RTA_TABLE, chunk, sizeof(request));
+#else
+		DBG1(DBG_KNL, "routing table IDs > 255 are not supported");
+		return FAILED;
+#endif /* HAVE_RTA_TABLE */
+	}
+	netlink_add_attribute(hdr, RTA_DST, dst_net, sizeof(request));
+
+	/* only when installing regular routes do we need all the parameters,
+	 * deletes are done by destination net (except if metrics are used, which
+	 * we don't support), for throw routes we don't need any of them either */
+	if (nlmsg_type == RTM_NEWROUTE && !pass)
+	{
+		chunk = src_ip->get_address(src_ip);
+		netlink_add_attribute(hdr, RTA_PREFSRC, chunk, sizeof(request));
+		if (gateway && gateway->get_family(gateway) == src_ip->get_family(src_ip))
+		{
+			chunk = gateway->get_address(gateway);
+			netlink_add_attribute(hdr, RTA_GATEWAY, chunk, sizeof(request));
+		}
+		ifindex = get_interface_index(this, if_name);
+		chunk.ptr = (char*)&ifindex;
+		chunk.len = sizeof(ifindex);
+		netlink_add_attribute(hdr, RTA_OIF, chunk, sizeof(request));
+
+		if (this->mtu || this->mss)
+		{
+			chunk = chunk_alloca(RTA_LENGTH((sizeof(struct rtattr) +
+											 sizeof(uint32_t)) * 2));
+			chunk.len = 0;
+			rta = (struct rtattr*)chunk.ptr;
+			if (this->mtu)
+			{
+				rta->rta_type = RTAX_MTU;
+				rta->rta_len = RTA_LENGTH(sizeof(uint32_t));
+				memcpy(RTA_DATA(rta), &this->mtu, sizeof(uint32_t));
+				chunk.len = rta->rta_len;
+			}
+			if (this->mss)
+			{
+				rta = (struct rtattr*)(chunk.ptr + RTA_ALIGN(chunk.len));
+				rta->rta_type = RTAX_ADVMSS;
+				rta->rta_len = RTA_LENGTH(sizeof(uint32_t));
+				memcpy(RTA_DATA(rta), &this->mss, sizeof(uint32_t));
+				chunk.len = RTA_ALIGN(chunk.len) + rta->rta_len;
+			}
+			netlink_add_attribute(hdr, RTA_METRICS, chunk, sizeof(request));
+		}
+	}
+	return this->socket->send_ack(this->socket, hdr);
+}
+
+/**
+ * Helper struct used to check routes
+ */
+typedef struct {
+	/** the entry we look for */
+	route_entry_t route;
+	/** kernel interface */
+	private_ipsec_offload_net_t *this;
+} route_entry_lookup_t;
+
+/**
+ * Check if a matching route entry has a VIP associated
+ */
+static bool route_with_vip(route_entry_lookup_t *a, route_entry_t *b)
+{
+	if (chunk_equals(a->route.dst_net, b->dst_net) &&
+		a->route.prefixlen == b->prefixlen &&
+		is_known_vip(a->this, b->src_ip))
+	{
+		return TRUE;
+	}
+	return FALSE;
+}
+
+/**
+ * Check if there is any route entry with a matching destination
+ */
+static bool route_with_dst(route_entry_lookup_t *a, route_entry_t *b)
+{
+	if (chunk_equals(a->route.dst_net, b->dst_net) &&
+		a->route.prefixlen == b->prefixlen)
+	{
+		return TRUE;
+	}
+	return FALSE;
+}
+
+METHOD(kernel_net_t, add_route, status_t,
+	private_ipsec_offload_net_t *this, chunk_t dst_net, uint8_t prefixlen,
+	host_t *gateway, host_t *src_ip, char *if_name, bool pass)
+{
+	status_t status;
+	route_entry_t *found;
+	route_entry_lookup_t lookup = {
+		.route = {
+			.dst_net = dst_net,
+			.prefixlen = prefixlen,
+			.gateway = gateway,
+			.src_ip = src_ip,
+			.if_name = if_name,
+			.pass = pass,
+		},
+		.this = this,
+	};
+
+	if (!this->routing_table)
+	{	/* treat these as regular routes if installing in the main table */
+		pass = lookup.route.pass = FALSE;
+	}
+
+	this->routes_lock->lock(this->routes_lock);
+	found = this->routes->get(this->routes, &lookup.route);
+	if (found)
+	{
+		this->routes_lock->unlock(this->routes_lock);
+		return ALREADY_DONE;
+	}
+
+	/* don't replace the route if we already have one with a VIP installed,
+	 * but keep track of it in case that other route is uninstalled */
+	this->lock->read_lock(this->lock);
+	if (!is_known_vip(this, src_ip))
+	{
+		found = this->routes->get_match(this->routes, &lookup,
+										(void*)route_with_vip);
+	}
+	this->lock->unlock(this->lock);
+	if (found)
+	{
+		status = SUCCESS;
+	}
+	else
+	{
+		status = manage_srcroute(this, RTM_NEWROUTE, NLM_F_CREATE|NLM_F_REPLACE,
+								 dst_net, prefixlen, gateway, src_ip, if_name,
+								 pass);
+	}
+	if (status == SUCCESS)
+	{
+		found = route_entry_clone(&lookup.route);
+		this->routes->put(this->routes, found, found);
+	}
+	this->routes_lock->unlock(this->routes_lock);
+	return status;
+}
+
+METHOD(kernel_net_t, del_route, status_t,
+	private_ipsec_offload_net_t *this, chunk_t dst_net, uint8_t prefixlen,
+	host_t *gateway, host_t *src_ip, char *if_name, bool pass)
+{
+	status_t status;
+	route_entry_t *found;
+	route_entry_lookup_t lookup = {
+		.route = {
+			.dst_net = dst_net,
+			.prefixlen = prefixlen,
+			.gateway = gateway,
+			.src_ip = src_ip,
+			.if_name = if_name,
+			.pass = pass,
+		},
+		.this = this,
+	};
+
+	if (!this->routing_table)
+	{	/* treat these as regular routes if installing in the main table */
+		pass = lookup.route.pass = FALSE;
+	}
+
+	this->routes_lock->lock(this->routes_lock);
+	found = this->routes->remove(this->routes, &lookup.route);
+	if (!found)
+	{
+		this->routes_lock->unlock(this->routes_lock);
+		return NOT_FOUND;
+	}
+	route_entry_destroy(found);
+
+	/* check if there are any other routes for the same destination and if
+	 * so update the route, otherwise uninstall it */
+	this->lock->read_lock(this->lock);
+	found = this->routes->get_match(this->routes, &lookup,
+									(void*)route_with_vip);
+	this->lock->unlock(this->lock);
+	if (!found)
+	{
+		found = this->routes->get_match(this->routes, &lookup,
+										(void*)route_with_dst);
+	}
+	if (found)
+	{
+		status = manage_srcroute(this, RTM_NEWROUTE, NLM_F_CREATE|NLM_F_REPLACE,
+							found->dst_net, found->prefixlen, found->gateway,
+							found->src_ip, found->if_name, found->pass);
+	}
+	else
+	{
+		status = manage_srcroute(this, RTM_DELROUTE, 0, dst_net, prefixlen,
+								 gateway, src_ip, if_name, pass);
+	}
+	this->routes_lock->unlock(this->routes_lock);
+	return status;
+}
+
+/**
+ * Initialize a list of local addresses.
+ */
+static status_t init_address_list(private_ipsec_offload_net_t *this)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *out, *current, *in;
+	struct rtgenmsg *msg;
+	size_t len;
+	enumerator_t *ifaces, *addrs;
+	iface_entry_t *iface;
+	addr_entry_t *addr;
+
+	DBG2(DBG_KNL, "known interfaces and IP addresses:");
+
+	memset(&request, 0, sizeof(request));
+
+	in = &request.hdr;
+	in->nlmsg_len = NLMSG_LENGTH(sizeof(struct rtgenmsg));
+	in->nlmsg_flags = NLM_F_REQUEST | NLM_F_MATCH | NLM_F_ROOT;
+	msg = NLMSG_DATA(in);
+	msg->rtgen_family = AF_UNSPEC;
+
+	/* get all links */
+	in->nlmsg_type = RTM_GETLINK;
+	if (this->socket->send(this->socket, in, &out, &len) != SUCCESS)
+	{
+		return FAILED;
+	}
+	current = out;
+	while (NLMSG_OK(current, len))
+	{
+		switch (current->nlmsg_type)
+		{
+			case NLMSG_DONE:
+				break;
+			case RTM_NEWLINK:
+				process_link(this, current, FALSE);
+				/* fall through */
+			default:
+				current = NLMSG_NEXT(current, len);
+				continue;
+		}
+		break;
+	}
+	free(out);
+
+	/* get all interface addresses */
+	in->nlmsg_type = RTM_GETADDR;
+	if (this->socket->send(this->socket, in, &out, &len) != SUCCESS)
+	{
+		return FAILED;
+	}
+	current = out;
+	while (NLMSG_OK(current, len))
+	{
+		switch (current->nlmsg_type)
+		{
+			case NLMSG_DONE:
+				break;
+			case RTM_NEWADDR:
+				process_addr(this, current, FALSE);
+				/* fall through */
+			default:
+				current = NLMSG_NEXT(current, len);
+				continue;
+		}
+		break;
+	}
+	free(out);
+
+	this->lock->read_lock(this->lock);
+	ifaces = this->ifaces->create_enumerator(this->ifaces);
+	while (ifaces->enumerate(ifaces, &iface))
+	{
+		if (iface_entry_up_and_usable(iface))
+		{
+			DBG2(DBG_KNL, "  %s", iface->ifname);
+			addrs = iface->addrs->create_enumerator(iface->addrs);
+			while (addrs->enumerate(addrs, (void**)&addr))
+			{
+				DBG2(DBG_KNL, "    %H", addr->ip);
+			}
+			addrs->destroy(addrs);
+		}
+	}
+	ifaces->destroy(ifaces);
+	this->lock->unlock(this->lock);
+	return SUCCESS;
+}
+
+/**
+ * create or delete a rule to use our routing table
+ */
+static status_t manage_rule(private_ipsec_offload_net_t *this, int nlmsg_type,
+							int family, uint32_t table, uint32_t prio)
+{
+	netlink_buf_t request;
+	struct nlmsghdr *hdr;
+	struct rtmsg *msg;
+	chunk_t chunk;
+	char *fwmark;
+
+	memset(&request, 0, sizeof(request));
+	hdr = &request.hdr;
+	hdr->nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;
+	hdr->nlmsg_type = nlmsg_type;
+	if (nlmsg_type == RTM_NEWRULE)
+	{
+		hdr->nlmsg_flags |= NLM_F_CREATE | NLM_F_EXCL;
+	}
+	hdr->nlmsg_len = NLMSG_LENGTH(sizeof(struct rtmsg));
+
+	msg = NLMSG_DATA(hdr);
+	msg->rtm_family = family;
+	msg->rtm_protocol = RTPROT_BOOT;
+	msg->rtm_scope = RT_SCOPE_UNIVERSE;
+	msg->rtm_type = RTN_UNICAST;
+
+	if (this->routing_table < 256)
+	{
+		msg->rtm_table = table;
+	}
+	else
+	{
+#ifdef HAVE_LINUX_FIB_RULES_H
+		chunk = chunk_from_thing(table);
+		netlink_add_attribute(hdr, FRA_TABLE, chunk, sizeof(request));
+#else
+		DBG1(DBG_KNL, "routing table IDs > 255 are not supported");
+		return FAILED;
+#endif /* HAVE_LINUX_FIB_RULES_H */
+	}
+	chunk = chunk_from_thing(prio);
+	netlink_add_attribute(hdr, RTA_PRIORITY, chunk, sizeof(request));
+
+	fwmark = lib->settings->get_str(lib->settings,
+							"%s.plugins.kernel-netlink.fwmark", NULL, lib->ns);
+	if (fwmark)
+	{
+#ifdef HAVE_LINUX_FIB_RULES_H
+		mark_t mark;
+
+		if (fwmark[0] == '!')
+		{
+			msg->rtm_flags |= FIB_RULE_INVERT;
+			fwmark++;
+		}
+		if (mark_from_string(fwmark, MARK_OP_NONE, &mark))
+		{
+			chunk = chunk_from_thing(mark.value);
+			netlink_add_attribute(hdr, FRA_FWMARK, chunk, sizeof(request));
+			chunk = chunk_from_thing(mark.mask);
+			netlink_add_attribute(hdr, FRA_FWMASK, chunk, sizeof(request));
+			if (msg->rtm_flags & FIB_RULE_INVERT)
+			{
+				this->routing_mark = mark;
+			}
+		}
+#else
+		DBG1(DBG_KNL, "setting firewall mark on routing rule is not supported");
+#endif /* HAVE_LINUX_FIB_RULES_H */
+	}
+	return this->socket->send_ack(this->socket, hdr);
+}
+
+/**
+ * check for kernel features (currently only via version number)
+ */
+static void check_kernel_features(private_ipsec_offload_net_t *this)
+{
+	struct utsname utsname;
+	int a, b, c;
+
+	if (uname(&utsname) == 0)
+	{
+		switch(sscanf(utsname.release, "%d.%d.%d", &a, &b, &c))
+		{
+			case 3:
+				if (a == 2)
+				{
+					if (b == 6 && c >= 36)
+					{
+						this->rta_mark = TRUE;
+					}
+					DBG2(DBG_KNL, "detected Linux %d.%d.%d, no support for "
+						 "RTA_PREFSRC for IPv6 routes", a, b, c);
+					break;
+				}
+				/* fall-through */
+			case 2:
+				/* only 3.x+ uses two part version numbers */
+				this->rta_prefsrc_for_ipv6 = TRUE;
+				this->rta_mark = TRUE;
+				break;
+			default:
+				break;
+		}
+	}
+}
+
+/**
+ * Destroy an address to iface map
+ */
+static void addr_map_destroy(hashtable_t *map)
+{
+	enumerator_t *enumerator;
+	addr_map_entry_t *addr;
+
+	enumerator = map->create_enumerator(map);
+	while (enumerator->enumerate(enumerator, NULL, (void**)&addr))
+	{
+		free(addr);
+	}
+	enumerator->destroy(enumerator);
+	map->destroy(map);
+}
+
+METHOD(kernel_net_t, destroy, void,
+	private_ipsec_offload_net_t *this)
+{
+	enumerator_t *enumerator;
+	route_entry_t *route;
+
+	if (this->routing_table)
+	{
+		manage_rule(this, RTM_DELRULE, AF_INET, this->routing_table,
+					this->routing_table_prio);
+		manage_rule(this, RTM_DELRULE, AF_INET6, this->routing_table,
+					this->routing_table_prio);
+	}
+	if (this->socket_events > 0)
+	{
+		lib->watcher->remove(lib->watcher, this->socket_events);
+		close(this->socket_events);
+	}
+	enumerator = this->routes->create_enumerator(this->routes);
+	while (enumerator->enumerate(enumerator, NULL, (void**)&route))
+	{
+		manage_srcroute(this, RTM_DELROUTE, 0, route->dst_net, route->prefixlen,
+						route->gateway, route->src_ip, route->if_name,
+						route->pass);
+		route_entry_destroy(route);
+	}
+	enumerator->destroy(enumerator);
+	this->routes->destroy(this->routes);
+	this->routes_lock->destroy(this->routes_lock);
+	DESTROY_IF(this->socket);
+
+	net_changes_clear(this);
+	this->net_changes->destroy(this->net_changes);
+	this->net_changes_lock->destroy(this->net_changes_lock);
+
+	addr_map_destroy(this->addrs);
+	addr_map_destroy(this->vips);
+
+	this->ifaces->destroy_function(this->ifaces, (void*)iface_entry_destroy);
+	this->rt_exclude->destroy(this->rt_exclude);
+	this->roam_lock->destroy(this->roam_lock);
+	this->condvar->destroy(this->condvar);
+	this->lock->destroy(this->lock);
+	free(this);
+}
+
+/*
+ * Described in header.
+ */
+ipsec_offload_net_t *ipsec_offload_net_create()
+{
+	private_ipsec_offload_net_t *this;
+	enumerator_t *enumerator;
+	bool register_for_events = TRUE;
+	char *exclude;
+
+	INIT(this,
+		.public = {
+			.interface = {
+				.get_interface = _get_interface_name,
+				.create_address_enumerator = _create_address_enumerator,
+				.create_local_subnet_enumerator = _create_local_subnet_enumerator,
+				.get_source_addr = _get_source_addr,
+				.get_nexthop = _get_nexthop,
+				.add_ip = _add_ip,
+				.del_ip = _del_ip,
+				.add_route = _add_route,
+				.del_route = _del_route,
+				.destroy = _destroy,
+			},
+		},
+		.socket = netlink_socket_create(NETLINK_ROUTE, rt_msg_names,
+			lib->settings->get_bool(lib->settings,
+				"%s.plugins.kernel-netlink.parallel_route", FALSE, lib->ns)),
+		.rt_exclude = linked_list_create(),
+		.routes = hashtable_create((hashtable_hash_t)route_entry_hash,
+								   (hashtable_equals_t)route_entry_equals, 16),
+		.net_changes = hashtable_create(
+								   (hashtable_hash_t)net_change_hash,
+								   (hashtable_equals_t)net_change_equals, 16),
+		.addrs = hashtable_create(
+								(hashtable_hash_t)addr_map_entry_hash,
+								(hashtable_equals_t)addr_map_entry_equals, 16),
+		.vips = hashtable_create((hashtable_hash_t)addr_map_entry_hash,
+								 (hashtable_equals_t)addr_map_entry_equals, 16),
+		.routes_lock = mutex_create(MUTEX_TYPE_DEFAULT),
+		.net_changes_lock = mutex_create(MUTEX_TYPE_DEFAULT),
+		.ifaces = linked_list_create(),
+		.lock = rwlock_create(RWLOCK_TYPE_DEFAULT),
+		.condvar = rwlock_condvar_create(),
+		.roam_lock = spinlock_create(),
+		.routing_table = lib->settings->get_int(lib->settings,
+						"%s.routing_table", ROUTING_TABLE, lib->ns),
+		.routing_table_prio = lib->settings->get_int(lib->settings,
+						"%s.routing_table_prio", ROUTING_TABLE_PRIO, lib->ns),
+		.process_route = lib->settings->get_bool(lib->settings,
+						"%s.process_route", TRUE, lib->ns),
+		.install_routes = lib->settings->get_bool(lib->settings,
+						"%s.install_routes", TRUE, lib->ns),
+		.install_virtual_ip = lib->settings->get_bool(lib->settings,
+						"%s.install_virtual_ip", TRUE, lib->ns),
+		.install_virtual_ip_on = lib->settings->get_str(lib->settings,
+						"%s.install_virtual_ip_on", NULL, lib->ns),
+		.prefer_temporary_addrs = lib->settings->get_bool(lib->settings,
+						"%s.prefer_temporary_addrs", FALSE, lib->ns),
+		.roam_events = lib->settings->get_bool(lib->settings,
+						"%s.plugins.kernel-netlink.roam_events", TRUE, lib->ns),
+		.process_rules = lib->settings->get_bool(lib->settings,
+						"%s.plugins.kernel-netlink.process_rules", FALSE, lib->ns),
+		.mtu = lib->settings->get_int(lib->settings,
+						"%s.plugins.kernel-netlink.mtu", 0, lib->ns),
+		.mss = lib->settings->get_int(lib->settings,
+						"%s.plugins.kernel-netlink.mss", 0, lib->ns),
+	);
+	timerclear(&this->last_route_reinstall);
+	timerclear(&this->next_roam);
+
+	check_kernel_features(this);
+
+	if (streq(lib->ns, "starter"))
+	{	/* starter has no threads, so we do not register for kernel events */
+		register_for_events = FALSE;
+	}
+
+	exclude = lib->settings->get_str(lib->settings,
+									 "%s.ignore_routing_tables", NULL, lib->ns);
+	if (exclude)
+	{
+		char *token;
+		uintptr_t table;
+
+		enumerator = enumerator_create_token(exclude, " ", " ");
+		while (enumerator->enumerate(enumerator, &token))
+		{
+			errno = 0;
+			table = strtoul(token, NULL, 10);
+
+			if (errno == 0)
+			{
+				this->rt_exclude->insert_last(this->rt_exclude, (void*)table);
+			}
+		}
+		enumerator->destroy(enumerator);
+	}
+
+	if (register_for_events)
+	{
+		struct sockaddr_nl addr;
+
+		memset(&addr, 0, sizeof(addr));
+		addr.nl_family = AF_NETLINK;
+
+		/* create and bind RT socket for events (address/interface/route changes) */
+		this->socket_events = socket(AF_NETLINK, SOCK_RAW, NETLINK_ROUTE);
+		if (this->socket_events < 0)
+		{
+			DBG1(DBG_KNL, "unable to create RT event socket: %s (%d)",
+				 strerror(errno), errno);
+			destroy(this);
+			return NULL;
+		}
+		addr.nl_groups = nl_group(RTNLGRP_IPV4_IFADDR) |
+						 nl_group(RTNLGRP_IPV6_IFADDR) |
+						 nl_group(RTNLGRP_LINK);
+		if (this->process_route)
+		{
+			addr.nl_groups |= nl_group(RTNLGRP_IPV4_ROUTE) |
+							  nl_group(RTNLGRP_IPV6_ROUTE);
+		}
+		if (this->process_rules)
+		{
+			addr.nl_groups |= nl_group(RTNLGRP_IPV4_RULE) |
+							  nl_group(RTNLGRP_IPV6_RULE);
+		}
+		if (bind(this->socket_events, (struct sockaddr*)&addr, sizeof(addr)))
+		{
+			DBG1(DBG_KNL, "unable to bind RT event socket: %s (%d)",
+				 strerror(errno), errno);
+			destroy(this);
+			return NULL;
+		}
+
+		lib->watcher->add(lib->watcher, this->socket_events, WATCHER_READ,
+						  (watcher_cb_t)receive_events, this);
+	}
+
+	if (init_address_list(this) != SUCCESS)
+	{
+		DBG1(DBG_KNL, "unable to get interface list");
+		destroy(this);
+		return NULL;
+	}
+
+	if (this->routing_table)
+	{
+		if (manage_rule(this, RTM_NEWRULE, AF_INET, this->routing_table,
+						this->routing_table_prio) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "unable to create IPv4 routing table rule");
+		}
+		if (manage_rule(this, RTM_NEWRULE, AF_INET6, this->routing_table,
+						this->routing_table_prio) != SUCCESS)
+		{
+			DBG1(DBG_KNL, "unable to create IPv6 routing table rule");
+		}
+	}
+
+	return &this->public;
+}
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.h b/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.h
new file mode 100644
index 000000000..e9c314927
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_net.h
@@ -0,0 +1,35 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+#ifndef IPSEC_OFFLOAD_NET_H_
+#define IPSEC_OFFLOAD_NET_H_
+
+#include <kernel/kernel_net.h>
+
+typedef struct ipsec_offload_net_t ipsec_offload_net_t;
+
+/**
+ * Implementation of the kernel network interface using ipsec offload
+ */
+struct ipsec_offload_net_t {
+
+        /**
+         * Implements kernel_net_t interface
+         */
+        kernel_net_t interface;
+};
+
+/**
+ * Create a ipsec offload network interface instance.
+ *
+ * @return                      ipsec_offload_net_t instance
+ */
+ipsec_offload_net_t *ipsec_offload_net_create();
+
+#endif /** IPSEC_OFFLOAD_NET_H_ @}*/
+
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.c b/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.c
new file mode 100644
index 000000000..af19fbf72
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.c
@@ -0,0 +1,101 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#include "ipsec_offload_plugin.h"
+
+#include "ipsec_offload_ipsec.h"
+#include "ipsec_offload_net.h"
+
+#include <sa/task_manager.h>
+
+typedef struct private_ipsec_offload_plugin_t private_ipsec_offload_plugin_t;
+
+/**
+ * private data of kernel netlink plugin
+ */
+struct private_ipsec_offload_plugin_t {
+	/**
+	 * implements plugin interface
+	 */
+	ipsec_offload_plugin_t public;
+};
+
+METHOD(plugin_t, get_name, char*,
+	private_ipsec_offload_plugin_t *this)
+{
+	return "ipsec-offload";
+}
+
+METHOD(plugin_t, get_features, int,
+	private_ipsec_offload_plugin_t *this, plugin_feature_t *features[])
+{
+	static plugin_feature_t f[] = {
+		PLUGIN_CALLBACK(kernel_ipsec_register, ipsec_offload_ipsec_create),
+			PLUGIN_PROVIDE(CUSTOM, "kernel-ipsec"),
+		PLUGIN_CALLBACK(kernel_net_register, ipsec_offload_net_create),
+			PLUGIN_PROVIDE(CUSTOM, "kernel-net"),
+	};
+	*features = f;
+	return countof(f);
+}
+
+METHOD(plugin_t, reload, bool,
+	private_ipsec_offload_plugin_t *this)
+{
+	u_int timeout;
+	FILE *f;
+
+	f = fopen("/proc/sys/net/core/xfrm_acq_expires", "w");
+	if (f)
+	{
+		timeout = lib->settings->get_int(lib->settings,
+							"%s.plugins.kernel-netlink.xfrm_acq_expires",
+							task_manager_total_retransmit_timeout(), lib->ns);
+		fprintf(f, "%u", timeout);
+		fclose(f);
+	}
+	return TRUE;
+}
+
+METHOD(plugin_t, destroy, void,
+	private_ipsec_offload_plugin_t *this)
+{
+	free(this);
+}
+
+/*
+ * see header file
+ */
+plugin_t *ipsec_offload_plugin_create()
+{
+	private_ipsec_offload_plugin_t *this;
+
+	if (!lib->caps->keep(lib->caps, CAP_NET_ADMIN))
+	{	/* required to bind/use XFRM sockets / create/modify routing tables, but
+		 * not if only the read-only parts of kernel-netlink-net are used, so
+		 * we don't fail here */
+		DBG1(DBG_KNL, "kernel-netlink plugin might require CAP_NET_ADMIN "
+			 "capability");
+	}
+
+	INIT(this,
+		.public = {
+			.plugin = {
+				.get_name = _get_name,
+				.get_features = _get_features,
+				.reload = _reload,
+				.destroy = _destroy,
+			},
+		},
+	);
+
+	reload(this);
+
+	return &this->public.plugin;
+}
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.h b/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.h
new file mode 100644
index 000000000..1de102fcf
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_plugin.h
@@ -0,0 +1,29 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#ifndef IPSEC_OFFLOAD_PLUGIN_H_
+#define IPSEC_OFFLOAD_PLUGIN_H_
+
+#include <plugins/plugin.h>
+
+typedef struct ipsec_offload_plugin_t ipsec_offload_plugin_t;
+
+/**
+ * offload ipsec interface plugin
+ */
+struct ipsec_offload_plugin_t {
+
+        /**
+         * implements plugin interface
+         */
+        plugin_t plugin;
+};
+
+#endif /** IPSEC_OFFLOAD_PLUGIN_H_ @}*/
+                                          
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.c b/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.c
new file mode 100644
index 000000000..c53346647
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.c
@@ -0,0 +1,797 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#include <sys/socket.h>
+#include <linux/netlink.h>
+#include <linux/rtnetlink.h>
+#include <linux/xfrm.h>
+#include <errno.h>
+#include <unistd.h>
+
+#include "ipsec_offload_shared.h"
+
+#include <utils/debug.h>
+#include <threading/mutex.h>
+#include <threading/condvar.h>
+#include <collections/array.h>
+#include <collections/hashtable.h>
+
+typedef struct private_netlink_socket_t private_netlink_socket_t;
+
+/**
+ * Private variables and functions of netlink_socket_t class.
+ */
+struct private_netlink_socket_t {
+
+	/**
+	 * public part of the netlink_socket_t object.
+	 */
+	netlink_socket_t public;
+
+	/**
+	 * mutex to lock access entries
+	 */
+	mutex_t *mutex;
+
+	/**
+	 * Netlink request entries currently active, uintptr_t seq => entry_t
+	 */
+	hashtable_t *entries;
+
+	/**
+	 * Current sequence number for Netlink requests
+	 */
+	refcount_t seq;
+
+	/**
+	 * netlink socket
+	 */
+	int socket;
+
+	/**
+	 * Netlink protocol
+	 */
+	int protocol;
+
+	/**
+	 * Enum names for Netlink messages
+	 */
+	enum_name_t *names;
+
+	/**
+	 * Timeout for Netlink replies, in ms
+	 */
+	u_int timeout;
+
+	/**
+	 * Number of times to repeat timed out queries
+	 */
+	u_int retries;
+
+	/**
+	 * Buffer size for received Netlink messages
+	 */
+	u_int buflen;
+
+	/**
+	 * Use parallel netlink queries
+	 */
+	bool parallel;
+
+	/**
+	 * Ignore errors potentially resulting from a retransmission
+	 */
+	bool ignore_retransmit_errors;
+};
+
+/**
+ * #definable hook to simulate request message loss
+ */
+#ifdef NETLINK_MSG_LOSS_HOOK
+bool NETLINK_MSG_LOSS_HOOK(struct nlmsghdr *msg);
+#define msg_loss_hook(msg) NETLINK_MSG_LOSS_HOOK(msg)
+#else
+#define msg_loss_hook(msg) FALSE
+#endif
+
+/**
+ * Request entry the answer for a waiting thread is collected in
+ */
+typedef struct {
+	/** Condition variable thread is waiting */
+	condvar_t *condvar;
+	/** Array of hdrs in a multi-message response, as struct nlmsghdr* */
+	array_t *hdrs;
+	/** All response messages received? */
+	bool complete;
+} entry_t;
+
+/**
+ * Clean up a thread waiting entry
+ */
+static void destroy_entry(entry_t *entry)
+{
+	entry->condvar->destroy(entry->condvar);
+	array_destroy_function(entry->hdrs, (void*)free, NULL);
+	free(entry);
+}
+
+/**
+ * Write a Netlink message to socket
+ */
+static bool write_msg(private_netlink_socket_t *this, struct nlmsghdr *msg)
+{
+	struct sockaddr_nl addr = {
+		.nl_family = AF_NETLINK,
+	};
+	int len;
+
+	if (msg_loss_hook(msg))
+	{
+		return TRUE;
+	}
+
+	while (TRUE)
+	{
+		len = sendto(this->socket, msg, msg->nlmsg_len, 0,
+					 (struct sockaddr*)&addr, sizeof(addr));
+		if (len != msg->nlmsg_len)
+		{
+			if (errno == EINTR)
+			{
+				continue;
+			}
+			DBG1(DBG_KNL, "netlink write error: %s", strerror(errno));
+			return FALSE;
+		}
+		return TRUE;
+	}
+}
+
+/**
+ * Read a single Netlink message from socket, return 0 on error, -1 on timeout
+ */
+static ssize_t read_msg(private_netlink_socket_t *this,
+						char *buf, size_t buflen, bool block)
+{
+	ssize_t len;
+
+	if (block)
+	{
+		fd_set set;
+		timeval_t tv = {};
+
+		FD_ZERO(&set);
+		FD_SET(this->socket, &set);
+		timeval_add_ms(&tv, this->timeout);
+
+		if (select(this->socket + 1, &set, NULL, NULL,
+				   this->timeout ? &tv : NULL) <= 0)
+		{
+			return -1;
+		}
+	}
+	len = recv(this->socket, buf, buflen, MSG_TRUNC|(block ? 0 : MSG_DONTWAIT));
+	if (len > buflen)
+	{
+		DBG1(DBG_KNL, "netlink response exceeds buffer size");
+		return 0;
+	}
+	if (len < 0)
+	{
+		if (errno != EAGAIN && errno != EWOULDBLOCK && errno != EINTR)
+		{
+			DBG1(DBG_KNL, "netlink read error: %s", strerror(errno));
+		}
+		return 0;
+	}
+	return len;
+}
+
+/**
+ * Queue received response message
+ */
+static bool queue(private_netlink_socket_t *this, struct nlmsghdr *buf)
+{
+	struct nlmsghdr *hdr;
+	entry_t *entry;
+	uintptr_t seq;
+
+	seq = (uintptr_t)buf->nlmsg_seq;
+
+	this->mutex->lock(this->mutex);
+	entry = this->entries->get(this->entries, (void*)seq);
+	if (entry)
+	{
+		hdr = malloc(buf->nlmsg_len);
+		memcpy(hdr, buf, buf->nlmsg_len);
+		array_insert(entry->hdrs, ARRAY_TAIL, hdr);
+		if (hdr->nlmsg_type == NLMSG_DONE || !(hdr->nlmsg_flags & NLM_F_MULTI))
+		{
+			entry->complete = TRUE;
+			entry->condvar->signal(entry->condvar);
+		}
+	}
+	else
+	{
+		DBG1(DBG_KNL, "received unknown netlink seq %u, ignored", seq);
+	}
+	this->mutex->unlock(this->mutex);
+
+	return entry != NULL;
+}
+
+/**
+ * Read and queue response message, optionally blocking, returns TRUE on timeout
+ */
+static bool read_and_queue(private_netlink_socket_t *this, bool block)
+{
+	struct nlmsghdr *hdr;
+	char buf[this->buflen];
+	ssize_t len, read_len;
+	bool wipe = FALSE;
+
+	len = read_len = read_msg(this, buf, sizeof(buf), block);
+	if (len == -1)
+	{
+		return TRUE;
+	}
+	if (len)
+	{
+		hdr = (struct nlmsghdr*)buf;
+		while (NLMSG_OK(hdr, len))
+		{
+			if (this->protocol == NETLINK_XFRM &&
+				hdr->nlmsg_type == XFRM_MSG_NEWSA)
+			{	/* wipe potential IPsec SA keys */
+				wipe = TRUE;
+			}
+			if (!queue(this, hdr))
+			{
+				break;
+			}
+			hdr = NLMSG_NEXT(hdr, len);
+		}
+	}
+	if (wipe)
+	{
+		memwipe(buf, read_len);
+	}
+	return FALSE;
+}
+
+CALLBACK(watch, bool,
+	private_netlink_socket_t *this, int fd, watcher_event_t event)
+{
+	if (event == WATCHER_READ)
+	{
+		read_and_queue(this, FALSE);
+	}
+	return TRUE;
+}
+
+/**
+ * Send a netlink request, try once
+ */
+static status_t send_once(private_netlink_socket_t *this, struct nlmsghdr *in,
+						  uintptr_t seq, struct nlmsghdr **out, size_t *out_len)
+{
+	struct nlmsghdr *hdr;
+	entry_t *entry;
+	u_char *ptr;
+	int i;
+
+	in->nlmsg_seq = seq;
+	in->nlmsg_pid = getpid();
+
+	if (this->names)
+	{
+		DBG3(DBG_KNL, "sending %N %u: %b", this->names, in->nlmsg_type,
+			 (u_int)seq, in, in->nlmsg_len);
+	}
+
+	this->mutex->lock(this->mutex);
+	if (!write_msg(this, in))
+	{
+		this->mutex->unlock(this->mutex);
+		return FAILED;
+	}
+
+	INIT(entry,
+		.condvar = condvar_create(CONDVAR_TYPE_DEFAULT),
+		.hdrs = array_create(0, 0),
+	);
+	this->entries->put(this->entries, (void*)seq, entry);
+
+	while (!entry->complete)
+	{
+		if (this->parallel &&
+			lib->watcher->get_state(lib->watcher) != WATCHER_STOPPED &&
+			lib->processor->get_total_threads(lib->processor))
+		{
+			if (this->timeout)
+			{
+				if (entry->condvar->timed_wait(entry->condvar, this->mutex,
+											   this->timeout))
+				{
+					break;
+				}
+			}
+			else
+			{
+				entry->condvar->wait(entry->condvar, this->mutex);
+			}
+		}
+		else
+		{	/* During (de-)initialization, no watcher thread is active.
+			 * collect responses ourselves. */
+			if (read_and_queue(this, TRUE))
+			{
+				break;
+			}
+		}
+	}
+	this->entries->remove(this->entries, (void*)seq);
+
+	this->mutex->unlock(this->mutex);
+
+	if (!entry->complete)
+	{	/* timeout */
+		destroy_entry(entry);
+		return OUT_OF_RES;
+	}
+
+	for (i = 0, *out_len = 0; i < array_count(entry->hdrs); i++)
+	{
+		array_get(entry->hdrs, i, &hdr);
+		*out_len += NLMSG_ALIGN(hdr->nlmsg_len);
+	}
+	ptr = malloc(*out_len);
+	*out = (struct nlmsghdr*)ptr;
+
+	while (array_remove(entry->hdrs, ARRAY_HEAD, &hdr))
+	{
+		if (this->names)
+		{
+			DBG3(DBG_KNL, "received %N %u: %b", this->names, hdr->nlmsg_type,
+				 hdr->nlmsg_seq, hdr, hdr->nlmsg_len);
+		}
+		memcpy(ptr, hdr, hdr->nlmsg_len);
+		ptr += NLMSG_ALIGN(hdr->nlmsg_len);
+		free(hdr);
+	}
+	destroy_entry(entry);
+	return SUCCESS;
+}
+
+/**
+ * Ignore errors for message types that might have completed previously
+ */
+static void ignore_retransmit_error(private_netlink_socket_t *this,
+									struct nlmsgerr *err, int type)
+{
+	switch (err->error)
+	{
+		case -EEXIST:
+			switch (this->protocol)
+			{
+				case NETLINK_XFRM:
+					switch (type)
+					{
+						case XFRM_MSG_NEWPOLICY:
+						case XFRM_MSG_NEWSA:
+							err->error = 0;
+							break;
+					}
+					break;
+				case NETLINK_ROUTE:
+					switch (type)
+					{
+						case RTM_NEWADDR:
+						case RTM_NEWLINK:
+						case RTM_NEWNEIGH:
+						case RTM_NEWROUTE:
+						case RTM_NEWRULE:
+							err->error = 0;
+							break;
+					}
+					break;
+			}
+			break;
+		case -ENOENT:
+			switch (this->protocol)
+			{
+				case NETLINK_XFRM:
+					switch (type)
+					{
+						case XFRM_MSG_DELPOLICY:
+						case XFRM_MSG_DELSA:
+							err->error = 0;
+							break;
+					}
+					break;
+				case NETLINK_ROUTE:
+					switch (type)
+					{
+						case RTM_DELADDR:
+						case RTM_DELLINK:
+						case RTM_DELNEIGH:
+						case RTM_DELROUTE:
+						case RTM_DELRULE:
+							err->error = 0;
+							break;
+					}
+					break;
+			}
+			break;
+	}
+}
+
+METHOD(netlink_socket_t, netlink_send, status_t,
+	private_netlink_socket_t *this, struct nlmsghdr *in, struct nlmsghdr **out,
+	size_t *out_len)
+{
+	uintptr_t seq;
+	u_int try;
+
+	seq = ref_get(&this->seq);
+
+	for (try = 0; try <= this->retries; ++try)
+	{
+		struct nlmsghdr *hdr;
+		status_t status;
+		size_t len;
+
+		if (try > 0)
+		{
+			DBG1(DBG_KNL, "retransmitting Netlink request (%u/%u)",
+				 try, this->retries);
+		}
+		status = send_once(this, in, seq, &hdr, &len);
+		switch (status)
+		{
+			case SUCCESS:
+				break;
+			case OUT_OF_RES:
+				continue;
+			default:
+				return status;
+		}
+		if (hdr->nlmsg_type == NLMSG_ERROR)
+		{
+			struct nlmsgerr* err;
+
+			err = NLMSG_DATA(hdr);
+			if (err->error == -EBUSY)
+			{
+				free(hdr);
+				try--;
+				continue;
+			}
+			if (this->ignore_retransmit_errors && try > 0)
+			{
+				ignore_retransmit_error(this, err, in->nlmsg_type);
+			}
+		}
+		*out = hdr;
+		*out_len = len;
+		return SUCCESS;
+	}
+	DBG1(DBG_KNL, "Netlink request timed out after %u retransmits",
+		 this->retries);
+	return OUT_OF_RES;
+}
+
+METHOD(netlink_socket_t, netlink_send_ack, status_t,
+	private_netlink_socket_t *this, struct nlmsghdr *in)
+{
+	struct nlmsghdr *out, *hdr;
+	size_t len;
+
+	if (netlink_send(this, in, &out, &len) != SUCCESS)
+	{
+		return FAILED;
+	}
+	hdr = out;
+	while (NLMSG_OK(hdr, len))
+	{
+		switch (hdr->nlmsg_type)
+		{
+			case NLMSG_ERROR:
+			{
+				struct nlmsgerr* err = NLMSG_DATA(hdr);
+
+				if (err->error)
+				{
+					if (-err->error == EEXIST)
+					{	/* do not report existing routes */
+						free(out);
+						return ALREADY_DONE;
+					}
+					if (-err->error == ESRCH)
+					{	/* do not report missing entries */
+						free(out);
+						return NOT_FOUND;
+					}
+					DBG1(DBG_KNL, "received netlink error: %s (%d)",
+						 strerror(-err->error), -err->error);
+					free(out);
+					return FAILED;
+				}
+				free(out);
+				return SUCCESS;
+			}
+			default:
+				hdr = NLMSG_NEXT(hdr, len);
+				continue;
+			case NLMSG_DONE:
+				break;
+		}
+		break;
+	}
+	DBG1(DBG_KNL, "netlink request not acknowledged");
+	free(out);
+	return FAILED;
+}
+
+METHOD(netlink_socket_t, destroy, void,
+	private_netlink_socket_t *this)
+{
+	if (this->socket != -1)
+	{
+		if (this->parallel)
+		{
+			lib->watcher->remove(lib->watcher, this->socket);
+		}
+		close(this->socket);
+	}
+	this->entries->destroy(this->entries);
+	this->mutex->destroy(this->mutex);
+	free(this);
+}
+
+/*
+ * Described in header
+ */
+u_int netlink_get_buflen()
+{
+	u_int buflen;
+
+	buflen = lib->settings->get_int(lib->settings,
+								"%s.plugins.kernel-netlink.buflen", 0, lib->ns);
+	if (!buflen)
+	{
+		long pagesize = sysconf(_SC_PAGESIZE);
+
+		if (pagesize == -1)
+		{
+			pagesize = 4096;
+		}
+		/* base this on NLMSG_GOODSIZE */
+		buflen = min(pagesize, 8192);
+	}
+	return buflen;
+}
+
+/*
+ * Described in header
+ */
+netlink_socket_t *netlink_socket_create(int protocol, enum_name_t *names,
+										bool parallel)
+{
+	private_netlink_socket_t *this;
+	struct sockaddr_nl addr = {
+		.nl_family = AF_NETLINK,
+	};
+	bool force_buf = FALSE;
+	int rcvbuf_size = 0;
+
+	INIT(this,
+		.public = {
+			.send = _netlink_send,
+			.send_ack = _netlink_send_ack,
+			.destroy = _destroy,
+		},
+		.seq = 200,
+		.mutex = mutex_create(MUTEX_TYPE_RECURSIVE),
+		.socket = socket(AF_NETLINK, SOCK_RAW, protocol),
+		.entries = hashtable_create(hashtable_hash_ptr, hashtable_equals_ptr, 4),
+		.protocol = protocol,
+		.names = names,
+		.buflen = netlink_get_buflen(),
+		.timeout = lib->settings->get_int(lib->settings,
+							"%s.plugins.kernel-netlink.timeout", 0, lib->ns),
+		.retries = lib->settings->get_int(lib->settings,
+							"%s.plugins.kernel-netlink.retries", 0, lib->ns),
+		.ignore_retransmit_errors = lib->settings->get_bool(lib->settings,
+							"%s.plugins.kernel-netlink.ignore_retransmit_errors",
+							FALSE, lib->ns),
+		.parallel = parallel,
+	);
+
+	if (this->socket == -1)
+	{
+		DBG1(DBG_KNL, "unable to create netlink socket: %s (%d)",
+			 strerror(errno), errno);
+		destroy(this);
+		return NULL;
+	}
+	if (bind(this->socket, (struct sockaddr*)&addr, sizeof(addr)))
+	{
+		DBG1(DBG_KNL, "unable to bind netlink socket: %s (%d)",
+			 strerror(errno), errno);
+		destroy(this);
+		return NULL;
+	}
+	rcvbuf_size = lib->settings->get_int(lib->settings,
+						"%s.plugins.kernel-netlink.receive_buffer_size",
+						rcvbuf_size, lib->ns);
+	if (rcvbuf_size)
+	{
+		int optname;
+
+		force_buf = lib->settings->get_bool(lib->settings,
+						"%s.plugins.kernel-netlink.force_receive_buffer_size",
+						force_buf, lib->ns);
+		optname = force_buf ? SO_RCVBUFFORCE : SO_RCVBUF;
+
+		if (setsockopt(this->socket, SOL_SOCKET, optname, &rcvbuf_size,
+					   sizeof(rcvbuf_size)) == -1)
+		{
+			DBG1(DBG_KNL, "failed to %supdate receive buffer size to %d: %s",
+					force_buf ? "forcibly " : "", rcvbuf_size, strerror(errno));
+		}
+	}
+	if (this->parallel)
+	{
+		lib->watcher->add(lib->watcher, this->socket, WATCHER_READ, watch, this);
+	}
+
+	return &this->public;
+}
+
+/*
+ * Described in header
+ */
+void netlink_add_attribute(struct nlmsghdr *hdr, int rta_type, chunk_t data,
+						  size_t buflen)
+{
+	struct rtattr *rta;
+
+	if (NLMSG_ALIGN(hdr->nlmsg_len) + RTA_LENGTH(data.len) > buflen)
+	{
+		DBG1(DBG_KNL, "unable to add attribute, buffer too small");
+		return;
+	}
+
+	rta = (struct rtattr*)(((char*)hdr) + NLMSG_ALIGN(hdr->nlmsg_len));
+	rta->rta_type = rta_type;
+	rta->rta_len = RTA_LENGTH(data.len);
+	memcpy(RTA_DATA(rta), data.ptr, data.len);
+	hdr->nlmsg_len = NLMSG_ALIGN(hdr->nlmsg_len) + RTA_ALIGN(rta->rta_len);
+}
+
+/**
+ * Add an attribute to the given Netlink message
+ */
+static struct rtattr *add_rtattr(struct nlmsghdr *hdr, int buflen, int type,
+								 int len)
+{
+	struct rtattr *rta;
+
+	if (NLMSG_ALIGN(hdr->nlmsg_len) + RTA_LENGTH(len) > buflen)
+	{
+		DBG1(DBG_KNL, "unable to add attribute, buffer too small");
+		return NULL;
+	}
+
+	rta = ((void*)hdr) + NLMSG_ALIGN(hdr->nlmsg_len);
+	rta->rta_type = type;
+	rta->rta_len = RTA_LENGTH(len);
+	hdr->nlmsg_len = NLMSG_ALIGN(hdr->nlmsg_len) + RTA_ALIGN(rta->rta_len);
+	return rta;
+}
+
+/*
+ * Described in header
+ */
+void *netlink_nested_start(struct nlmsghdr *hdr, size_t buflen, int type)
+{
+	return add_rtattr(hdr, buflen, type, 0);
+}
+
+/*
+ * Described in header
+ */
+void netlink_nested_end(struct nlmsghdr *hdr, void *attr)
+{
+	struct rtattr *rta = attr;
+	void *end;
+
+	if (attr)
+	{
+		end = (char*)hdr + NLMSG_ALIGN(hdr->nlmsg_len);
+		rta->rta_len = end - attr;
+	}
+}
+
+/*
+ * Described in header
+ */
+void *netlink_reserve(struct nlmsghdr *hdr, int buflen, int type, int len)
+{
+	struct rtattr *rta;
+
+	rta = add_rtattr(hdr, buflen, type, len);
+	if (!rta)
+	{
+		return NULL;
+	}
+	return RTA_DATA(rta);
+}
+
+/*
+ * Described in header
+ */
+void route_entry_destroy(route_entry_t *this)
+{
+	free(this->if_name);
+	DESTROY_IF(this->src_ip);
+	DESTROY_IF(this->gateway);
+	chunk_free(&this->dst_net);
+	free(this);
+}
+
+/*
+ * Described in header
+ */
+route_entry_t *route_entry_clone(const route_entry_t *this)
+{
+	route_entry_t *route;
+
+	INIT(route,
+		.if_name = strdupnull(this->if_name),
+		.src_ip = this->src_ip ? this->src_ip->clone(this->src_ip) : NULL,
+		.gateway = this->gateway ? this->gateway->clone(this->gateway) : NULL,
+		.dst_net = chunk_clone(this->dst_net),
+		.prefixlen = this->prefixlen,
+		.pass = this->pass,
+	);
+	return route;
+}
+
+/*
+ * Described in header
+ */
+u_int route_entry_hash(const route_entry_t *this)
+{
+	return chunk_hash_inc(chunk_from_thing(this->prefixlen),
+						  chunk_hash(this->dst_net));
+}
+
+/**
+ * Compare two IP addresses, also accept it if both are NULL
+ */
+static bool addrs_null_or_equal(host_t *a, host_t *b)
+{
+	return (!a && !b) || (a && b && a->ip_equals(a, b));
+}
+
+/*
+ * Described in header
+ */
+bool route_entry_equals(const route_entry_t *a, const route_entry_t *b)
+{
+	return streq(a->if_name, b->if_name) &&
+		a->pass == b->pass &&
+		a->prefixlen == b->prefixlen &&
+		chunk_equals(a->dst_net, b->dst_net) &&
+		addrs_null_or_equal(a->src_ip, b->src_ip) &&
+		addrs_null_or_equal(a->gateway, b->gateway);
+}
diff --git a/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.h b/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.h
new file mode 100644
index 000000000..c3a42aeac
--- /dev/null
+++ b/src/libcharon/plugins/ipsec_offload/ipsec_offload_shared.h
@@ -0,0 +1,173 @@
+/****************************************************************************
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
+#ifndef IPSEC_OFFLOAD_SHARED_H_
+#define IPSEC_OFFLOAD_SHARED_H_
+
+#include <library.h>
+
+#include <linux/rtnetlink.h>
+
+/**
+ * Default buffer size.
+ *
+ * 1024 byte is currently sufficient for all operations.
+ */
+#ifndef KERNEL_NETLINK_BUFSIZE
+#define KERNEL_NETLINK_BUFSIZE 1024
+#endif
+
+/**
+ * General purpose netlink buffer.
+ *
+ * Some platforms require an enforced alignment to four bytes (e.g. ARM).
+ */
+typedef union {
+	struct nlmsghdr hdr;
+	u_char bytes[KERNEL_NETLINK_BUFSIZE];
+} netlink_buf_t __attribute__((aligned(RTA_ALIGNTO)));
+
+typedef struct netlink_socket_t netlink_socket_t;
+
+/**
+ * Wrapper around a netlink socket.
+ */
+struct netlink_socket_t {
+
+	/**
+	 * Send a netlink message and wait for a reply.
+	 *
+	 * @param	in		netlink message to send
+	 * @param	out 	received netlink message
+	 * @param	out_len	length of the received message
+	 */
+	status_t (*send)(netlink_socket_t *this, struct nlmsghdr *in,
+					 struct nlmsghdr **out, size_t *out_len);
+
+	/**
+	 * Send a netlink message and wait for its acknowledge.
+	 *
+	 * @param	in		netlink message to send
+	 */
+	status_t (*send_ack)(netlink_socket_t *this, struct nlmsghdr *in);
+
+	/**
+	 * Destroy the socket.
+	 */
+	void (*destroy)(netlink_socket_t *this);
+};
+
+/**
+ * Create a netlink_socket_t object.
+ *
+ * @param protocol	protocol type (e.g. NETLINK_XFRM or NETLINK_ROUTE)
+ * @param names		optional enum names for Netlink messages
+ * @param parallel	support parallel queries on this Netlink socket
+ */
+netlink_socket_t *netlink_socket_create(int protocol, enum_name_t *names,
+										bool parallel);
+
+/**
+ * Creates an rtattr and adds it to the given netlink message.
+ *
+ * @param hdr			netlink message
+ * @param rta_type		type of the rtattr
+ * @param data			data to add to the rtattr
+ * @param buflen		length of the netlink message buffer
+ */
+void netlink_add_attribute(struct nlmsghdr *hdr, int rta_type, chunk_t data,
+						   size_t buflen);
+
+/**
+ * Creates an rtattr under which other rtattrs are nested to the given netlink
+ * message.
+ *
+ * The returned pointer has to be passed to netlink_nested_end() after the
+ * nested attributes have been added to the message.
+ *
+ * @param hdr			netlink message
+ * @param buflen		size of full netlink buffer
+ * @param type			RTA type
+ * @return				attribute pointer
+ */
+void *netlink_nested_start(struct nlmsghdr *hdr, size_t buflen, int type);
+
+/**
+ * Updates the length of the given attribute after nested attributes were added.
+ *
+ * @param hdr			netlink message
+ * @param attr			attribute returned from netlink_nested_start()
+ */
+void netlink_nested_end(struct nlmsghdr *hdr, void *attr);
+
+/**
+ * Reserve space in a netlink message for given size and type, returning buffer.
+ *
+ * @param hdr			netlink message
+ * @param buflen		size of full netlink buffer
+ * @param type			RTA type
+ * @param len			length of RTA data
+ * @return				buffer to len bytes of attribute data, NULL on error
+ */
+void* netlink_reserve(struct nlmsghdr *hdr, int buflen, int type, int len);
+
+/**
+ * Determine buffer size for received messages (e.g. events).
+ *
+ * @return				buffer size
+ */
+u_int netlink_get_buflen();
+
+/**
+ * Information about an installed route.
+ */
+struct route_entry_t {
+
+	/** Destination net */
+	chunk_t dst_net;
+
+	/** Destination net prefix length */
+	uint8_t prefixlen;
+
+	/** Name of the interface the route is bound to (optional) */
+	char *if_name;
+
+	/** Source IP of the route (virtual IP or %any) */
+	host_t *src_ip;
+
+	/** Gateway for this route (optional) */
+	host_t *gateway;
+
+	/** Whether the route was installed for a passthrough policy */
+	bool pass;
+};
+
+typedef struct route_entry_t route_entry_t;
+
+/**
+ * Destroy a route entry.
+ */
+void route_entry_destroy(route_entry_t *this);
+
+/**
+ * Clone a route entry.
+ */
+route_entry_t *route_entry_clone(const route_entry_t *this);
+
+/**
+ * Hash a route entry (note that this only hashes the destination).
+ */
+u_int route_entry_hash(const route_entry_t *this);
+
+/**
+ * Compare two route entries.
+ */
+bool route_entry_equals(const route_entry_t *a, const route_entry_t *b);
+
+#endif /* IPSEC_OFFLOAD_SHARED_H_ */
diff --git a/src/libcharon/plugins/stroke/stroke_config.c b/src/libcharon/plugins/stroke/stroke_config.c
index 175b6b549..72d2afc39 100644
--- a/src/libcharon/plugins/stroke/stroke_config.c
+++ b/src/libcharon/plugins/stroke/stroke_config.c
@@ -13,6 +13,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #include "stroke_config.h"
 
@@ -1090,6 +1098,7 @@ static child_cfg_t *build_child_cfg(private_stroke_config_t *this,
 				   (msg->add_conn.ipcomp ? OPT_IPCOMP : 0) |
 				   (msg->add_conn.me.hostaccess ? OPT_HOSTACCESS : 0) |
 				   (msg->add_conn.install_policy ? 0 : OPT_NO_POLICIES) |
+				   (msg->add_conn.hw_offload ? OPT_HW_OFFLOAD : 0) |
 				   (msg->add_conn.sha256_96 ? OPT_SHA256_96 : 0),
 		.tfc = msg->add_conn.tfc,
 		.inactivity = msg->add_conn.inactivity,
diff --git a/src/libcharon/plugins/vici/vici_config.c b/src/libcharon/plugins/vici/vici_config.c
index eb679290d..698e032f9 100644
--- a/src/libcharon/plugins/vici/vici_config.c
+++ b/src/libcharon/plugins/vici/vici_config.c
@@ -38,6 +38,14 @@
  * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
  * THE SOFTWARE.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #define _GNU_SOURCE
 
@@ -559,7 +567,8 @@ static void log_child_data(child_data_t *data, char *name)
 	DBG2(DBG_CFG, "   proposals = %#P", data->proposals);
 	DBG2(DBG_CFG, "   local_ts = %#R", data->local_ts);
 	DBG2(DBG_CFG, "   remote_ts = %#R", data->remote_ts);
-	DBG2(DBG_CFG, "   hw_offload = %N", hw_offload_names, cfg->hw_offload);
+	//DBG2(DBG_CFG, "   hw_offload = %N", hw_offload_names, cfg->hw_offload);
+	DBG2(DBG_CFG, "   hw_offload = %u", has_opt(OPT_HW_OFFLOAD)); 
 	DBG2(DBG_CFG, "   sha256_96 = %u", has_opt(OPT_SHA256_96));
 	DBG2(DBG_CFG, "   copy_df = %u", !has_opt(OPT_NO_COPY_DF));
 	DBG2(DBG_CFG, "   copy_ecn = %u", !has_opt(OPT_NO_COPY_ECN));
@@ -1013,6 +1022,16 @@ CALLBACK(parse_action, bool,
 	return FALSE;
 }
 
+/**
+ * Parse OPT_HW_OFFLOAD option
+ */
+CALLBACK(parse_opt_hw_offl, bool,
+	child_cfg_option_t *out, chunk_t v)
+{
+	return parse_option(out, OPT_HW_OFFLOAD, v, TRUE);
+}
+
+#if 0
 /**
  * Parse an hw_offload_t
  */
@@ -1033,6 +1052,7 @@ CALLBACK(parse_hw_offload, bool,
 	}
 	return FALSE;
 }
+#endif
 
 /**
  * Parse a uint32_t with the given base
@@ -1740,7 +1760,8 @@ CALLBACK(child_kv, bool,
 		{ "tfc_padding",		parse_tfc,			&child->cfg.tfc						},
 		{ "priority",			parse_uint32,		&child->cfg.priority				},
 		{ "interface",			parse_string,		&child->cfg.interface				},
-		{ "hw_offload",			parse_hw_offload,	&child->cfg.hw_offload				},
+		//{ "hw_offload",			parse_hw_offload,	&child->cfg.hw_offload				},
+		{ "hw_offload",			parse_opt_hw_offl,	&child->cfg.options				},
 		{ "sha256_96",			parse_opt_sha256_96,&child->cfg.options					},
 		{ "copy_df",			parse_opt_copy_df,	&child->cfg.options					},
 		{ "copy_ecn",			parse_opt_copy_ecn,	&child->cfg.options					},
diff --git a/src/libcharon/sa/child_sa.c b/src/libcharon/sa/child_sa.c
index 207763953..9351af8e3 100644
--- a/src/libcharon/sa/child_sa.c
+++ b/src/libcharon/sa/child_sa.c
@@ -16,6 +16,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #define _GNU_SOURCE
 #include "child_sa.h"
@@ -907,7 +915,8 @@ static status_t install_internal(private_child_sa_t *this, chunk_t encr,
 		.ipcomp = this->ipcomp,
 		.cpi = cpi,
 		.encap = this->encap,
-		.hw_offload = this->config->get_hw_offload(this->config),
+		.hw_offload = this->config->has_option(this->config, OPT_HW_OFFLOAD),
+		//.hw_offload = this->config->get_hw_offload(this->config),
 		.mark = this->config->get_set_mark(this->config, inbound),
 		.esn = esn,
 		.copy_df = !this->config->has_option(this->config, OPT_NO_COPY_DF),
diff --git a/src/starter/args.c b/src/starter/args.c
index a37ce6a3e..bd3797e40 100644
--- a/src/starter/args.c
+++ b/src/starter/args.c
@@ -14,6 +14,15 @@
  * for more details.
  */
 
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
 #include <stddef.h>
 #include <stdlib.h>
 #include <string.h>
@@ -175,6 +184,7 @@ static const token_info_t token_info[] =
 	{ ARG_STR,  offsetof(starter_conn_t, me_peerid), NULL                          },
 	{ ARG_UINT, offsetof(starter_conn_t, reqid), NULL                              },
 	{ ARG_UINT, offsetof(starter_conn_t, replay_window), NULL                      },
+	{ ARG_ENUM, offsetof(starter_conn_t, hw_offload), LST_bool		       },
 	{ ARG_MISC, 0, NULL  /* KW_MARK */                                             },
 	{ ARG_MISC, 0, NULL  /* KW_MARK_IN */                                          },
 	{ ARG_MISC, 0, NULL  /* KW_MARK_OUT */                                         },
diff --git a/src/starter/confread.h b/src/starter/confread.h
index 0c22481f0..08c3103ec 100644
--- a/src/starter/confread.h
+++ b/src/starter/confread.h
@@ -12,6 +12,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #ifndef _IPSEC_CONFREAD_H_
 #define _IPSEC_CONFREAD_H_
@@ -169,7 +177,7 @@ struct starter_conn {
 		bool            me_mediation;
 		char            *me_mediated_by;
 		char            *me_peerid;
-
+		bool            hw_offload;
 		starter_conn_t *next;
 };
 
diff --git a/src/starter/keywords.h.in b/src/starter/keywords.h.in
index 60ec2723a..56967c252 100644
--- a/src/starter/keywords.h.in
+++ b/src/starter/keywords.h.in
@@ -74,6 +74,7 @@ enum kw_token_t {
 	KW_ME_PEERID,
 	KW_REQID,
 	KW_REPLAY_WINDOW,
+	KW_HW_OFFLOAD,
 	KW_MARK,
 	KW_MARK_IN,
 	KW_MARK_OUT,
diff --git a/src/starter/keywords.txt b/src/starter/keywords.txt
index e696dce8e..9448f2df5 100644
--- a/src/starter/keywords.txt
+++ b/src/starter/keywords.txt
@@ -13,6 +13,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #include <string.h>
 
@@ -136,6 +144,7 @@ rightgroups,       KW_RIGHTGROUPS
 rightgroups2,      KW_RIGHTGROUPS2
 also,              KW_ALSO
 auto,              KW_AUTO
+hw_offload,        KW_HW_OFFLOAD
 # deprecated/removed keywords
 interfaces,        KW_SETUP_DEPRECATED
 dumpdir,           KW_SETUP_DEPRECATED
diff --git a/src/starter/starterstroke.c b/src/starter/starterstroke.c
index 90ba1cd72..4166086db 100644
--- a/src/starter/starterstroke.c
+++ b/src/starter/starterstroke.c
@@ -13,6 +13,15 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
+
 
 #include <unistd.h>
 #include <stdlib.h>
@@ -228,6 +237,7 @@ int starter_stroke_add_conn(starter_config_t *cfg, starter_conn_t *conn)
 	msg->add_conn.reqid = conn->reqid;
 	msg->add_conn.replay_window = conn->replay_window;
 	msg->add_conn.mark_in.value = conn->mark_in.value;
+	msg->add_conn.hw_offload = conn->hw_offload;
 	msg->add_conn.mark_in.mask = conn->mark_in.mask;
 	msg->add_conn.mark_out.value = conn->mark_out.value;
 	msg->add_conn.mark_out.mask = conn->mark_out.mask;
diff --git a/src/stroke/stroke_msg.h b/src/stroke/stroke_msg.h
index 08560d36f..428717d13 100644
--- a/src/stroke/stroke_msg.h
+++ b/src/stroke/stroke_msg.h
@@ -13,6 +13,14 @@
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  * for more details.
  */
+/*
+ * Strongswan IPSEC offload Implementation for Xilinx U25N Accelerator Card.
+ * Copyright 2021 Xilinx Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation, incorporated herein by reference.
+ */
 
 #ifndef STROKE_MSG_H_
 #define STROKE_MSG_H_
@@ -303,6 +311,7 @@ struct stroke_msg_t {
 			stroke_end_t me, other;
 			uint32_t replay_window;
 			bool sha256_96;
+			bool hw_offload;
 		} add_conn;
 
 		/* data for STR_ADD_CA */
